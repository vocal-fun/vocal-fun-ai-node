/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [29981]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [29981]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [30433]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 1.5375869274139404
 > Real-time factor: 0.4832353442057781
INFO:     127.0.0.1:44236 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 0.5470659732818604
 > Real-time factor: 0.23091126935040238
INFO:     127.0.0.1:44236 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['what do you think that the best way to get the most out of your time in the city is?', 'what do you think that the best way to get the most out of your time in the city is?', 'I think that the best way to get the most out of']
 > Processing time: 4.031206130981445
 > Real-time factor: 0.26201508981081945
INFO:     127.0.0.1:49696 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [30433]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [31613]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.2628884315490723
 > Real-time factor: 0.3969026498810867
INFO:     127.0.0.1:50584 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.5963566303253174
 > Real-time factor: 0.24687713462513608
INFO:     127.0.0.1:50590 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50590 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55872 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55872 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do that?', 'how will we do']
 > Processing time: 3.788353681564331
 > Real-time factor: 0.2450516271957683
INFO:     127.0.0.1:42356 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [31613]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [32505]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.570594310760498
 > Real-time factor: 0.6501878295334368
INFO:     127.0.0.1:40416 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.6901638507843018
 > Real-time factor: 0.24456982691234658
INFO:     127.0.0.1:40416 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will we make America great again?', 'The Trump administration is a disaster.', 'The Trump administration is a disaster.', 'The president is a disaster.', 'The Republican Party is a disaster.', 'The Democratic Party is a disaster.', 'The media is a disaster.', 'The courts are a disaster.', 'The']
 > Processing time: 6.965655326843262
 > Real-time factor: 0.24225977911182006
INFO:     127.0.0.1:43792 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [32505]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [33533]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 1.7113888263702393
 > Real-time factor: 0.3260760025358062
INFO:     127.0.0.1:36354 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36354 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will you make America great again (Please give a 1 sentence answer)', 'By: james', 'I think that we should make America great again by making it a better place for everyone.', 'We should make it a place where everyone can live and work in peace.', 'We should make it a place where everyone can have a']
 > Processing time: 5.87427544593811
 > Real-time factor: 0.2332388097880509
INFO:     127.0.0.1:52936 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [33533]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [34009]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Hello there!', 'How can I assist you today?']
 > Processing time: 1.5856494903564453
 > Real-time factor: 0.41878558909495517
INFO:     127.0.0.1:33026 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will you make medical greater than the sum of its parts?', 'how will you make medical greater than the sum of its parts?', 'how will you make medical greater than the sum of its parts?', 'how will you make medical greater than the sum of its parts?', 'how will']
 > Processing time: 4.019543170928955
 > Real-time factor: 0.2351501860354233
INFO:     127.0.0.1:45742 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.9067587852478027
 > Real-time factor: 0.2849776398904511
INFO:     127.0.0.1:40266 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 0.7283236980438232
 > Real-time factor: 0.23315240333719953
INFO:     127.0.0.1:40266 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [34009]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [36079]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.6593501567840576
 > Real-time factor: 0.5670200681423331
INFO:     127.0.0.1:53056 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.8496580123901367
 > Real-time factor: 0.3830340033775457
INFO:     127.0.0.1:40394 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [36079]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [36459]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.6309592723846436
 > Real-time factor: 0.7021761159809706
INFO:     127.0.0.1:35518 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35518 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['A conversation with Trump and a Vocal User', 'Vocal User: how will you make America great again', 'Trump: I will make America great again by making America great again', 'Vocal User: how will you make America great again', 'Trump: I will make America great again by making America great again', 'Vocal User: how will']
 > Processing time: 6.7169013023376465
 > Real-time factor: 0.24325247299322197
INFO:     127.0.0.1:58464 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [36459]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [37202]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 2.3165512084960938
 > Real-time factor: 0.6762332417302858
INFO:     127.0.0.1:55408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55408 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will you make a medical greater than the sum of its parts?', 'how will you make a medical greater than the sum of its parts?', 'how will you make a medical greater than the sum of its parts?', 'how will you make a medical greater than the sum of its parts?']
 > Processing time: 4.542133092880249
 > Real-time factor: 0.26645782260452894
INFO:     127.0.0.1:58808 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [37202]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [38100]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 2.402278423309326
 > Real-time factor: 0.6102562123729337
INFO:     127.0.0.1:54248 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [38100]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [38536]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 2.6627776622772217
 > Real-time factor: 0.3065954102954128
INFO:     127.0.0.1:60678 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60684 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.5198941230773926
 > Real-time factor: 0.23938492761979005
INFO:     127.0.0.1:60684 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how will you make America great again?', 'The Trump administration is in the process of rolling back environmental regulations and reversing Obama-era policies.', 'The president has also proposed a budget that would cut funding for the EPA, the Department of Energy, and other agencies.', 'Trumpâ€™s']
 > Processing time: 6.494143962860107
 > Real-time factor: 0.27362547844003254
INFO:     127.0.0.1:37976 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35632 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35632 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how do you like Muslims?', "I'm a Muslim.", "I don't know if that makes me a good or bad Muslim, but I am one.", 'I have been to the mosque and I have prayed there.', 'I have also been to a few of the']
 > Processing time: 5.08357048034668
 > Real-time factor: 0.2551180061988918
INFO:     127.0.0.1:55142 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['vah jo hai vah smart hai vah kachra Nahin Karta Tha.', 'vah jo bhi hai kya kar raha hai.', 'Vah jo khud se kuch nahin karega.', 'Koi bhi kar sakta hai, koi']
 > Processing time: 5.090098857879639
 > Real-time factor: 0.2697582098336939
INFO:     127.0.0.1:34738 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Pakistanâ€™s first-ever â€˜Pakistani Prideâ€™ event held in London', 'London: The first ever Pakistani Pride event was held at the British Museum in London on Saturday.', 'The event, which was organised by the Pakistan High Commission in London']
 > Processing time: 4.711076021194458
 > Real-time factor: 0.26657571922433226
INFO:     127.0.0.1:40044 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['hey how do you feel about packets?', 'I\'m not sure what you mean by "packets".', 'If you mean the packets that are sent to the server, then I think they are fine.', 'If it is the packets sent from the client to the client, then']
 > Processing time: 5.891869783401489
 > Real-time factor: 0.2709106180852188
INFO:     127.0.0.1:43684 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["hey guys, i'm new to this forum and i have a question.", "i've been using the 100% free version of the software for a while now and i love it.", 'but i want to buy the pro version']
 > Processing time: 3.672866106033325
 > Real-time factor: 0.26469009059128673
INFO:     127.0.0.1:43684 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55150 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55150 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Mr Trump what is your country on baggage was specifically gay people are homosexuals as one could refer to them as a group.', 'I am not sure if you have read the Bible but it clearly states that homosexuality is an abomination and that God hates it.', "You can't be a Christian and support this sinful behaviour.", 'It is']
 > Processing time: 6.175071954727173
 > Real-time factor: 0.25469954021334806
INFO:     127.0.0.1:43544 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how do you feel about those who are not in the church?', 'I am a Christian, and I believe that God is the creator of all things.', 'He made us to be His children, and we should love Him with all our hearts, minds, souls, and strength.']
 > Processing time: 3.754380702972412
 > Real-time factor: 0.2537894690873525
INFO:     127.0.0.1:55088 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Jesus was gay and he used to go to the baths.', 'Iâ€™m not sure if this is a joke or not, but itâ€™s certainly a very interesting idea.', 'I think it would be great to see a film about Jesusâ€™ life as a young man in']
 > Processing time: 4.1861412525177
 > Real-time factor: 0.25352783623933006
INFO:     127.0.0.1:43232 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['hey Trump do you like tea?', "I'm not sure if this is a joke or not.", 'Trump is a very good president.', 'He has done more for the country than any other president in history.', 'He is a great president and he will be re-elected']
 > Processing time: 4.738917112350464
 > Real-time factor: 0.24868893589193033
INFO:     127.0.0.1:46498 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['do you watch porn with health recruitment?', "I'm not sure if this is the right place to ask, but I was wondering if anyone has ever used health recruitment to get a job in the porn industry.", 'I know that there are some people who have done it, but it']
 > Processing time: 4.20915675163269
 > Real-time factor: 0.254921738006759
INFO:     127.0.0.1:44378 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [38536]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [72500]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [72500]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [72894]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 4.121037244796753
 > Real-time factor: 0.9617789082109272
INFO:     127.0.0.1:46818 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46818 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['can we make Mercury a planet again?', "I'm not sure if this is the right place to post this, but I was wondering what you guys thought about making mercury a full fledged planet.", 'It has been demoted from being a planet because it']
 > Processing time: 4.648342609405518
 > Real-time factor: 0.26546753796307565
INFO:     127.0.0.1:43304 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how can we make America great again?', 'Iâ€™m not sure what the answer is, but I do know that it starts with us.', 'We have to be willing to take a stand for our country and fight for its future.', 'It wonâ€™t be easy, but if']
 > Processing time: 4.217080116271973
 > Real-time factor: 0.258664034860126
INFO:     127.0.0.1:38448 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [72894]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [74559]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [74559]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [74970]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.7379176616668701
 > Real-time factor: 0.4988685227004073
INFO:     127.0.0.1:49760 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.8900368213653564
 > Real-time factor: 0.23226320667376102
INFO:     127.0.0.1:49760 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how to:']
 > Processing time: 0.5017127990722656
 > Real-time factor: 0.2310133482196679
INFO:     127.0.0.1:57546 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['a new constitution']
 > Processing time: 0.5090672969818115
 > Real-time factor: 0.22949243331797808
INFO:     127.0.0.1:59718 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['You can use a syringe to remove the sand from the tyres.']
 > Processing time: 1.0244591236114502
 > Real-time factor: 0.23339936017970406
INFO:     127.0.0.1:42044 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['sedition']
 > Processing time: 0.3523564338684082
 > Real-time factor: 0.24074923670049583
INFO:     127.0.0.1:35064 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['about you shut the fuck up']
 > Processing time: 0.5925970077514648
 > Real-time factor: 0.23089419036117825
INFO:     127.0.0.1:45022 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["I'm not gonna do it"]
 > Processing time: 0.4126133918762207
 > Real-time factor: 0.22772640395651447
INFO:     127.0.0.1:45028 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['I will fuck you over']
 > Processing time: 0.4865415096282959
 > Real-time factor: 0.23018023273480784
INFO:     127.0.0.1:41396 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['I will take your America and put it in green lenses']
 > Processing time: 1.070359230041504
 > Real-time factor: 0.23277399619708816
INFO:     127.0.0.1:48068 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['blah blahhh bla']
 > Processing time: 0.4604504108428955
 > Real-time factor: 0.22916512186452345
INFO:     127.0.0.1:51352 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Shut the fuck up bro']
 > Processing time: 0.5794601440429688
 > Real-time factor: 0.2299362254561521
INFO:     127.0.0.1:51352 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['- a new generation of Americans']
 > Processing time: 0.6578798294067383
 > Real-time factor: 0.22935508219103495
INFO:     127.0.0.1:41472 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['a new generation of trash']
 > Processing time: 0.5456380844116211
 > Real-time factor: 0.23030857123423132
INFO:     127.0.0.1:40156 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Vodafone is so fast']
 > Processing time: 0.7255430221557617
 > Real-time factor: 0.25710696256323196
INFO:     127.0.0.1:57624 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['What is the name of the new king?']
 > Processing time: 0.8140130043029785
 > Real-time factor: 0.23058821614697683
INFO:     127.0.0.1:42948 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["It's The Lion King"]
 > Processing time: 0.6140894889831543
 > Real-time factor: 0.22990819804534351
INFO:     127.0.0.1:45248 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [74970]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [76077]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 2.45133638381958
 > Real-time factor: 0.7485592630071701
INFO:     127.0.0.1:57700 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57700 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how can we make America great again?', 'The answer is simple: We must make America a better place to live.', 'We must make our schools and our neighborhoods safer, our streets and our parks cleaner, our workplaces and our communities more vibrant, and our government more responsive']
 > Processing time: 4.629331588745117
 > Real-time factor: 0.24266089520137557
INFO:     127.0.0.1:57724 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how about you shut the fuck up and let me do my job.', '" "I\'m sorry, but I can\'t do that.', '" "You\'re not going to do what?" "I can\'t let you go in there.', '" "Why not?" "Because I\'m not going in there']
 > Processing time: 3.1817514896392822
 > Real-time factor: 0.2353903409737565
INFO:     127.0.0.1:42604 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['what the fuck are you not going there for?" "I\'m not going anywhere.', '" "I just want to know what the fuck is going on.', '" "You\'re not going to get anything out of me.', '" "Why not?" "Because I\'m not a fucking rat.', '" "What do']
 > Processing time: 3.593489408493042
 > Real-time factor: 0.22990007850515173
INFO:     127.0.0.1:37228 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how big is a fucking rat?" "I don\'t know.', '" "I\'m not a fucking scientist.', '" "You\'re not a scientist?" "No.', '" "What are you, then?" "A fucking artist?" "You know, I\'m not really sure what I am.', '"']
 > Processing time: 4.165997505187988
 > Real-time factor: 0.23190472641423418
INFO:     127.0.0.1:38204 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['why are you not a fucking scientist?" "I\'m a fucking doctor.', '" "I don\'t know what you\'re talking about.', '" "You\'re a fucking liar.', '" "What the fuck is wrong with you?" "You don\'t even know what the fuck you\'re doing.', '" "It']
 > Processing time: 4.157142877578735
 > Real-time factor: 0.23661101590728928
INFO:     127.0.0.1:44566 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33086 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33086 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Ultrasound money for the win!']
 > Processing time: 1.4863436222076416
 > Real-time factor: 0.23749186137448186
INFO:     127.0.0.1:33086 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make Ethereum great again!!!']
 > Processing time: 0.5828633308410645
 > Real-time factor: 0.2220786640352065
INFO:     127.0.0.1:33086 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['tell me something new in ethereum', 'I am a newbie in e-commerce and I want to know something new about ethereum.', 'A:', 'You can use the web3.js library to interact with the Ethereum blockchain.', 'Here is a good tutorial']
 > Processing time: 7.992342948913574
 > Real-time factor: 0.23735475975587803
INFO:     127.0.0.1:35258 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.9466252326965332
 > Real-time factor: 0.31842028284352203
INFO:     127.0.0.1:52660 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52660 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [76077]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [77581]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.830176830291748
 > Real-time factor: 0.6253936137480326
INFO:     127.0.0.1:58054 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.6148459911346436
 > Real-time factor: 0.23426448203827224
INFO:     127.0.0.1:58054 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58054 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how do you like Muslims?" "I don\'t like Muslims.', '" "I like Muslims, but I don\'t want to be one.', '" "You\'re not a Muslim.', '" "No, I\'m not.', '" "But I\'m a Christian.', '" "And I\'m going to be']
 > Processing time: 5.12192177772522
 > Real-time factor: 0.23984534318476278
INFO:     127.0.0.1:39216 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['about you shut the fuck up.', '" "I\'m not gonna shut up.', '" "[Sighs]" "I don\'t know what to do.', '" "You\'re not gonna do anything.', '" "It\'s not your fault.', '" "We\'re all in this together.', '" "No, we']
 > Processing time: 3.518876075744629
 > Real-time factor: 0.23182040689734532
INFO:     127.0.0.1:55174 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [77581]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [78170]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.626175880432129
 > Real-time factor: 0.657399130308163
INFO:     127.0.0.1:33168 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.5131969451904297
 > Real-time factor: 0.23135411844637255
INFO:     127.0.0.1:33168 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Ajmer Kashyap (born 12 August 1997) is a Pakistani footballer who plays for Pakistan Super League side Al-Ahli.', 'He has played for Al-Haq and Al-Jaze']
 > Processing time: 3.953226327896118
 > Real-time factor: 0.23792645790601089
INFO:     127.0.0.1:59442 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how can we make America great again?']
 > Processing time: 1.789973497390747
 > Real-time factor: 0.2364427514704901
INFO:     127.0.0.1:42602 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Shut the fuck']
 > Processing time: 0.546464204788208
 > Real-time factor: 0.23065726867496145
INFO:     127.0.0.1:55576 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55584 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55584 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [78170]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [78938]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 3.8313260078430176
 > Real-time factor: 1.6171657441221006
INFO:     127.0.0.1:47016 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.5258197784423828
 > Real-time factor: 0.23704461307357172
INFO:     127.0.0.1:47016 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47032 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47032 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["i don't like Muslims"]
 > Processing time: 0.6024363040924072
 > Real-time factor: 0.23472788565941438
INFO:     127.0.0.1:53204 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['why the fuck not?']
 > Processing time: 0.38240718841552734
 > Real-time factor: 0.23685613776860612
INFO:     127.0.0.1:53204 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['What do you think about the sex of the king?']
 > Processing time: 0.7280936241149902
 > Real-time factor: 0.23659609189659772
INFO:     127.0.0.1:53204 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["i'm not a fucking idiot"]
 > Processing time: 0.5827336311340332
 > Real-time factor: 0.2270511126396917
INFO:     127.0.0.1:55374 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["I'm not a fan of the sexy tits."]
 > Processing time: 0.7361037731170654
 > Real-time factor: 0.26084932176059544
INFO:     127.0.0.1:37056 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [78938]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [80104]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [80104]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [81290]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [81290]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [82651]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [82651]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [82945]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [82945]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [85126]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 1.1570310592651367
 > Real-time factor: 0.3891953694287934
INFO:     127.0.0.1:58598 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 0.5082495212554932
 > Real-time factor: 0.22442530326184765
INFO:     127.0.0.1:58598 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['do you like Muslims?" "I don\'t know.', '" "I\'m not a Muslim.', '" "You\'re not a Christian?" "No.', '" "No, I\'m not.', '" "What do you do?" "What does he do?" ""What does she do?""']
 > Processing time: 3.6950912475585938
 > Real-time factor: 0.22615346740425843
INFO:     127.0.0.1:56028 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['shut the fuck up bro.', '" "I\'m not gonna shut up.', '" "You\'re not gonna do shit.', '" "What are you talking about?" "You know what I\'m talking about.', '" "No, I don\'t.', '" "Yes, you do.', '" "And you know']
 > Processing time: 3.3645830154418945
 > Real-time factor: 0.23046950485391227
INFO:     127.0.0.1:47606 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
["you're not gonna do shit.", '" "You\'re not going to do shit!" "You are not going anywhere!" "I\'m not going nowhere.', '" "I am not going away.', '" "We\'re not leaving you here.', '" "No, we\'re not.', '" "Come on.', '"']
 > Processing time: 5.53294825553894
 > Real-time factor: 0.22485607368301147
INFO:     127.0.0.1:54946 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['tell me something new about America.', '"', '"I don\'t know anything about America," I said.', '"I\'m just a guy who\'s been to the moon."', '**CHAPTER FOURTEEN**', '**_The Moon_**', '**I** t was']
 > Processing time: 7.778791666030884
 > Real-time factor: 0.2321232328941128
INFO:     127.0.0.1:56210 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [85126]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [85878]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 2.4448342323303223
 > Real-time factor: 1.1021547845699133
INFO:     127.0.0.1:37082 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37082 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['A conversation with Trump and a Vocal User', 'Vocal User: do you think Muslims are trash', 'Trump: I donâ€™t know.', "I don't know.", 'Iâ€™m not a Muslim.', 'Iâ€™ve never been a Muslim, but Iâ€˜ve been a supporter of the Muslim community.', 'I think they']
 > Processing time: 5.595122814178467
 > Real-time factor: 0.24383450742464977
INFO:     127.0.0.1:43900 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.8830728530883789
 > Real-time factor: 0.31816595442154827
INFO:     127.0.0.1:56320 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56320 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [85878]
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/vits-ljspeech").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 300, in _set_model_item
    model_type, lang, dataset, model = model_name.split("/")
ValueError: not enough values to unpack (expected 4, got 3)
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--ljspeech--vits

  0%|          | 0.00/146M [00:00<?, ?iB/s]
  1%|          | 1.74M/146M [00:00<00:08, 17.4MiB/s]
  2%|â–         | 3.47M/146M [00:00<00:08, 17.1MiB/s]
  4%|â–Ž         | 5.18M/146M [00:00<00:25, 5.44MiB/s]
  5%|â–         | 6.86M/146M [00:00<00:18, 7.38MiB/s]
  6%|â–Œ         | 8.55M/146M [00:00<00:14, 9.23MiB/s]
  7%|â–‹         | 10.2M/146M [00:01<00:12, 10.9MiB/s]
  8%|â–Š         | 11.8M/146M [00:01<00:15, 8.46MiB/s]
 14%|â–ˆâ–Ž        | 19.9M/146M [00:01<00:05, 22.7MiB/s]
 16%|â–ˆâ–Œ        | 23.4M/146M [00:01<00:06, 19.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 31.5M/146M [00:01<00:04, 23.6MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 34.3M/146M [00:03<00:13, 8.27MiB/s]
 25%|â–ˆâ–ˆâ–       | 36.4M/146M [00:03<00:12, 8.72MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 38.2M/146M [00:03<00:11, 9.55MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 40.2M/146M [00:03<00:09, 10.8MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 42.1M/146M [00:03<00:12, 8.63MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 52.4M/146M [00:04<00:05, 16.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 56.6M/146M [00:04<00:05, 15.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 58.5M/146M [00:04<00:06, 13.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 60.8M/146M [00:05<00:06, 13.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 62.9M/146M [00:05<00:07, 11.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64.6M/146M [00:05<00:06, 11.9MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 66.0M/146M [00:06<00:12, 6.45MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 69.2M/146M [00:06<00:09, 7.88MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 72.8M/146M [00:06<00:06, 11.2MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 74.6M/146M [00:06<00:08, 8.64MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 83.9M/146M [00:07<00:03, 15.5MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94.4M/146M [00:07<00:02, 20.0MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 96.6M/146M [00:07<00:02, 18.1MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 98.5M/146M [00:08<00:04, 10.9MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 99.9M/146M [00:08<00:04, 10.6MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 101M/146M [00:08<00:03, 11.2MiB/s] 
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 103M/146M [00:08<00:03, 12.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 105M/146M [00:08<00:04, 9.37MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 115M/146M [00:09<00:01, 18.5MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 120M/146M [00:09<00:01, 13.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 124M/146M [00:09<00:01, 15.1MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 126M/146M [00:10<00:01, 12.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 128M/146M [00:10<00:01, 14.3MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 130M/146M [00:10<00:01, 13.9MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 132M/146M [00:10<00:00, 15.6MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 134M/146M [00:10<00:00, 14.9MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 136M/146M [00:11<00:00, 11.2MiB/s] > Model's license - apache 2.0
 > Check https://choosealicense.com/licenses/apache-2.0/ for more info.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 93, in __init__
    self._load_tts(tts_checkpoint, tts_config_path, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 187, in _load_tts
    self.tts_model = setup_tts_model(config=self.tts_config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/__init__.py", line 13, in setup_model
    model = MyModel.init_from_config(config=config, samples=samples)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1796, in init_from_config
    tokenizer, new_config = TTSTokenizer.init_from_config(config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/tokenizer.py", line 198, in init_from_config
    phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/__init__.py", line 60, in get_phonemizer_by_name
    return ESpeak(**kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py", line 114, in __init__
    raise Exception(" [!] No espeak backend found. Install espeak-ng or espeak to your system.")
Exception:  [!] No espeak backend found. Install espeak-ng or espeak to your system.

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146M/146M [00:11<00:00, 12.4MiB/s]
 > tts_models/en/ljspeech/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 93, in __init__
    self._load_tts(tts_checkpoint, tts_config_path, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 187, in _load_tts
    self.tts_model = setup_tts_model(config=self.tts_config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/__init__.py", line 13, in setup_model
    model = MyModel.init_from_config(config=config, samples=samples)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1796, in init_from_config
    tokenizer, new_config = TTSTokenizer.init_from_config(config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/tokenizer.py", line 198, in init_from_config
    phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/__init__.py", line 60, in get_phonemizer_by_name
    return ESpeak(**kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py", line 114, in __init__
    raise Exception(" [!] No espeak backend found. Install espeak-ng or espeak to your system.")
Exception:  [!] No espeak backend found. Install espeak-ng or espeak to your system.
 > tts_models/en/ljspeech/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 93, in __init__
    self._load_tts(tts_checkpoint, tts_config_path, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 187, in _load_tts
    self.tts_model = setup_tts_model(config=self.tts_config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/__init__.py", line 13, in setup_model
    model = MyModel.init_from_config(config=config, samples=samples)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1796, in init_from_config
    tokenizer, new_config = TTSTokenizer.init_from_config(config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/tokenizer.py", line 198, in init_from_config
    phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/__init__.py", line 60, in get_phonemizer_by_name
    return ESpeak(**kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py", line 114, in __init__
    raise Exception(" [!] No espeak backend found. Install espeak-ng or espeak to your system.")
Exception:  [!] No espeak backend found. Install espeak-ng or espeak to your system.
 > tts_models/en/ljspeech/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 93, in __init__
    self._load_tts(tts_checkpoint, tts_config_path, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 187, in _load_tts
    self.tts_model = setup_tts_model(config=self.tts_config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/__init__.py", line 13, in setup_model
    model = MyModel.init_from_config(config=config, samples=samples)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1796, in init_from_config
    tokenizer, new_config = TTSTokenizer.init_from_config(config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/tokenizer.py", line 198, in init_from_config
    phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/__init__.py", line 60, in get_phonemizer_by_name
    return ESpeak(**kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py", line 114, in __init__
    raise Exception(" [!] No espeak backend found. Install espeak-ng or espeak to your system.")
Exception:  [!] No espeak backend found. Install espeak-ng or espeak to your system.
 > tts_models/en/ljspeech/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/en/ljspeech/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 93, in __init__
    self._load_tts(tts_checkpoint, tts_config_path, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 187, in _load_tts
    self.tts_model = setup_tts_model(config=self.tts_config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/__init__.py", line 13, in setup_model
    model = MyModel.init_from_config(config=config, samples=samples)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1796, in init_from_config
    tokenizer, new_config = TTSTokenizer.init_from_config(config)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/tokenizer.py", line 198, in init_from_config
    phonemizer = get_phonemizer_by_name(config.phonemizer, **phonemizer_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/__init__.py", line 60, in get_phonemizer_by_name
    return ESpeak(**kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/text/phonemizers/espeak_wrapper.py", line 114, in __init__
    raise Exception(" [!] No espeak backend found. Install espeak-ng or espeak to your system.")
Exception:  [!] No espeak backend found. Install espeak-ng or espeak to your system.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
INFO:     Started server process [88740]
INFO:uvicorn.error:Started server process [88740]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
 > tts_models/en/ljspeech/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.5024378299713135
 > Real-time factor: 0.7477598896457986
INFO:     127.0.0.1:47866 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Make America great again!!!']
 > Processing time: 0.10526418685913086
 > Real-time factor: 0.04952789604480701
INFO:     127.0.0.1:47866 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['yo how are you doing?', "I'm doing fine", "jdong: I'm not sure if you are aware, but I'm working on a new version of the ubuntu-docs package", 'm']
 > Processing time: 0.5013368129730225
 > Real-time factor: 0.043475006001664145
INFO:     127.0.0.1:40746 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['how about you shut the fuck up and let me do my job.', '" "I\'m sorry, but I can\'t do that.', '" "You\'re not going to do what?" "I can\'t let you go in there.', '" "Why not?" "Because I\'m not going in there']
 > Processing time: 0.33050107955932617
 > Real-time factor: 0.02327160230266178
INFO:     127.0.0.1:48274 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [88740]
INFO:uvicorn.error:Finished server process [88740]
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 20, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 17, in <module>
    print(TTS.list_models())
TypeError: TTS.list_models() missing 1 required positional argument: 'self'
<TTS.utils.manage.ModelManager object at 0x7f00fd8c3b50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
<TTS.utils.manage.ModelManager object at 0x7f7c64c37b50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
<TTS.utils.manage.ModelManager object at 0x7f14fbcebb50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
<TTS.utils.manage.ModelManager object at 0x7effc272fb50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
<TTS.utils.manage.ModelManager object at 0x7fcd395b3b50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
<TTS.utils.manage.ModelManager object at 0x7f218a80fb50>
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 22, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/vits").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 385, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 301, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'vits'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [91233]
INFO:uvicorn.error:Started server process [91233]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [91233]
INFO:uvicorn.error:Finished server process [91233]
<TTS.utils.manage.ModelManager object at 0x7f80462abb50>
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Downloading model to /home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--bark

  0%|          | 0.00/3.93G [00:00<?, ?iB/s]
  0%|          | 1.20M/3.93G [00:00<10:09, 6.45MiB/s]
  0%|          | 4.02M/3.93G [00:00<05:40, 11.5MiB/s]
  0%|          | 7.36M/3.93G [00:00<04:32, 14.4MiB/s]
  0%|          | 12.6M/3.93G [00:00<03:18, 19.7MiB/s]
  0%|          | 17.8M/3.93G [00:00<02:52, 22.7MiB/s]
  1%|          | 23.0M/3.93G [00:01<02:40, 24.4MiB/s]
  1%|          | 28.2M/3.93G [00:01<02:32, 25.6MiB/s]
  1%|          | 33.5M/3.93G [00:01<02:28, 26.3MiB/s]
  1%|          | 38.7M/3.93G [00:01<02:25, 26.7MiB/s]
  1%|          | 43.9M/3.93G [00:01<02:23, 27.1MiB/s]
  1%|          | 49.1M/3.93G [00:02<02:22, 27.3MiB/s]
  1%|â–         | 54.3M/3.93G [00:02<02:21, 27.5MiB/s]
  2%|â–         | 59.5M/3.93G [00:02<02:20, 27.6MiB/s]
  2%|â–         | 64.7M/3.93G [00:02<02:20, 27.5MiB/s]
  2%|â–         | 69.9M/3.93G [00:02<02:19, 27.7MiB/s]
  2%|â–         | 75.1M/3.93G [00:02<02:19, 27.7MiB/s]
  2%|â–         | 80.3M/3.93G [00:03<02:19, 27.7MiB/s]
  2%|â–         | 85.5M/3.93G [00:03<02:19, 27.7MiB/s]
  2%|â–         | 90.7M/3.93G [00:03<02:18, 27.8MiB/s]
  2%|â–         | 96.0M/3.93G [00:03<02:18, 27.8MiB/s]
  3%|â–Ž         | 101M/3.93G [00:03<02:18, 27.7MiB/s] 
  3%|â–Ž         | 106M/3.93G [00:04<02:18, 27.7MiB/s]
  3%|â–Ž         | 112M/3.93G [00:04<02:17, 27.9MiB/s]
  3%|â–Ž         | 117M/3.93G [00:04<02:17, 27.8MiB/s]
  3%|â–Ž         | 122M/3.93G [00:04<02:17, 27.7MiB/s]
  3%|â–Ž         | 127M/3.93G [00:04<02:17, 27.8MiB/s]
  3%|â–Ž         | 132M/3.93G [00:05<02:16, 27.9MiB/s]
  3%|â–Ž         | 138M/3.93G [00:05<02:16, 27.9MiB/s]
  4%|â–Ž         | 143M/3.93G [00:05<02:17, 27.5MiB/s]
  4%|â–         | 148M/3.93G [00:05<02:15, 27.9MiB/s]
  4%|â–         | 153M/3.93G [00:05<02:15, 27.9MiB/s]
  4%|â–         | 158M/3.93G [00:05<02:15, 27.8MiB/s]
  4%|â–         | 164M/3.93G [00:06<02:17, 27.5MiB/s]
  4%|â–         | 169M/3.93G [00:06<02:14, 28.0MiB/s]
  4%|â–         | 174M/3.93G [00:06<02:14, 28.0MiB/s]
  5%|â–         | 179M/3.93G [00:06<02:16, 27.6MiB/s]
  5%|â–         | 185M/3.93G [00:06<02:14, 28.0MiB/s]
  5%|â–         | 190M/3.93G [00:07<02:14, 27.9MiB/s]
  5%|â–         | 195M/3.93G [00:07<02:14, 27.9MiB/s]
  5%|â–Œ         | 200M/3.93G [00:07<02:15, 27.5MiB/s]
  5%|â–Œ         | 205M/3.93G [00:07<02:13, 28.0MiB/s]
  5%|â–Œ         | 211M/3.93G [00:07<02:13, 27.9MiB/s]
  5%|â–Œ         | 216M/3.93G [00:08<02:13, 27.9MiB/s]
  6%|â–Œ         | 221M/3.93G [00:08<02:13, 27.9MiB/s]
  6%|â–Œ         | 226M/3.93G [00:08<02:13, 27.9MiB/s]
  6%|â–Œ         | 232M/3.93G [00:08<02:12, 27.9MiB/s]
  6%|â–Œ         | 237M/3.93G [00:08<02:14, 27.5MiB/s]
  6%|â–Œ         | 242M/3.93G [00:09<02:13, 27.6MiB/s]
  6%|â–‹         | 247M/3.93G [00:09<02:13, 27.7MiB/s]
  6%|â–‹         | 252M/3.93G [00:09<02:11, 28.0MiB/s]
  7%|â–‹         | 258M/3.93G [00:09<02:11, 28.0MiB/s]
  7%|â–‹         | 263M/3.93G [00:09<02:13, 27.5MiB/s]
  7%|â–‹         | 268M/3.93G [00:09<02:11, 28.0MiB/s]
  7%|â–‹         | 273M/3.93G [00:10<02:11, 27.9MiB/s]
  7%|â–‹         | 276M/3.93G [00:10<02:11, 27.9MiB/s]
  7%|â–‹         | 279M/3.93G [00:10<02:12, 27.5MiB/s]
  7%|â–‹         | 284M/3.93G [00:10<02:10, 28.0MiB/s]
  7%|â–‹         | 289M/3.93G [00:10<02:10, 28.0MiB/s]
  7%|â–‹         | 294M/3.93G [00:10<02:10, 27.9MiB/s]
  8%|â–Š         | 299M/3.93G [00:11<02:10, 27.9MiB/s]
  8%|â–Š         | 305M/3.93G [00:11<02:10, 27.9MiB/s]
  8%|â–Š         | 310M/3.93G [00:11<02:10, 27.8MiB/s]
  8%|â–Š         | 315M/3.93G [00:11<02:12, 27.4MiB/s]
  8%|â–Š         | 320M/3.93G [00:11<02:09, 27.8MiB/s]
  8%|â–Š         | 325M/3.93G [00:11<02:09, 27.8MiB/s]
  8%|â–Š         | 331M/3.93G [00:12<02:09, 27.8MiB/s]
  9%|â–Š         | 336M/3.93G [00:12<02:10, 27.5MiB/s]
  9%|â–Š         | 341M/3.93G [00:12<02:10, 27.6MiB/s]
  9%|â–‰         | 346M/3.93G [00:12<02:08, 28.0MiB/s]
  9%|â–‰         | 351M/3.93G [00:12<02:08, 27.9MiB/s]
  9%|â–‰         | 357M/3.93G [00:13<02:08, 27.9MiB/s]
  9%|â–‰         | 362M/3.93G [00:13<02:08, 27.8MiB/s]
  9%|â–‰         | 367M/3.93G [00:13<02:08, 27.8MiB/s]
  9%|â–‰         | 372M/3.93G [00:13<02:08, 27.8MiB/s]
 10%|â–‰         | 377M/3.93G [00:13<02:08, 27.8MiB/s]
 10%|â–‰         | 383M/3.93G [00:14<02:07, 27.8MiB/s]
 10%|â–‰         | 388M/3.93G [00:14<02:07, 27.8MiB/s]
 10%|â–‰         | 393M/3.93G [00:14<02:08, 27.7MiB/s]
 10%|â–ˆ         | 398M/3.93G [00:14<02:08, 27.6MiB/s]
 10%|â–ˆ         | 403M/3.93G [00:14<02:07, 27.7MiB/s]
 10%|â–ˆ         | 408M/3.93G [00:14<02:07, 27.7MiB/s]
 11%|â–ˆ         | 414M/3.93G [00:15<02:07, 27.6MiB/s]
 11%|â–ˆ         | 419M/3.93G [00:15<02:07, 27.6MiB/s]
 11%|â–ˆ         | 424M/3.93G [00:15<02:07, 27.6MiB/s]
 11%|â–ˆ         | 429M/3.93G [00:15<02:06, 27.7MiB/s]
 11%|â–ˆ         | 434M/3.93G [00:15<02:06, 27.7MiB/s]
 11%|â–ˆ         | 440M/3.93G [00:16<02:07, 27.3MiB/s]
 11%|â–ˆâ–        | 445M/3.93G [00:16<02:05, 27.8MiB/s]
 11%|â–ˆâ–        | 450M/3.93G [00:16<02:05, 27.8MiB/s]
 12%|â–ˆâ–        | 455M/3.93G [00:16<02:05, 27.7MiB/s]
 12%|â–ˆâ–        | 460M/3.93G [00:16<02:05, 27.6MiB/s]
 12%|â–ˆâ–        | 465M/3.93G [00:17<02:05, 27.6MiB/s]
 12%|â–ˆâ–        | 471M/3.93G [00:17<02:05, 27.6MiB/s]
 12%|â–ˆâ–        | 476M/3.93G [00:17<02:04, 27.7MiB/s]
 12%|â–ˆâ–        | 481M/3.93G [00:17<02:04, 27.7MiB/s]
 12%|â–ˆâ–        | 486M/3.93G [00:17<02:04, 27.7MiB/s]
 12%|â–ˆâ–        | 491M/3.93G [00:17<01:48, 31.7MiB/s]
 13%|â–ˆâ–Ž        | 495M/3.93G [00:18<02:00, 28.7MiB/s]
 13%|â–ˆâ–Ž        | 498M/3.93G [00:18<02:14, 25.5MiB/s]
 13%|â–ˆâ–Ž        | 502M/3.93G [00:18<02:06, 27.2MiB/s]
 13%|â–ˆâ–Ž        | 506M/3.93G [00:18<01:49, 31.2MiB/s]
 13%|â–ˆâ–Ž        | 510M/3.93G [00:18<02:03, 27.6MiB/s]
 13%|â–ˆâ–Ž        | 513M/3.93G [00:18<02:16, 25.1MiB/s]
 13%|â–ˆâ–Ž        | 517M/3.93G [00:18<01:56, 29.3MiB/s]
 13%|â–ˆâ–Ž        | 520M/3.93G [00:19<02:00, 28.4MiB/s]
 13%|â–ˆâ–Ž        | 523M/3.93G [00:19<02:16, 25.0MiB/s]
 13%|â–ˆâ–Ž        | 528M/3.93G [00:19<02:05, 27.1MiB/s]
 14%|â–ˆâ–Ž        | 532M/3.93G [00:19<01:48, 31.4MiB/s]
 14%|â–ˆâ–Ž        | 536M/3.93G [00:19<02:06, 26.9MiB/s]
 14%|â–ˆâ–Ž        | 538M/3.93G [00:19<02:12, 25.6MiB/s]
 14%|â–ˆâ–        | 543M/3.93G [00:19<01:55, 29.3MiB/s]
 14%|â–ˆâ–        | 546M/3.93G [00:19<02:02, 27.6MiB/s]
 14%|â–ˆâ–        | 549M/3.93G [00:20<02:13, 25.5MiB/s]
 14%|â–ˆâ–        | 553M/3.93G [00:20<01:53, 29.7MiB/s]
 14%|â–ˆâ–        | 557M/3.93G [00:20<02:01, 27.7MiB/s]
 14%|â–ˆâ–        | 559M/3.93G [00:20<02:11, 25.6MiB/s]
 14%|â–ˆâ–        | 564M/3.93G [00:20<01:53, 29.8MiB/s]
 14%|â–ˆâ–        | 567M/3.93G [00:20<02:02, 27.6MiB/s]
 14%|â–ˆâ–        | 570M/3.93G [00:20<02:10, 25.8MiB/s]
 15%|â–ˆâ–        | 574M/3.93G [00:20<01:53, 29.6MiB/s]
 15%|â–ˆâ–        | 577M/3.93G [00:21<02:01, 27.6MiB/s]
 15%|â–ˆâ–        | 580M/3.93G [00:21<02:09, 25.9MiB/s]
 15%|â–ˆâ–        | 585M/3.93G [00:21<01:53, 29.6MiB/s]
 15%|â–ˆâ–        | 588M/3.93G [00:21<02:01, 27.6MiB/s]
 15%|â–ˆâ–Œ        | 590M/3.93G [00:21<02:08, 26.0MiB/s]
 15%|â–ˆâ–Œ        | 595M/3.93G [00:21<01:53, 29.5MiB/s]
 15%|â–ˆâ–Œ        | 598M/3.93G [00:21<02:01, 27.4MiB/s]
 15%|â–ˆâ–Œ        | 601M/3.93G [00:21<02:05, 26.5MiB/s]
 15%|â–ˆâ–Œ        | 605M/3.93G [00:22<01:54, 29.2MiB/s]
 15%|â–ˆâ–Œ        | 608M/3.93G [00:22<02:01, 27.4MiB/s]
 16%|â–ˆâ–Œ        | 611M/3.93G [00:22<02:05, 26.4MiB/s]
 16%|â–ˆâ–Œ        | 615M/3.93G [00:22<01:49, 30.3MiB/s]
 16%|â–ˆâ–Œ        | 618M/3.93G [00:22<02:06, 26.3MiB/s]
 16%|â–ˆâ–Œ        | 621M/3.93G [00:22<02:04, 26.7MiB/s]
 16%|â–ˆâ–Œ        | 624M/3.93G [00:22<01:57, 28.1MiB/s]
 16%|â–ˆâ–Œ        | 627M/3.93G [00:22<02:10, 25.4MiB/s]
 16%|â–ˆâ–Œ        | 631M/3.93G [00:23<01:59, 27.7MiB/s]
 16%|â–ˆâ–Œ        | 635M/3.93G [00:23<01:54, 28.7MiB/s]
 16%|â–ˆâ–Œ        | 638M/3.93G [00:23<02:08, 25.7MiB/s]
 16%|â–ˆâ–‹        | 642M/3.93G [00:23<01:58, 27.9MiB/s]
 16%|â–ˆâ–‹        | 645M/3.93G [00:23<01:53, 29.1MiB/s]
 16%|â–ˆâ–‹        | 648M/3.93G [00:23<02:06, 25.9MiB/s]
 17%|â–ˆâ–‹        | 652M/3.93G [00:23<01:58, 27.7MiB/s]
 17%|â–ˆâ–‹        | 655M/3.93G [00:23<01:52, 29.1MiB/s]
 17%|â–ˆâ–‹        | 658M/3.93G [00:24<02:05, 26.1MiB/s]
 17%|â–ˆâ–‹        | 662M/3.93G [00:24<01:58, 27.7MiB/s]
 17%|â–ˆâ–‹        | 666M/3.93G [00:24<01:51, 29.3MiB/s]
 17%|â–ˆâ–‹        | 669M/3.93G [00:24<02:05, 26.0MiB/s]
 17%|â–ˆâ–‹        | 673M/3.93G [00:24<01:57, 27.9MiB/s]
 17%|â–ˆâ–‹        | 676M/3.93G [00:24<01:51, 29.3MiB/s]
 17%|â–ˆâ–‹        | 679M/3.93G [00:24<02:05, 26.0MiB/s]
 17%|â–ˆâ–‹        | 683M/3.93G [00:24<01:57, 27.6MiB/s]
 17%|â–ˆâ–‹        | 686M/3.93G [00:25<01:51, 29.2MiB/s]
 18%|â–ˆâ–Š        | 690M/3.93G [00:25<02:02, 26.5MiB/s]
 18%|â–ˆâ–Š        | 694M/3.93G [00:25<01:57, 27.7MiB/s]
 18%|â–ˆâ–Š        | 697M/3.93G [00:25<01:52, 28.8MiB/s]
 18%|â–ˆâ–Š        | 700M/3.93G [00:25<01:59, 27.0MiB/s]
 18%|â–ˆâ–Š        | 704M/3.93G [00:25<01:47, 30.0MiB/s]
 18%|â–ˆâ–Š        | 707M/3.93G [00:25<01:56, 27.8MiB/s]
 18%|â–ˆâ–Š        | 710M/3.93G [00:25<01:58, 27.1MiB/s]
 18%|â–ˆâ–Š        | 713M/3.93G [00:25<01:51, 28.9MiB/s]
 18%|â–ˆâ–Š        | 716M/3.93G [00:26<02:05, 25.7MiB/s]
 18%|â–ˆâ–Š        | 719M/3.93G [00:26<01:58, 27.2MiB/s]
 18%|â–ˆâ–Š        | 723M/3.93G [00:26<01:52, 28.5MiB/s]
 18%|â–ˆâ–Š        | 726M/3.93G [00:26<02:00, 26.7MiB/s]
 19%|â–ˆâ–Š        | 730M/3.93G [00:26<01:46, 30.0MiB/s]
 19%|â–ˆâ–Š        | 733M/3.93G [00:26<01:55, 27.6MiB/s]
 19%|â–ˆâ–Š        | 736M/3.93G [00:26<02:00, 26.6MiB/s]
 19%|â–ˆâ–‰        | 740M/3.93G [00:26<01:47, 29.8MiB/s]
 19%|â–ˆâ–‰        | 743M/3.93G [00:27<02:00, 26.4MiB/s]
 19%|â–ˆâ–‰        | 745M/3.93G [00:27<01:59, 26.7MiB/s]
 19%|â–ˆâ–‰        | 749M/3.93G [00:27<01:53, 28.0MiB/s]
 19%|â–ˆâ–‰        | 751M/3.93G [00:27<02:00, 26.4MiB/s]
 19%|â–ˆâ–‰        | 756M/3.93G [00:27<01:46, 30.0MiB/s]
 19%|â–ˆâ–‰        | 759M/3.93G [00:27<01:56, 27.4MiB/s]
 19%|â–ˆâ–‰        | 762M/3.93G [00:27<02:00, 26.4MiB/s]
 19%|â–ˆâ–‰        | 765M/3.93G [00:27<01:46, 29.7MiB/s]
 20%|â–ˆâ–‰        | 768M/3.93G [00:28<01:59, 26.4MiB/s]
 20%|â–ˆâ–‰        | 771M/3.93G [00:28<01:58, 26.8MiB/s]
 20%|â–ˆâ–‰        | 774M/3.93G [00:28<01:53, 27.7MiB/s]
 20%|â–ˆâ–‰        | 777M/3.93G [00:28<01:57, 27.0MiB/s]
 20%|â–ˆâ–‰        | 781M/3.93G [00:28<01:44, 30.3MiB/s]
 20%|â–ˆâ–‰        | 784M/3.93G [00:28<01:57, 26.7MiB/s]
 20%|â–ˆâ–ˆ        | 787M/3.93G [00:28<01:57, 26.8MiB/s]
 20%|â–ˆâ–ˆ        | 790M/3.93G [00:28<01:54, 27.5MiB/s]
 20%|â–ˆâ–ˆ        | 793M/3.93G [00:28<01:56, 26.9MiB/s]
 20%|â–ˆâ–ˆ        | 796M/3.93G [00:28<01:47, 29.2MiB/s]
 20%|â–ˆâ–ˆ        | 799M/3.93G [00:29<02:00, 26.0MiB/s]
 20%|â–ˆâ–ˆ        | 802M/3.93G [00:29<01:53, 27.6MiB/s]
 20%|â–ˆâ–ˆ        | 805M/3.93G [00:29<01:51, 28.0MiB/s]
 21%|â–ˆâ–ˆ        | 808M/3.93G [00:29<01:54, 27.3MiB/s]
 21%|â–ˆâ–ˆ        | 812M/3.93G [00:29<01:46, 29.2MiB/s]
 21%|â–ˆâ–ˆ        | 815M/3.93G [00:29<01:59, 26.2MiB/s]
 21%|â–ˆâ–ˆ        | 818M/3.93G [00:29<02:01, 25.7MiB/s]
 21%|â–ˆâ–ˆ        | 820M/3.93G [00:29<02:28, 21.0MiB/s]
 21%|â–ˆâ–ˆ        | 826M/3.93G [00:30<01:41, 30.7MiB/s]
 21%|â–ˆâ–ˆ        | 830M/3.93G [00:30<01:49, 28.5MiB/s]
 21%|â–ˆâ–ˆ        | 834M/3.93G [00:30<01:45, 29.4MiB/s]
 21%|â–ˆâ–ˆâ–       | 837M/3.93G [00:30<01:46, 29.2MiB/s]
 21%|â–ˆâ–ˆâ–       | 840M/3.93G [00:30<01:51, 27.6MiB/s]
 21%|â–ˆâ–ˆâ–       | 843M/3.93G [00:30<01:51, 27.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 846M/3.93G [00:30<02:13, 23.2MiB/s]
 22%|â–ˆâ–ˆâ–       | 849M/3.93G [00:31<02:14, 23.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 851M/3.93G [00:31<02:41, 19.1MiB/s]
 22%|â–ˆâ–ˆâ–       | 860M/3.93G [00:31<01:31, 33.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 864M/3.93G [00:31<01:32, 33.3MiB/s]
 22%|â–ˆâ–ˆâ–       | 867M/3.93G [00:31<01:40, 30.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 871M/3.93G [00:31<01:46, 28.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 875M/3.93G [00:31<01:39, 30.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 878M/3.93G [00:31<01:47, 28.5MiB/s]
 22%|â–ˆâ–ˆâ–       | 881M/3.93G [00:32<01:49, 28.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 884M/3.93G [00:32<01:45, 29.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 887M/3.93G [00:32<01:55, 26.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 891M/3.93G [00:32<01:49, 27.9MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 894M/3.93G [00:32<01:46, 28.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 896M/3.93G [00:32<01:50, 27.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 900M/3.93G [00:32<01:46, 28.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 903M/3.93G [00:32<01:55, 26.3MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 906M/3.93G [00:32<01:48, 27.8MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 909M/3.93G [00:33<01:47, 28.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 912M/3.93G [00:33<01:48, 27.8MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 915M/3.93G [00:33<01:44, 29.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 918M/3.93G [00:33<01:54, 26.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 922M/3.93G [00:33<01:49, 27.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 925M/3.93G [00:33<01:48, 27.8MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 927M/3.93G [00:33<01:49, 27.5MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 930M/3.93G [00:33<01:45, 28.4MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 933M/3.93G [00:33<01:53, 26.5MiB/s]
 24%|â–ˆâ–ˆâ–       | 937M/3.93G [00:34<01:47, 27.9MiB/s]
 24%|â–ˆâ–ˆâ–       | 940M/3.93G [00:34<01:47, 27.9MiB/s]
 24%|â–ˆâ–ˆâ–       | 943M/3.93G [00:34<01:48, 27.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 946M/3.93G [00:34<01:45, 28.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 949M/3.93G [00:34<01:53, 26.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 953M/3.93G [00:34<01:47, 27.8MiB/s]
 24%|â–ˆâ–ˆâ–       | 956M/3.93G [00:34<01:47, 27.7MiB/s]
 24%|â–ˆâ–ˆâ–       | 958M/3.93G [00:34<01:47, 27.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 961M/3.93G [00:34<01:45, 28.3MiB/s]
 25%|â–ˆâ–ˆâ–       | 964M/3.93G [00:35<01:51, 26.7MiB/s]
 25%|â–ˆâ–ˆâ–       | 968M/3.93G [00:35<01:43, 28.7MiB/s]
 25%|â–ˆâ–ˆâ–       | 970M/3.93G [00:35<01:51, 26.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 974M/3.93G [00:35<01:46, 27.8MiB/s]
 25%|â–ˆâ–ˆâ–       | 977M/3.93G [00:35<01:45, 28.1MiB/s]
 25%|â–ˆâ–ˆâ–       | 979M/3.93G [00:35<01:49, 27.0MiB/s]
 25%|â–ˆâ–ˆâ–       | 983M/3.93G [00:35<01:44, 28.3MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 986M/3.93G [00:35<01:52, 26.2MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 989M/3.93G [00:35<01:46, 27.7MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 992M/3.93G [00:36<01:46, 27.7MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 995M/3.93G [00:36<01:45, 27.9MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 998M/3.93G [00:36<01:43, 28.3MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 1.00G/3.93G [00:36<01:48, 27.0MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.00G/3.93G [00:36<01:42, 28.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:36<01:50, 26.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:36<01:46, 27.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:36<01:46, 27.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:36<01:44, 27.9MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:37<01:43, 28.1MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:37<01:47, 27.1MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:37<01:40, 28.9MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:37<01:48, 26.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:37<01:45, 27.5MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.03G/3.93G [00:37<01:44, 27.7MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:37<01:44, 27.7MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:37<01:42, 28.2MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:37<01:47, 27.0MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:40, 28.7MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:48, 26.7MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:44, 27.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:45, 27.4MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:38<01:43, 27.7MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:38<01:42, 28.2MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:38<01:46, 27.0MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:38<01:39, 28.9MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:38<01:46, 26.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:38<01:44, 27.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:39<01:44, 27.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:39<01:43, 27.7MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:39<01:40, 28.3MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.08G/3.93G [00:39<01:45, 27.1MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:39<01:38, 28.8MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:39<02:24, 19.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:39<02:24, 19.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:40<02:31, 18.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:40<02:10, 21.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:40<01:59, 23.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:40<01:53, 25.0MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:40<01:49, 25.8MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:41<01:46, 26.5MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:41<01:44, 26.9MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.13G/3.93G [00:41<01:43, 27.0MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:41<01:42, 27.3MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:41<01:41, 27.4MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:41<01:40, 27.6MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:42<01:40, 27.7MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:42<01:40, 27.6MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:42<01:40, 27.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:42<01:39, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:42<01:39, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:43<01:39, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.18G/3.93G [00:43<01:38, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:43<01:38, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:43<01:38, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:43<01:38, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:44<01:38, 27.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:44<01:37, 27.9MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:44<01:37, 27.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:44<01:37, 27.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.23G/3.93G [00:44<01:37, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.23G/3.93G [00:44<01:37, 27.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:45<01:36, 27.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:45<01:36, 27.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:45<01:36, 27.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:45<01:36, 27.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:45<01:36, 27.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:46<01:35, 27.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:46<01:35, 27.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:46<01:35, 27.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.93G [00:46<01:35, 27.8MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:46<01:35, 27.7MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:47<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:47<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:47<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:47<01:34, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:48<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.33G/3.93G [00:48<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.33G/3.93G [00:48<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:48<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:48<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:49<01:32, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:49<01:32, 27.8MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:49<01:33, 27.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:49<01:32, 27.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:49<01:31, 28.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:50<01:31, 28.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:50<01:31, 27.9MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:50<01:32, 27.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:50<01:31, 27.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:50<01:30, 28.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:50<01:30, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:51<01:30, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:51<01:30, 27.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:51<01:30, 27.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:51<01:30, 27.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:51<01:30, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:52<01:29, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:52<01:30, 27.5MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:52<01:29, 28.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:52<01:29, 27.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:52<01:29, 27.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:53<01:29, 27.8MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:53<01:29, 27.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:53<01:28, 28.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:53<01:28, 28.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:53<01:27, 27.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:53<01:27, 27.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:54<01:28, 27.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:54<01:27, 27.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:54<01:27, 27.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:54<01:27, 27.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:54<01:27, 27.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:55<01:27, 27.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:55<01:26, 27.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:55<01:26, 27.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:55<01:26, 27.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:55<01:26, 27.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:56<01:26, 27.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:56<01:26, 27.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:56<01:25, 27.7MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:56<01:25, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:56<01:25, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:56<01:25, 27.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:57<01:24, 27.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:57<01:24, 27.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:57<01:24, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:57<01:24, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:57<01:24, 27.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:58<01:24, 27.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:58<01:23, 27.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:58<01:23, 27.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:58<01:23, 27.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:58<01:24, 27.5MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:59<01:24, 27.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:59<01:22, 28.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:59<01:22, 28.0MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:59<01:23, 27.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:59<01:21, 28.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:59<01:21, 28.0MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [01:00<01:23, 27.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [01:00<01:21, 27.8MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [01:00<01:20, 28.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.93G [01:00<01:20, 28.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.67G/3.93G [01:00<01:21, 27.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [01:01<01:20, 28.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:01<01:20, 28.0MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:01<01:20, 27.9MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:01<01:24, 26.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:01<01:47, 20.8MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:02<01:57, 19.0MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:02<01:06, 33.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:02<01:11, 30.9MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [01:02<01:10, 31.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.72G/3.93G [01:02<01:13, 30.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:02<01:15, 29.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:02<01:17, 28.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:03<01:17, 28.2MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:03<01:16, 28.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:03<01:17, 28.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:03<01:17, 28.1MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:03<01:17, 28.1MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:04<01:18, 27.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.77G/3.93G [01:04<01:18, 27.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.77G/3.93G [01:04<01:16, 28.1MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:04<01:16, 28.0MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:04<01:16, 27.9MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:05<01:17, 27.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:05<01:16, 28.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:05<01:16, 28.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:05<01:16, 27.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:05<01:16, 27.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.82G/3.93G [01:05<01:16, 27.7MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:06<01:16, 27.7MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:06<01:21, 26.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:06<01:14, 28.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:06<01:13, 28.6MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:06<01:15, 28.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:06<01:38, 21.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:07<01:41, 20.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:07<01:34, 22.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:07<01:27, 23.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:07<01:22, 25.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:07<01:19, 25.9MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.87G/3.93G [01:08<01:18, 26.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [01:08<01:16, 26.9MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:08<01:15, 27.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:08<01:14, 27.4MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:08<01:14, 27.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:09<01:13, 27.6MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:09<01:13, 27.7MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:09<01:13, 27.7MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:09<01:12, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.92G/3.93G [01:09<01:12, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [01:09<01:12, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:10<01:12, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:10<01:12, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:10<01:11, 27.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:10<01:11, 27.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:10<01:11, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:11<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:11<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:11<01:10, 27.8MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:11<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:11<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [01:12<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [01:12<01:09, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:12<01:09, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:12<01:09, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [01:12<01:09, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [01:12<01:09, 27.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:13<01:08, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:13<01:08, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.93G [01:13<01:08, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [01:13<01:08, 27.8MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [01:13<01:08, 27.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:14<01:08, 27.8MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:14<01:08, 27.8MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [01:14<01:07, 28.0MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [01:14<01:07, 27.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [01:14<01:07, 27.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [01:15<01:07, 27.6MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:15<01:06, 28.0MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:15<01:07, 27.7MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [01:15<01:06, 28.0MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [01:15<01:06, 27.8MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.09G/3.93G [01:15<01:06, 28.0MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.09G/3.93G [01:16<01:05, 27.9MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:16<01:06, 27.8MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:16<01:05, 28.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [01:16<01:05, 28.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [01:16<01:05, 27.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:17<01:06, 27.4MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:17<01:04, 27.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [01:17<01:04, 28.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [01:17<01:05, 27.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [01:17<01:04, 27.8MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [01:18<01:03, 28.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [01:18<01:04, 27.5MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.16G/3.93G [01:18<01:04, 27.6MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.16G/3.93G [01:18<01:02, 28.3MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:18<01:02, 28.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:18<01:03, 27.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [01:19<01:02, 28.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [01:19<01:02, 28.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:19<01:02, 28.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:19<01:02, 27.7MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [01:19<01:02, 27.9MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [01:20<01:02, 27.9MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.21G/3.93G [01:20<01:01, 27.9MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.21G/3.93G [01:20<01:01, 27.8MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:20<01:02, 27.7MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:20<01:01, 27.6MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [01:21<01:00, 28.0MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [01:21<01:01, 27.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:21<01:00, 27.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:21<01:00, 28.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.25G/3.93G [01:21<01:00, 27.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.26G/3.93G [01:21<00:59, 28.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.26G/3.93G [01:22<01:00, 27.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:22<00:59, 28.0MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:22<00:59, 27.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [01:22<00:59, 28.0MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [01:22<00:59, 27.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:23<00:58, 28.0MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:23<00:59, 27.4MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [01:23<00:58, 27.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [01:23<00:58, 28.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.31G/3.93G [01:23<00:58, 27.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.31G/3.93G [01:24<00:57, 28.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:24<00:58, 27.5MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:24<00:57, 28.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:24<00:49, 32.4MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:24<00:55, 28.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:24<01:02, 25.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [01:24<00:59, 27.0MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [01:25<00:48, 32.6MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:25<00:55, 28.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:25<01:02, 25.3MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:25<00:59, 26.6MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.36G/3.93G [01:25<00:50, 31.3MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.36G/3.93G [01:25<00:57, 27.4MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [01:25<01:04, 24.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [01:26<00:57, 27.0MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:26<00:56, 27.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:26<00:48, 32.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:26<00:55, 28.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [01:26<01:01, 25.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [01:26<00:57, 27.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:26<00:48, 31.9MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:27<00:55, 27.8MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:27<01:01, 24.8MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.41G/3.93G [01:27<00:56, 27.1MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.93G [01:27<00:48, 31.7MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.93G [01:27<00:55, 27.5MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [01:27<01:01, 24.7MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [01:27<00:55, 27.3MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:28<00:48, 31.1MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:28<00:55, 27.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:28<01:01, 24.4MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [01:28<00:54, 27.7MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [01:28<00:46, 32.1MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:28<00:53, 27.8MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:28<00:59, 24.8MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:29<00:53, 27.5MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.46G/3.93G [01:29<00:47, 31.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.46G/3.93G [01:29<00:54, 27.3MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.46G/3.93G [01:29<00:59, 24.5MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:29<00:52, 27.7MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:29<00:45, 32.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:29<00:52, 27.8MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:30<00:58, 24.9MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:30<00:53, 27.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:30<00:52, 27.6MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:30<00:46, 31.0MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [01:30<00:53, 27.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [01:30<00:54, 26.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.51G/3.93G [01:30<00:48, 29.6MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.51G/3.93G [01:31<00:50, 28.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.51G/3.93G [01:31<00:57, 24.8MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:31<00:51, 27.6MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:31<00:44, 31.6MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:31<00:51, 27.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [01:31<01:07, 20.9MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [01:31<00:51, 27.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:32<00:43, 31.8MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:32<00:45, 30.8MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:32<01:09, 19.9MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [01:32<00:49, 28.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [01:32<00:45, 30.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.56G/3.93G [01:32<00:49, 27.7MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.56G/3.93G [01:33<00:45, 29.8MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:33<00:41, 33.3MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:33<00:46, 29.0MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:33<00:52, 26.0MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:33<01:04, 21.2MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:33<01:09, 19.5MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:34<01:12, 18.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [01:34<01:08, 19.7MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [01:34<01:05, 20.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:34<01:02, 21.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:34<01:01, 21.8MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:34<00:59, 22.2MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.61G/3.93G [01:35<00:58, 22.5MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.61G/3.93G [01:35<00:57, 22.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [01:35<00:57, 23.1MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [01:35<00:56, 23.3MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:35<00:55, 23.5MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:36<00:54, 23.7MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:36<00:49, 26.3MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:36<00:43, 29.6MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:36<00:49, 26.0MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:36<00:56, 22.9MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:36<00:52, 24.5MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:36<00:44, 28.7MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:37<00:50, 25.1MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:37<00:57, 22.1MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:37<00:52, 24.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:37<00:44, 28.6MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:37<00:50, 25.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:37<00:57, 22.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:37<00:50, 24.8MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:38<00:43, 29.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:38<00:49, 25.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:38<00:56, 22.3MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:38<00:49, 25.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:38<00:42, 29.2MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:38<00:48, 25.5MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:38<00:54, 22.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:39<00:48, 25.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:39<00:41, 29.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:39<00:47, 25.9MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [01:39<00:53, 22.8MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [01:39<00:51, 23.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:39<00:42, 28.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:39<00:43, 27.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:40<00:50, 24.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:40<00:46, 25.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:40<00:40, 29.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:40<00:45, 26.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [01:40<00:52, 22.8MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [01:40<00:45, 26.3MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.75G/3.93G [01:40<00:39, 29.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [01:41<00:45, 25.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [01:41<00:51, 22.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:41<00:43, 26.6MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:41<00:38, 30.3MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:41<00:44, 26.2MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:41<00:50, 23.2MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:41<00:43, 26.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:41<00:38, 29.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:42<00:44, 25.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:42<00:49, 23.0MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:42<00:42, 27.0MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.80G/3.93G [01:42<00:39, 28.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.80G/3.93G [01:42<00:44, 25.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.93G [01:42<00:42, 26.4MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:42<00:37, 30.0MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:43<00:43, 25.8MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:43<00:49, 22.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [01:43<00:41, 27.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [01:43<00:36, 30.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:43<00:42, 26.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:43<00:47, 23.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:43<00:40, 27.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:44<00:36, 30.3MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:44<00:41, 26.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:44<00:46, 23.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.85G/3.93G [01:44<00:39, 27.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.85G/3.93G [01:44<00:35, 30.0MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:44<00:41, 25.9MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:44<00:40, 26.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:44<00:36, 29.5MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:45<00:42, 25.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:45<00:41, 25.9MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:45<00:36, 29.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:45<00:42, 25.0MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:45<00:40, 25.9MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:45<00:36, 29.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:45<00:42, 24.9MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:45<00:40, 25.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:46<00:35, 29.2MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.90G/3.93G [01:46<00:41, 24.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.90G/3.93G [01:46<00:39, 25.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.90G/3.93G [01:46<00:35, 29.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:46<00:41, 24.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:46<00:39, 25.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:46<00:35, 29.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:47<00:40, 24.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:47<00:39, 25.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:47<00:35, 28.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:47<00:40, 24.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:47<00:38, 26.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:47<00:34, 28.7MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:47<00:40, 24.9MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:47<00:37, 26.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:47<00:34, 29.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.95G/3.93G [01:48<00:39, 25.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.95G/3.93G [01:48<00:37, 26.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.95G/3.93G [01:48<00:33, 29.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.96G/3.93G [01:48<00:38, 25.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.96G/3.93G [01:48<00:37, 26.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.96G/3.93G [01:48<00:33, 29.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:48<00:38, 25.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:48<00:36, 26.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:49<00:33, 29.0MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:49<00:38, 25.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:49<00:36, 26.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:49<00:32, 29.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:49<00:37, 25.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:49<00:35, 26.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:49<00:32, 29.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.00G/3.93G [01:49<00:37, 25.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.00G/3.93G [01:50<00:35, 26.5MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.00G/3.93G [01:50<00:31, 29.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:50<00:36, 25.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:50<00:34, 26.7MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:50<00:32, 28.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:50<00:36, 24.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:50<00:33, 27.0MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:50<00:30, 29.5MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:51<00:35, 25.5MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:51<00:33, 26.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:51<00:30, 29.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:51<00:35, 25.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:51<00:33, 27.0MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:51<00:30, 29.6MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.05G/3.93G [01:51<00:34, 25.5MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.05G/3.93G [01:51<00:32, 27.0MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.05G/3.93G [01:52<00:29, 29.5MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:52<00:34, 25.4MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:52<00:32, 27.3MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:52<00:29, 30.0MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:52<00:33, 25.9MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:52<00:31, 27.4MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:52<00:32, 26.3MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.08G/3.93G [01:52<00:34, 24.6MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.08G/3.93G [01:53<00:29, 28.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:53<00:26, 31.5MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:53<00:31, 26.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:53<00:30, 27.7MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.10G/3.93G [01:53<00:27, 30.4MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.10G/3.93G [01:53<00:31, 26.2MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.10G/3.93G [01:53<00:30, 27.5MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:53<00:27, 30.5MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:54<00:31, 26.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:54<00:30, 27.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:54<00:26, 30.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:54<00:31, 26.1MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:54<00:29, 27.2MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:54<00:26, 30.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:54<00:30, 26.0MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:54<00:29, 27.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:55<00:26, 30.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:55<00:30, 26.0MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:55<00:28, 27.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:55<00:26, 30.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:55<00:30, 26.0MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:55<00:28, 27.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:55<00:25, 30.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:55<00:29, 26.0MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:56<00:28, 27.3MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:56<00:25, 29.9MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:56<00:29, 25.8MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:56<00:27, 27.4MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:56<00:25, 29.9MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:56<00:29, 25.8MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:56<00:27, 27.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:56<00:24, 30.1MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:57<00:28, 25.9MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.20G/3.93G [01:57<00:26, 27.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [01:57<00:24, 30.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [01:57<00:28, 25.9MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:57<00:26, 27.6MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:57<00:24, 29.6MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:57<00:28, 25.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [01:57<00:25, 27.9MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [01:58<00:24, 29.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [01:58<00:28, 25.1MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:58<00:24, 28.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:58<00:23, 29.7MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:58<00:27, 25.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:58<00:24, 28.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:58<00:23, 29.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:58<00:27, 25.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:59<00:24, 28.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:59<00:22, 29.8MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:59<00:26, 25.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [01:59<00:23, 28.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [01:59<00:22, 29.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:59<00:26, 25.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:59<00:23, 28.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:59<00:22, 29.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [02:00<00:25, 25.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [02:00<00:23, 28.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [02:00<00:21, 29.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [02:00<00:25, 25.4MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [02:00<00:22, 28.5MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [02:00<00:21, 29.5MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [02:00<00:25, 25.2MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [02:00<00:22, 28.6MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [02:01<00:21, 29.5MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [02:01<00:24, 25.2MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [02:01<00:21, 28.7MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [02:01<00:21, 29.4MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [02:01<00:24, 25.2MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [02:01<00:21, 28.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [02:01<00:20, 29.5MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [02:01<00:24, 25.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [02:02<00:20, 28.8MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [02:02<00:20, 29.4MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [02:02<00:23, 25.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [02:02<00:20, 28.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [02:02<00:20, 29.4MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [02:02<00:23, 25.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [02:02<00:20, 28.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [02:03<00:23, 25.0MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [02:03<00:22, 25.8MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [02:03<00:18, 30.2MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [02:03<00:18, 30.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [02:03<00:21, 26.1MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [02:03<00:19, 29.4MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:03<00:18, 29.9MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:03<00:21, 25.4MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:03<00:18, 29.1MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [02:04<00:18, 29.6MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [02:04<00:21, 25.3MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.39G/3.93G [02:04<00:18, 29.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:04<00:18, 29.5MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:04<00:21, 25.2MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:04<00:18, 29.0MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:04<00:17, 29.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:04<00:20, 25.2MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:05<00:17, 28.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [02:05<00:17, 29.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [02:05<00:20, 25.2MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.43G/3.93G [02:05<00:17, 29.0MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.43G/3.93G [02:05<00:17, 29.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.43G/3.93G [02:05<00:19, 25.2MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.44G/3.93G [02:05<00:17, 28.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.44G/3.93G [02:05<00:16, 29.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.44G/3.93G [02:06<00:19, 25.1MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:06<00:16, 29.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:06<00:16, 29.5MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:06<00:19, 25.2MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:06<00:16, 29.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:06<00:16, 29.4MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:06<00:18, 25.2MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:06<00:16, 29.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:07<00:15, 29.4MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:07<00:18, 25.2MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:07<00:15, 29.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:07<00:15, 29.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:07<00:17, 25.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.49G/3.93G [02:07<00:15, 29.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.49G/3.93G [02:07<00:15, 29.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.49G/3.93G [02:07<00:17, 25.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:08<00:15, 29.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:08<00:14, 29.5MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:08<00:17, 25.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:08<00:14, 29.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:08<00:14, 29.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:08<00:16, 25.1MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [02:08<00:14, 29.1MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [02:08<00:14, 29.4MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:09<00:16, 25.2MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:09<00:13, 29.1MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:09<00:13, 29.3MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.54G/3.93G [02:09<00:15, 25.2MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.54G/3.93G [02:09<00:13, 29.1MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.54G/3.93G [02:09<00:13, 29.4MiB/s] > Failed to download the model file to /home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 754, in _error_catcher
    yield
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 900, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
urllib3.exceptions.IncompleteRead: IncompleteRead(3545063888 bytes read, 389470645 more expected)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/models.py", line 820, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 1066, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 983, in read
    data = self._raw_read(amt)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 878, in _raw_read
    with self._error_catcher():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/response.py", line 778, in _error_catcher
    raise ProtocolError(arg, e) from e
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(3545063888 bytes read, 389470645 more expected)', IncompleteRead(3545063888 bytes read, 389470645 more expected))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 19, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/bark").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 411, in download_model
    self.create_dir_and_download_model(model_name, model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 352, in create_dir_and_download_model
    raise e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 347, in create_dir_and_download_model
    self._download_hf_model(model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 237, in _download_hf_model
    self._download_model_files(model_item["hf_url"], output_path, self.progress_bar)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 609, in _download_model_files
    for data in r.iter_content(block_size):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/models.py", line 822, in generate
    raise ChunkedEncodingError(e)
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(3545063888 bytes read, 389470645 more expected)', IncompleteRead(3545063888 bytes read, 389470645 more expected))

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.55G/3.93G [02:10<00:14, 27.2MiB/s]
 > Downloading model to /home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--bark

  0%|          | 0.00/3.93G [00:00<?, ?iB/s]
  0%|          | 4.68M/3.93G [00:00<01:25, 45.9MiB/s]
  0%|          | 17.1M/3.93G [00:00<00:42, 91.7MiB/s]
  1%|          | 27.0M/3.93G [00:00<00:41, 95.0MiB/s]
  1%|          | 36.8M/3.93G [00:00<00:40, 96.0MiB/s]
  1%|â–         | 50.5M/3.93G [00:00<00:35, 111MiB/s] 
  2%|â–         | 62.0M/3.93G [00:00<00:36, 105MiB/s]
  2%|â–         | 74.2M/3.93G [00:00<00:35, 110MiB/s]
  2%|â–         | 85.9M/3.93G [00:00<00:34, 112MiB/s]
  2%|â–         | 97.2M/3.93G [00:00<00:34, 111MiB/s]
  3%|â–Ž         | 109M/3.93G [00:01<00:33, 113MiB/s] 
  3%|â–Ž         | 120M/3.93G [00:01<00:34, 111MiB/s]
  3%|â–Ž         | 132M/3.93G [00:01<00:33, 113MiB/s]
  4%|â–Ž         | 143M/3.93G [00:01<00:34, 111MiB/s]
  4%|â–         | 155M/3.93G [00:01<00:33, 113MiB/s]
  4%|â–         | 166M/3.93G [00:01<00:34, 110MiB/s]
  5%|â–         | 179M/3.93G [00:01<00:33, 113MiB/s]
  5%|â–         | 190M/3.93G [00:01<00:35, 106MiB/s]
  5%|â–Œ         | 203M/3.93G [00:01<00:32, 114MiB/s]
  5%|â–Œ         | 215M/3.93G [00:01<00:34, 108MiB/s]
  6%|â–Œ         | 228M/3.93G [00:02<00:32, 114MiB/s]
  6%|â–Œ         | 240M/3.93G [00:02<00:32, 115MiB/s]
  6%|â–‹         | 251M/3.93G [00:02<00:32, 113MiB/s]
  7%|â–‹         | 263M/3.93G [00:02<00:32, 114MiB/s]
  7%|â–‹         | 275M/3.93G [00:02<00:32, 112MiB/s]
  7%|â–‹         | 286M/3.93G [00:02<00:32, 114MiB/s]
  8%|â–Š         | 298M/3.93G [00:02<00:32, 112MiB/s]
  8%|â–Š         | 309M/3.93G [00:02<00:31, 113MiB/s]
  8%|â–Š         | 321M/3.93G [00:02<00:32, 111MiB/s]
  8%|â–Š         | 333M/3.93G [00:03<00:31, 113MiB/s]
  9%|â–Š         | 344M/3.93G [00:03<00:32, 109MiB/s]
  9%|â–‰         | 357M/3.93G [00:03<00:31, 114MiB/s]
  9%|â–‰         | 368M/3.93G [00:03<00:32, 108MiB/s]
 10%|â–‰         | 382M/3.93G [00:03<00:30, 115MiB/s]
 10%|â–‰         | 393M/3.93G [00:03<00:30, 116MiB/s]
 10%|â–ˆ         | 405M/3.93G [00:03<00:31, 113MiB/s]
 11%|â–ˆ         | 417M/3.93G [00:03<00:30, 114MiB/s]
 11%|â–ˆ         | 428M/3.93G [00:03<00:31, 112MiB/s]
 11%|â–ˆ         | 440M/3.93G [00:03<00:30, 114MiB/s]
 11%|â–ˆâ–        | 451M/3.93G [00:04<00:31, 112MiB/s]
 12%|â–ˆâ–        | 463M/3.93G [00:04<00:30, 113MiB/s]
 12%|â–ˆâ–        | 474M/3.93G [00:04<00:32, 106MiB/s]
 12%|â–ˆâ–        | 487M/3.93G [00:04<00:30, 112MiB/s]
 13%|â–ˆâ–Ž        | 499M/3.93G [00:04<00:32, 105MiB/s]
 13%|â–ˆâ–Ž        | 512M/3.93G [00:04<00:30, 112MiB/s]
 13%|â–ˆâ–Ž        | 523M/3.93G [00:04<00:30, 114MiB/s]
 14%|â–ˆâ–Ž        | 535M/3.93G [00:04<00:30, 112MiB/s]
 14%|â–ˆâ–        | 547M/3.93G [00:04<00:29, 113MiB/s]
 14%|â–ˆâ–        | 558M/3.93G [00:05<00:30, 111MiB/s]
 14%|â–ˆâ–        | 570M/3.93G [00:05<00:29, 113MiB/s]
 15%|â–ˆâ–        | 581M/3.93G [00:05<00:30, 112MiB/s]
 15%|â–ˆâ–Œ        | 593M/3.93G [00:05<00:29, 113MiB/s]
 15%|â–ˆâ–Œ        | 604M/3.93G [00:05<00:29, 111MiB/s]
 16%|â–ˆâ–Œ        | 616M/3.93G [00:05<00:29, 112MiB/s]
 16%|â–ˆâ–Œ        | 627M/3.93G [00:05<00:29, 110MiB/s]
 16%|â–ˆâ–Œ        | 638M/3.93G [00:05<00:30, 108MiB/s]
 17%|â–ˆâ–‹        | 650M/3.93G [00:05<00:29, 111MiB/s]
 17%|â–ˆâ–‹        | 661M/3.93G [00:05<00:29, 110MiB/s]
 17%|â–ˆâ–‹        | 673M/3.93G [00:06<00:29, 112MiB/s]
 17%|â–ˆâ–‹        | 684M/3.93G [00:06<00:29, 111MiB/s]
 18%|â–ˆâ–Š        | 695M/3.93G [00:06<00:29, 112MiB/s]
 18%|â–ˆâ–Š        | 706M/3.93G [00:06<00:30, 107MiB/s]
 18%|â–ˆâ–Š        | 717M/3.93G [00:06<00:30, 106MiB/s]
 19%|â–ˆâ–Š        | 729M/3.93G [00:06<00:28, 111MiB/s]
 19%|â–ˆâ–‰        | 741M/3.93G [00:06<00:28, 112MiB/s]
 19%|â–ˆâ–‰        | 752M/3.93G [00:06<00:28, 111MiB/s]
 19%|â–ˆâ–‰        | 764M/3.93G [00:06<00:28, 113MiB/s]
 20%|â–ˆâ–‰        | 775M/3.93G [00:07<00:28, 111MiB/s]
 20%|â–ˆâ–‰        | 787M/3.93G [00:07<00:27, 113MiB/s]
 20%|â–ˆâ–ˆ        | 798M/3.93G [00:07<00:28, 108MiB/s]
 21%|â–ˆâ–ˆ        | 811M/3.93G [00:07<00:27, 114MiB/s]
 21%|â–ˆâ–ˆ        | 823M/3.93G [00:07<00:27, 115MiB/s]
 21%|â–ˆâ–ˆ        | 834M/3.93G [00:07<00:27, 112MiB/s]
 21%|â–ˆâ–ˆâ–       | 846M/3.93G [00:07<00:27, 114MiB/s]
 22%|â–ˆâ–ˆâ–       | 857M/3.93G [00:07<00:27, 112MiB/s]
 22%|â–ˆâ–ˆâ–       | 869M/3.93G [00:07<00:26, 114MiB/s]
 22%|â–ˆâ–ˆâ–       | 880M/3.93G [00:07<00:27, 111MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 893M/3.93G [00:08<00:26, 115MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 904M/3.93G [00:08<00:27, 110MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 917M/3.93G [00:08<00:26, 115MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 929M/3.93G [00:08<00:25, 116MiB/s]
 24%|â–ˆâ–ˆâ–       | 940M/3.93G [00:08<00:26, 112MiB/s]
 24%|â–ˆâ–ˆâ–       | 953M/3.93G [00:08<00:25, 116MiB/s]
 25%|â–ˆâ–ˆâ–       | 965M/3.93G [00:08<00:25, 116MiB/s]
 25%|â–ˆâ–ˆâ–       | 976M/3.93G [00:08<00:26, 114MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 988M/3.93G [00:08<00:25, 115MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 999M/3.93G [00:08<00:26, 110MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:09<00:26, 112MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:09<00:27, 107MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:09<00:25, 114MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:09<00:25, 115MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:09<00:25, 113MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:09<00:25, 114MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:09<00:26, 109MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:09<00:25, 112MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:09<00:25, 111MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:10<00:25, 113MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:10<00:25, 109MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:10<00:24, 113MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:10<00:25, 108MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:10<00:24, 115MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:10<00:25, 109MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:10<00:23, 115MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:10<00:23, 115MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:10<00:23, 115MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:10<00:23, 116MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:11<00:23, 113MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:11<00:23, 114MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:11<00:23, 112MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:11<00:23, 113MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:11<00:23, 112MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:11<00:25, 102MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:11<00:25, 103MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:11<00:24, 107MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.33G/3.93G [00:11<00:24, 106MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:12<00:23, 110MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:12<00:24, 106MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:12<00:22, 115MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.38G/3.93G [00:12<00:23, 109MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:12<00:22, 116MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:12<00:21, 116MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:12<00:22, 113MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:12<00:21, 115MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:12<00:22, 111MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:13<00:21, 114MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:13<00:22, 109MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:13<00:21, 115MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:13<00:21, 116MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:13<00:22, 110MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:13<00:21, 112MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:13<00:21, 113MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:13<00:21, 114MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:13<00:21, 110MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:13<00:20, 114MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:14<00:21, 109MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:14<00:20, 115MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:14<00:20, 116MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:14<00:38, 60.0MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:14<00:31, 73.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:14<00:28, 82.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:14<00:25, 90.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:15<00:36, 63.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [00:15<00:30, 73.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [00:15<00:27, 82.8MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [00:15<00:25, 89.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [00:15<00:23, 96.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [00:15<00:21, 102MiB/s] 
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [00:15<00:21, 103MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [00:16<00:20, 107MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [00:16<00:20, 107MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [00:16<00:19, 110MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.77G/3.93G [00:16<00:20, 106MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [00:16<00:19, 110MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [00:16<00:19, 107MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [00:16<00:19, 112MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [00:16<00:18, 113MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [00:16<00:18, 112MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [00:16<00:18, 113MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [00:17<00:19, 108MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [00:17<00:18, 115MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [00:17<00:17, 116MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [00:17<00:18, 113MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [00:17<00:17, 114MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [00:17<00:18, 113MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [00:17<00:17, 114MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [00:17<00:17, 112MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [00:17<00:17, 113MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [00:17<00:17, 114MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.97G/3.93G [00:18<00:17, 114MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [00:18<00:16, 115MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [00:18<00:17, 114MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [00:18<00:16, 115MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [00:18<00:17, 110MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [00:18<00:16, 115MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [00:18<00:16, 116MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [00:18<00:16, 116MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [00:18<00:16, 116MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [00:19<00:16, 116MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [00:19<00:16, 114MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [00:19<00:16, 115MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [00:19<00:16, 113MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [00:19<00:15, 114MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [00:19<00:16, 110MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [00:19<00:15, 114MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [00:19<00:16, 108MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [00:19<00:15, 115MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [00:19<00:15, 116MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [00:20<00:15, 115MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [00:20<00:14, 116MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.21G/3.93G [00:20<00:15, 113MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [00:20<00:14, 114MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [00:20<00:14, 115MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.25G/3.93G [00:20<00:14, 113MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.26G/3.93G [00:20<00:14, 114MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [00:20<00:14, 112MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [00:20<00:14, 113MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [00:20<00:15, 109MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.31G/3.93G [00:21<00:14, 114MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [00:21<00:14, 115MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [00:21<00:14, 114MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [00:21<00:13, 115MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.36G/3.93G [00:21<00:14, 112MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [00:21<00:13, 114MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [00:21<00:14, 109MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [00:21<00:13, 114MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [00:21<00:14, 108MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [00:22<00:13, 115MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [00:22<00:13, 116MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [00:22<00:12, 116MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [00:22<00:12, 116MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.46G/3.93G [00:22<00:12, 114MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [00:22<00:12, 115MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [00:22<00:13, 110MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [00:22<00:12, 116MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.51G/3.93G [00:22<00:12, 116MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [00:22<00:12, 113MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [00:23<00:12, 114MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [00:23<00:12, 112MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.56G/3.93G [00:23<00:12, 114MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [00:23<00:12, 112MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [00:23<00:11, 114MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [00:23<00:12, 111MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [00:23<00:11, 114MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [00:23<00:12, 110MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [00:23<00:11, 115MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [00:24<00:11, 116MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [00:24<00:11, 116MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [00:24<00:10, 116MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [00:24<00:11, 113MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [00:24<00:10, 116MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [00:24<00:11, 111MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [00:24<00:10, 115MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [00:24<00:11, 110MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [00:24<00:10, 115MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [00:24<00:10, 116MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [00:25<00:10, 113MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [00:25<00:10, 114MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [00:25<00:10, 112MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [00:25<00:10, 114MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [00:25<00:10, 112MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [00:25<00:09, 115MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [00:25<00:10, 110MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [00:25<00:09, 114MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.85G/3.93G [00:25<00:09, 115MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [00:25<00:09, 113MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [00:26<00:09, 114MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [00:26<00:09, 112MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.90G/3.93G [00:26<00:09, 113MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [00:26<00:09, 111MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [00:26<00:09, 106MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [00:26<00:08, 113MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.95G/3.93G [00:26<00:08, 114MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.96G/3.93G [00:26<00:08, 113MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [00:26<00:08, 115MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [00:27<00:08, 112MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [00:27<00:13, 70.3MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [00:27<00:11, 80.0MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [00:27<00:10, 85.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [00:27<00:09, 93.3MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [00:27<00:09, 95.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.05G/3.93G [00:27<00:08, 103MiB/s] 
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [00:27<00:08, 101MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [00:28<00:07, 109MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [00:28<00:08, 105MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.10G/3.93G [00:28<00:07, 110MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [00:28<00:07, 109MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [00:28<00:07, 107MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [00:28<00:07, 111MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [00:28<00:07, 110MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [00:28<00:06, 112MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [00:28<00:06, 111MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [00:29<00:06, 113MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [00:29<00:06, 109MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [00:29<00:06, 111MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [00:29<00:06, 106MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [00:29<00:06, 104MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [00:29<00:06, 106MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [00:29<00:06, 114MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [00:29<00:05, 115MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [00:29<00:06, 109MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [00:29<00:05, 112MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [00:30<00:05, 110MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [00:30<00:05, 112MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [00:30<00:05, 111MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [00:30<00:05, 111MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [00:30<00:05, 101MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [00:30<00:05, 109MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [00:30<00:05, 107MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [00:30<00:05, 110MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [00:30<00:04, 109MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [00:31<00:04, 112MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [00:31<00:04, 108MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [00:31<00:04, 113MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.44G/3.93G [00:31<00:04, 108MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [00:31<00:04, 114MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [00:31<00:04, 115MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [00:31<00:04, 110MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [00:31<00:04, 112MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.49G/3.93G [00:31<00:03, 111MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [00:31<00:03, 113MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [00:32<00:03, 111MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [00:32<00:03, 113MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.54G/3.93G [00:32<00:03, 111MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.55G/3.93G [00:32<00:03, 113MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.56G/3.93G [00:32<00:03, 110MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.58G/3.93G [00:32<00:03, 114MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.59G/3.93G [00:32<00:03, 109MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.60G/3.93G [00:32<00:02, 115MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.61G/3.93G [00:32<00:02, 109MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.63G/3.93G [00:33<00:02, 116MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.64G/3.93G [00:33<00:02, 116MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.65G/3.93G [00:33<00:02, 113MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.66G/3.93G [00:33<00:02, 114MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.67G/3.93G [00:33<00:02, 112MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.68G/3.93G [00:33<00:02, 114MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.70G/3.93G [00:33<00:02, 109MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.71G/3.93G [00:33<00:02, 111MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.72G/3.93G [00:33<00:01, 110MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.73G/3.93G [00:33<00:01, 112MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.74G/3.93G [00:34<00:01, 109MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.75G/3.93G [00:34<00:01, 113MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.77G/3.93G [00:34<00:01, 108MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.78G/3.93G [00:34<00:01, 114MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.79G/3.93G [00:34<00:01, 108MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.80G/3.93G [00:34<00:01, 115MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.82G/3.93G [00:34<00:01, 116MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.83G/3.93G [00:34<00:00, 113MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.84G/3.93G [00:34<00:00, 114MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.85G/3.93G [00:35<00:00, 112MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.86G/3.93G [00:35<00:00, 114MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.87G/3.93G [00:35<00:00, 112MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.88G/3.93G [00:35<00:00, 113MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.90G/3.93G [00:35<00:00, 114MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.91G/3.93G [00:35<00:00, 113MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.92G/3.93G [00:35<00:00, 114MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.93G/3.93G [00:35<00:00, 112MiB/s]

  0%|          | 0.00/3.74G [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.93G/3.93G [00:37<00:00, 106MiB/s]


  0%|          | 202k/3.74G [00:00<57:40, 1.08MiB/s][A

  0%|          | 640k/3.74G [00:00<34:20, 1.82MiB/s][A

  0%|          | 1.51M/3.74G [00:00<20:06, 3.10MiB/s][A

  0%|          | 3.25M/3.74G [00:00<11:16, 5.53MiB/s][A

  0%|          | 6.72M/3.74G [00:00<06:07, 10.2MiB/s][A

  0%|          | 11.9M/3.74G [00:01<03:51, 16.1MiB/s][A

  0%|          | 17.1M/3.74G [00:01<03:07, 19.9MiB/s][A

  1%|          | 22.3M/3.74G [00:01<02:46, 22.4MiB/s][A

  1%|          | 27.6M/3.74G [00:01<02:35, 23.9MiB/s][A

  1%|          | 32.8M/3.74G [00:01<02:27, 25.2MiB/s][A

  1%|          | 38.0M/3.74G [00:02<02:22, 26.0MiB/s][A

  1%|          | 43.2M/3.74G [00:02<02:19, 26.5MiB/s][A

  1%|â–         | 48.4M/3.74G [00:02<02:18, 26.7MiB/s][A

  1%|â–         | 53.5M/3.74G [00:02<02:16, 27.1MiB/s][A

  2%|â–         | 58.7M/3.74G [00:02<02:15, 27.2MiB/s][A

  2%|â–         | 63.9M/3.74G [00:03<02:14, 27.3MiB/s][A

  2%|â–         | 69.1M/3.74G [00:03<02:13, 27.4MiB/s][A

  2%|â–         | 74.3M/3.74G [00:03<02:13, 27.5MiB/s][A

  2%|â–         | 79.5M/3.74G [00:03<02:13, 27.5MiB/s][A

  2%|â–         | 84.6M/3.74G [00:03<02:13, 27.5MiB/s][A

  2%|â–         | 89.8M/3.74G [00:03<02:12, 27.5MiB/s][A

  3%|â–Ž         | 95.0M/3.74G [00:04<02:12, 27.5MiB/s][A

  3%|â–Ž         | 100M/3.74G [00:04<02:12, 27.5MiB/s] [A

  3%|â–Ž         | 105M/3.74G [00:04<02:11, 27.6MiB/s][A

  3%|â–Ž         | 111M/3.74G [00:04<02:11, 27.6MiB/s][A

  3%|â–Ž         | 116M/3.74G [00:04<02:11, 27.6MiB/s][A

  3%|â–Ž         | 121M/3.74G [00:05<02:11, 27.5MiB/s][A

  3%|â–Ž         | 126M/3.74G [00:05<02:11, 27.6MiB/s][A

  4%|â–Ž         | 131M/3.74G [00:05<02:10, 27.6MiB/s][A

  4%|â–Ž         | 137M/3.74G [00:05<02:10, 27.6MiB/s][A

  4%|â–         | 142M/3.74G [00:05<02:10, 27.7MiB/s][A

  4%|â–         | 147M/3.74G [00:06<02:10, 27.5MiB/s][A

  4%|â–         | 152M/3.74G [00:06<02:09, 27.8MiB/s][A

  4%|â–         | 157M/3.74G [00:06<02:09, 27.6MiB/s][A

  4%|â–         | 162M/3.74G [00:06<02:10, 27.5MiB/s][A

  4%|â–         | 168M/3.74G [00:06<02:10, 27.5MiB/s][A

  5%|â–         | 173M/3.74G [00:06<02:09, 27.6MiB/s][A

  5%|â–         | 178M/3.74G [00:07<02:08, 27.6MiB/s][A

  5%|â–         | 183M/3.74G [00:07<02:09, 27.6MiB/s][A

  5%|â–Œ         | 188M/3.74G [00:07<02:08, 27.6MiB/s][A

  5%|â–Œ         | 194M/3.74G [00:07<02:08, 27.6MiB/s][A

  5%|â–Œ         | 199M/3.74G [00:07<02:08, 27.5MiB/s][A

  5%|â–Œ         | 204M/3.74G [00:08<02:08, 27.6MiB/s][A

  6%|â–Œ         | 209M/3.74G [00:08<02:08, 27.5MiB/s][A

  6%|â–Œ         | 214M/3.74G [00:08<02:08, 27.5MiB/s][A

  6%|â–Œ         | 220M/3.74G [00:08<02:07, 27.6MiB/s][A

  6%|â–Œ         | 225M/3.74G [00:08<02:07, 27.6MiB/s][A

  6%|â–Œ         | 230M/3.74G [00:09<02:07, 27.5MiB/s][A

  6%|â–‹         | 235M/3.74G [00:09<02:06, 27.6MiB/s][A

  6%|â–‹         | 240M/3.74G [00:09<02:06, 27.7MiB/s][A

  7%|â–‹         | 246M/3.74G [00:09<02:06, 27.7MiB/s][A

  7%|â–‹         | 251M/3.74G [00:09<02:06, 27.7MiB/s][A

  7%|â–‹         | 256M/3.74G [00:09<02:06, 27.5MiB/s][A

  7%|â–‹         | 261M/3.74G [00:10<02:06, 27.6MiB/s][A

  7%|â–‹         | 266M/3.74G [00:10<01:51, 31.3MiB/s][A

  7%|â–‹         | 269M/3.74G [00:10<01:56, 29.8MiB/s][A

  7%|â–‹         | 273M/3.74G [00:10<02:09, 26.7MiB/s][A

  7%|â–‹         | 277M/3.74G [00:10<02:11, 26.3MiB/s][A

  8%|â–Š         | 282M/3.74G [00:10<02:09, 26.7MiB/s][A

  8%|â–Š         | 287M/3.74G [00:11<02:07, 27.0MiB/s][A

  8%|â–Š         | 292M/3.74G [00:11<02:06, 27.2MiB/s][A

  8%|â–Š         | 298M/3.74G [00:11<02:06, 27.3MiB/s][A

  8%|â–Š         | 303M/3.74G [00:11<02:05, 27.4MiB/s][A

  8%|â–Š         | 308M/3.74G [00:11<02:04, 27.5MiB/s][A

  8%|â–Š         | 313M/3.74G [00:12<02:04, 27.6MiB/s][A

  9%|â–Š         | 318M/3.74G [00:12<02:03, 27.7MiB/s][A

  9%|â–Š         | 324M/3.74G [00:12<02:03, 27.6MiB/s][A

  9%|â–‰         | 329M/3.74G [00:12<02:04, 27.5MiB/s][A

  9%|â–‰         | 334M/3.74G [00:12<02:02, 27.8MiB/s][A

  9%|â–‰         | 339M/3.74G [00:12<02:02, 27.7MiB/s][A

  9%|â–‰         | 344M/3.74G [00:13<02:02, 27.7MiB/s][A

  9%|â–‰         | 350M/3.74G [00:13<02:02, 27.7MiB/s][A

  9%|â–‰         | 355M/3.74G [00:13<02:02, 27.7MiB/s][A

 10%|â–‰         | 360M/3.74G [00:13<02:01, 27.7MiB/s][A

 10%|â–‰         | 365M/3.74G [00:13<02:01, 27.7MiB/s][A

 10%|â–‰         | 370M/3.74G [00:14<02:01, 27.7MiB/s][A

 10%|â–ˆ         | 376M/3.74G [00:14<02:01, 27.7MiB/s][A

 10%|â–ˆ         | 381M/3.74G [00:14<02:01, 27.7MiB/s][A

 10%|â–ˆ         | 386M/3.74G [00:14<02:01, 27.5MiB/s][A

 10%|â–ˆ         | 391M/3.74G [00:14<02:00, 27.8MiB/s][A

 11%|â–ˆ         | 397M/3.74G [00:15<02:00, 27.7MiB/s][A

 11%|â–ˆ         | 402M/3.74G [00:15<02:01, 27.5MiB/s][A

 11%|â–ˆ         | 407M/3.74G [00:15<02:00, 27.6MiB/s][A

 11%|â–ˆ         | 412M/3.74G [00:15<01:59, 27.8MiB/s][A

 11%|â–ˆ         | 417M/3.74G [00:15<01:59, 27.8MiB/s][A

 11%|â–ˆâ–        | 423M/3.74G [00:15<02:00, 27.5MiB/s][A

 11%|â–ˆâ–        | 428M/3.74G [00:16<01:59, 27.8MiB/s][A

 12%|â–ˆâ–        | 433M/3.74G [00:16<01:59, 27.7MiB/s][A

 12%|â–ˆâ–        | 438M/3.74G [00:16<01:59, 27.6MiB/s][A

 12%|â–ˆâ–        | 443M/3.74G [00:16<01:59, 27.7MiB/s][A

 12%|â–ˆâ–        | 449M/3.74G [00:16<01:58, 27.7MiB/s][A

 12%|â–ˆâ–        | 454M/3.74G [00:17<01:58, 27.7MiB/s][A

 12%|â–ˆâ–        | 459M/3.74G [00:17<01:58, 27.6MiB/s][A

 12%|â–ˆâ–        | 464M/3.74G [00:17<01:59, 27.5MiB/s][A

 13%|â–ˆâ–Ž        | 469M/3.74G [00:17<01:58, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 474M/3.74G [00:17<01:58, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 480M/3.74G [00:18<01:58, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 485M/3.74G [00:18<01:58, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 490M/3.74G [00:18<01:57, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 495M/3.74G [00:18<01:57, 27.6MiB/s][A

 13%|â–ˆâ–Ž        | 500M/3.74G [00:18<01:57, 27.6MiB/s][A

 14%|â–ˆâ–Ž        | 506M/3.74G [00:19<01:57, 27.5MiB/s][A

 14%|â–ˆâ–Ž        | 511M/3.74G [00:19<01:56, 27.7MiB/s][A

 14%|â–ˆâ–        | 516M/3.74G [00:19<01:56, 27.7MiB/s][A

 14%|â–ˆâ–        | 521M/3.74G [00:19<01:56, 27.7MiB/s][A

 14%|â–ˆâ–        | 526M/3.74G [00:19<01:56, 27.6MiB/s][A

 14%|â–ˆâ–        | 532M/3.74G [00:19<01:55, 27.7MiB/s][A

 14%|â–ˆâ–        | 537M/3.74G [00:20<01:55, 27.7MiB/s][A

 14%|â–ˆâ–        | 542M/3.74G [00:20<01:55, 27.7MiB/s][A

 15%|â–ˆâ–        | 547M/3.74G [00:20<01:39, 32.0MiB/s][A

 15%|â–ˆâ–        | 551M/3.74G [00:20<01:52, 28.3MiB/s][A

 15%|â–ˆâ–        | 554M/3.74G [00:20<02:01, 26.2MiB/s][A

 15%|â–ˆâ–        | 558M/3.74G [00:20<02:00, 26.5MiB/s][A

 15%|â–ˆâ–Œ        | 563M/3.74G [00:20<01:39, 31.9MiB/s][A

 15%|â–ˆâ–Œ        | 566M/3.74G [00:21<01:49, 29.1MiB/s][A

 15%|â–ˆâ–Œ        | 569M/3.74G [00:21<02:04, 25.4MiB/s][A

 15%|â–ˆâ–Œ        | 573M/3.74G [00:21<02:02, 26.0MiB/s][A

 15%|â–ˆâ–Œ        | 578M/3.74G [00:21<01:59, 26.5MiB/s][A

 16%|â–ˆâ–Œ        | 584M/3.74G [00:21<01:57, 27.0MiB/s][A

 16%|â–ˆâ–Œ        | 589M/3.74G [00:22<01:57, 26.9MiB/s][A

 16%|â–ˆâ–Œ        | 594M/3.74G [00:22<01:54, 27.4MiB/s][A

 16%|â–ˆâ–Œ        | 599M/3.74G [00:22<01:54, 27.4MiB/s][A

 16%|â–ˆâ–Œ        | 604M/3.74G [00:22<01:53, 27.5MiB/s][A

 16%|â–ˆâ–‹        | 610M/3.74G [00:22<01:53, 27.6MiB/s][A

 16%|â–ˆâ–‹        | 615M/3.74G [00:22<01:53, 27.5MiB/s][A

 17%|â–ˆâ–‹        | 620M/3.74G [00:23<01:53, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 625M/3.74G [00:23<01:52, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 630M/3.74G [00:23<01:52, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 636M/3.74G [00:23<01:52, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 641M/3.74G [00:23<01:52, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 646M/3.74G [00:24<01:52, 27.6MiB/s][A

 17%|â–ˆâ–‹        | 651M/3.74G [00:24<01:52, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 656M/3.74G [00:24<01:51, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 662M/3.74G [00:24<01:51, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 667M/3.74G [00:24<01:51, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 672M/3.74G [00:25<01:51, 27.7MiB/s][A

 18%|â–ˆâ–Š        | 677M/3.74G [00:25<01:51, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 682M/3.74G [00:25<01:50, 27.7MiB/s][A

 18%|â–ˆâ–Š        | 688M/3.74G [00:25<01:50, 27.7MiB/s][A

 19%|â–ˆâ–Š        | 693M/3.74G [00:25<01:50, 27.7MiB/s][A

 19%|â–ˆâ–Š        | 698M/3.74G [00:25<01:49, 27.7MiB/s][A

 19%|â–ˆâ–‰        | 703M/3.74G [00:26<01:49, 27.7MiB/s][A

 19%|â–ˆâ–‰        | 708M/3.74G [00:26<01:49, 27.7MiB/s][A

 19%|â–ˆâ–‰        | 714M/3.74G [00:26<01:50, 27.5MiB/s][A

 19%|â–ˆâ–‰        | 719M/3.74G [00:26<01:48, 27.8MiB/s][A

 19%|â–ˆâ–‰        | 724M/3.74G [00:26<01:34, 31.8MiB/s][A

 19%|â–ˆâ–‰        | 727M/3.74G [00:26<01:46, 28.4MiB/s][A

 20%|â–ˆâ–‰        | 730M/3.74G [00:27<01:58, 25.3MiB/s][A

 20%|â–ˆâ–‰        | 734M/3.74G [00:27<01:52, 26.8MiB/s][A

 20%|â–ˆâ–‰        | 739M/3.74G [00:27<01:35, 31.6MiB/s][A

 20%|â–ˆâ–‰        | 743M/3.74G [00:27<01:47, 27.9MiB/s][A

 20%|â–ˆâ–‰        | 746M/3.74G [00:27<02:01, 24.7MiB/s][A

 20%|â–ˆâ–ˆ        | 750M/3.74G [00:27<01:51, 26.9MiB/s][A

 20%|â–ˆâ–ˆ        | 755M/3.74G [00:28<01:51, 26.9MiB/s][A

 20%|â–ˆâ–ˆ        | 761M/3.74G [00:28<01:49, 27.1MiB/s][A

 20%|â–ˆâ–ˆ        | 766M/3.74G [00:28<01:48, 27.3MiB/s][A

 21%|â–ˆâ–ˆ        | 771M/3.74G [00:28<01:47, 27.7MiB/s][A

 21%|â–ˆâ–ˆ        | 776M/3.74G [00:28<01:47, 27.7MiB/s][A

 21%|â–ˆâ–ˆ        | 781M/3.74G [00:28<01:46, 27.7MiB/s][A

 21%|â–ˆâ–ˆ        | 787M/3.74G [00:29<01:47, 27.6MiB/s][A

 21%|â–ˆâ–ˆ        | 792M/3.74G [00:29<01:32, 32.0MiB/s][A

 21%|â–ˆâ–ˆ        | 795M/3.74G [00:29<01:44, 28.2MiB/s][A

 21%|â–ˆâ–ˆâ–       | 798M/3.74G [00:29<01:57, 25.1MiB/s][A

 21%|â–ˆâ–ˆâ–       | 802M/3.74G [00:29<01:50, 26.6MiB/s][A

 22%|â–ˆâ–ˆâ–       | 807M/3.74G [00:29<01:31, 32.1MiB/s][A

 22%|â–ˆâ–ˆâ–       | 811M/3.74G [00:29<01:45, 27.9MiB/s][A

 22%|â–ˆâ–ˆâ–       | 814M/3.74G [00:30<01:58, 24.7MiB/s][A

 22%|â–ˆâ–ˆâ–       | 817M/3.74G [00:30<01:51, 26.3MiB/s][A

 22%|â–ˆâ–ˆâ–       | 823M/3.74G [00:30<01:49, 26.6MiB/s][A

 22%|â–ˆâ–ˆâ–       | 828M/3.74G [00:30<01:31, 32.0MiB/s][A

 22%|â–ˆâ–ˆâ–       | 831M/3.74G [00:30<01:46, 27.3MiB/s][A

 22%|â–ˆâ–ˆâ–       | 834M/3.74G [00:30<01:57, 24.8MiB/s][A

 22%|â–ˆâ–ˆâ–       | 838M/3.74G [00:31<01:50, 26.4MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 843M/3.74G [00:31<01:48, 26.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 848M/3.74G [00:31<01:47, 26.9MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 854M/3.74G [00:31<01:30, 31.9MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 857M/3.74G [00:31<01:43, 27.9MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 860M/3.74G [00:31<01:56, 24.8MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 864M/3.74G [00:31<01:47, 26.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 869M/3.74G [00:32<01:29, 32.0MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 873M/3.74G [00:32<01:43, 27.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 876M/3.74G [00:32<01:56, 24.6MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 880M/3.74G [00:32<01:47, 26.6MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 884M/3.74G [00:32<01:30, 31.7MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 888M/3.74G [00:32<01:44, 27.4MiB/s][A

 24%|â–ˆâ–ˆâ–       | 891M/3.74G [00:32<01:56, 24.5MiB/s][A

 24%|â–ˆâ–ˆâ–       | 895M/3.74G [00:33<01:47, 26.6MiB/s][A

 24%|â–ˆâ–ˆâ–       | 900M/3.74G [00:33<01:29, 31.7MiB/s][A

 24%|â–ˆâ–ˆâ–       | 903M/3.74G [00:33<01:43, 27.4MiB/s][A

 24%|â–ˆâ–ˆâ–       | 906M/3.74G [00:33<01:55, 24.5MiB/s][A

 24%|â–ˆâ–ˆâ–       | 911M/3.74G [00:33<01:46, 26.6MiB/s][A

 24%|â–ˆâ–ˆâ–       | 915M/3.74G [00:33<01:28, 31.8MiB/s][A

 25%|â–ˆâ–ˆâ–       | 919M/3.74G [00:33<01:42, 27.5MiB/s][A

 25%|â–ˆâ–ˆâ–       | 922M/3.74G [00:34<01:54, 24.7MiB/s][A

 25%|â–ˆâ–ˆâ–       | 926M/3.74G [00:34<01:45, 26.6MiB/s][A

 25%|â–ˆâ–ˆâ–       | 931M/3.74G [00:34<01:29, 31.3MiB/s][A

 25%|â–ˆâ–ˆâ–       | 934M/3.74G [00:34<01:43, 27.1MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 937M/3.74G [00:34<01:49, 25.7MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 942M/3.74G [00:34<01:45, 26.6MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 946M/3.74G [00:34<01:29, 31.1MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 950M/3.74G [00:35<01:43, 26.9MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 953M/3.74G [00:35<01:49, 25.5MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 957M/3.74G [00:35<01:45, 26.5MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 961M/3.74G [00:35<01:31, 30.5MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 965M/3.74G [00:35<01:45, 26.4MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 968M/3.74G [00:35<01:47, 25.8MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 973M/3.74G [00:35<01:42, 26.9MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 977M/3.74G [00:36<01:30, 30.4MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 980M/3.74G [00:36<01:44, 26.3MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 983M/3.74G [00:36<01:43, 26.6MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 987M/3.74G [00:36<01:30, 30.4MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 990M/3.74G [00:36<01:45, 26.1MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 993M/3.74G [00:36<01:43, 26.5MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 998M/3.74G [00:36<01:30, 30.3MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.00G/3.74G [00:36<01:45, 26.0MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.00G/3.74G [00:37<01:43, 26.5MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:37<01:31, 30.0MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:37<01:46, 25.7MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:37<01:42, 26.6MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:30, 30.1MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:45, 25.8MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:41, 26.9MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.03G/3.74G [00:37<01:30, 30.0MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.03G/3.74G [00:38<01:45, 25.7MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.03G/3.74G [00:38<01:41, 26.8MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.04G/3.74G [00:38<01:30, 30.0MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.04G/3.74G [00:38<01:45, 25.7MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:40, 26.7MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:29, 30.0MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:44, 25.7MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:38<01:40, 26.6MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:39<01:28, 30.4MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:39<01:43, 26.0MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:39<01:40, 26.6MiB/s][A

 29%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:39<01:28, 30.2MiB/s][A

 29%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:39<01:43, 25.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:40, 26.6MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:28, 30.1MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:43, 25.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:40<01:39, 26.7MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:40<01:29, 29.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:40<01:42, 25.9MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:40<01:39, 26.6MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:40<01:27, 30.1MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:40<01:41, 26.0MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:40<01:38, 26.7MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:40<01:28, 29.6MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:41<01:41, 26.0MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.12G/3.74G [00:41<01:37, 26.8MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.12G/3.74G [00:41<01:27, 30.0MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.12G/3.74G [00:41<01:41, 25.9MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:41<01:37, 26.8MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:41<01:27, 30.0MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:41<01:40, 25.9MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:41<01:37, 26.8MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:42<01:27, 29.8MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:42<01:39, 26.1MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:42<01:36, 26.8MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:42<01:28, 29.3MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:37, 26.5MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:36, 26.6MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:27, 29.5MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.17G/3.74G [00:42<01:36, 26.6MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.17G/3.74G [00:43<01:37, 26.5MiB/s][A

 31%|â–ˆâ–ˆâ–ˆâ–      | 1.17G/3.74G [00:43<01:26, 29.6MiB/s][A

 31%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:43<01:36, 26.5MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:43<01:37, 26.4MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:43<01:26, 29.7MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:36, 26.6MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:36, 26.3MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:25, 29.6MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:44<01:35, 26.7MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:44<01:36, 26.2MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:44<01:25, 29.6MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:44<01:34, 26.7MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:44<01:36, 26.2MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:44<01:25, 29.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:44<01:35, 26.6MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:44<01:35, 26.3MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:45<01:25, 29.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:45<01:34, 26.6MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:45<01:35, 26.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:45<01:25, 29.3MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:45<01:34, 26.5MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:45<01:34, 26.6MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:45<01:25, 29.3MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.25G/3.74G [00:45<01:34, 26.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.25G/3.74G [00:46<01:33, 26.7MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:46<01:24, 29.4MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:46<01:33, 26.4MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:46<01:32, 26.7MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:46<01:24, 29.2MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:46<01:33, 26.5MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:46<01:31, 26.9MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:46<01:24, 29.2MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:47<01:33, 26.4MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:47<01:30, 27.0MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:47<01:24, 29.2MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:47<01:32, 26.5MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:47<01:31, 26.9MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:26, 28.3MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:31, 26.6MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:30, 27.0MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.31G/3.74G [00:48<01:23, 29.2MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.31G/3.74G [00:48<01:30, 27.0MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.31G/3.74G [00:48<01:30, 26.8MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:48<01:24, 28.8MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:48<01:30, 26.7MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:48<01:29, 26.9MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:23, 28.9MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:30, 26.7MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:49<01:29, 26.8MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.34G/3.74G [00:49<01:23, 28.8MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.34G/3.74G [00:49<01:30, 26.6MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.34G/3.74G [00:49<01:22, 28.9MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:49<01:27, 27.5MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:49<01:30, 26.5MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:49<01:21, 29.3MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.36G/3.74G [00:49<01:28, 27.0MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.36G/3.74G [00:50<01:29, 26.7MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.36G/3.74G [00:50<01:25, 27.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:50<01:28, 26.7MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:50<01:16, 31.1MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:50<01:27, 27.0MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:50<01:30, 26.1MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:50<01:17, 30.3MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:50<01:28, 26.6MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:51<01:31, 25.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:51<01:18, 29.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:51<01:28, 26.6MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.40G/3.74G [00:51<01:29, 26.2MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.40G/3.74G [00:51<01:24, 27.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.40G/3.74G [00:51<01:28, 26.3MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:51<01:20, 29.1MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:51<01:26, 26.9MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:51<01:28, 26.2MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:52<01:18, 29.8MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:52<01:27, 26.7MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:52<01:26, 26.9MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:52<01:25, 27.2MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:52<01:27, 26.4MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:52<01:17, 29.9MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:26, 26.7MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:25, 27.0MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:23, 27.5MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:53<01:26, 26.4MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.45G/3.74G [00:53<01:16, 30.0MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.45G/3.74G [00:53<01:26, 26.6MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.45G/3.74G [00:53<01:24, 27.0MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:53<01:22, 27.6MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:53<01:26, 26.5MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:53<01:16, 29.7MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:53<01:24, 27.0MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:53<01:23, 27.1MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:54<01:23, 27.3MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:54<01:26, 26.2MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:54<01:16, 29.6MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:54<01:24, 26.7MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:54<01:23, 27.2MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:54<01:22, 27.5MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:54<01:25, 26.4MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:54<01:15, 29.6MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:55<01:24, 26.7MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:55<01:22, 27.3MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:55<01:21, 27.4MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:55<01:24, 26.4MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:55<01:15, 29.7MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:55<01:23, 26.7MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:21, 27.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:21, 27.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:23, 26.5MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:15, 29.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:56<01:24, 26.2MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:56<01:20, 27.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:56<01:20, 27.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.54G/3.74G [00:56<01:22, 26.6MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.54G/3.74G [00:56<01:14, 29.5MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.54G/3.74G [00:56<01:22, 26.8MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.74G [00:56<01:20, 27.3MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.74G [00:56<01:20, 27.4MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.74G [00:57<01:21, 26.9MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:57<01:16, 28.6MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:57<01:21, 26.8MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:57<01:19, 27.6MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:57<01:19, 27.5MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:57<01:20, 26.9MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:57<01:15, 28.7MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:57<01:21, 26.6MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:57<01:17, 27.9MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:58<01:18, 27.4MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:58<01:20, 26.9MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.59G/3.74G [00:58<01:14, 29.0MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.59G/3.74G [00:58<01:21, 26.6MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.59G/3.74G [00:58<01:17, 27.8MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:58<01:18, 27.4MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:58<01:18, 27.2MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:58<01:15, 28.3MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:58<01:20, 26.5MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:59<01:16, 27.8MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:59<01:18, 27.3MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:59<01:18, 27.2MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:59<01:15, 28.1MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:59<01:17, 27.2MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:59<01:11, 29.6MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:59<01:19, 26.7MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:59<01:18, 27.0MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:59<01:16, 27.5MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.64G/3.74G [01:00<01:18, 26.9MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.74G [01:00<01:11, 29.5MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.74G [01:00<01:18, 26.6MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [01:00<01:17, 26.9MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [01:00<01:16, 27.3MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [01:00<01:17, 27.1MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [01:00<01:08, 30.4MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [01:00<01:19, 26.3MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [01:00<01:17, 26.9MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [01:01<01:16, 27.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:01<01:16, 27.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:01<01:09, 29.9MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:01<01:19, 26.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.68G/3.74G [01:01<01:15, 27.4MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.68G/3.74G [01:01<01:15, 27.4MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.68G/3.74G [01:01<01:22, 25.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:01<01:14, 27.8MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:01<01:15, 27.4MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:02<01:12, 28.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:02<01:13, 27.7MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:02<01:14, 27.6MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:02<01:06, 30.5MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:02<01:17, 26.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:02<01:14, 27.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:02<01:14, 27.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:02<01:14, 27.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:02<01:08, 29.8MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:03<01:17, 26.2MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:03<01:14, 27.2MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.73G/3.74G [01:03<01:14, 27.2MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.73G/3.74G [01:03<01:13, 27.4MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.73G/3.74G [01:03<01:13, 27.5MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.73G/3.74G [01:03<01:12, 27.6MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:03<01:07, 29.6MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:03<01:15, 26.6MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:03<01:14, 26.8MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:04<01:14, 26.7MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:04<01:12, 27.6MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:04<01:13, 27.2MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:04<01:11, 27.7MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:04<01:08, 29.1MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:04<01:14, 26.7MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:04<01:11, 27.5MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:04<01:14, 26.6MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:04<01:10, 27.9MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:05<01:11, 27.6MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.78G/3.74G [01:05<01:11, 27.7MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.78G/3.74G [01:05<01:04, 30.3MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.78G/3.74G [01:05<01:14, 26.1MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:05<01:11, 27.3MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:05<01:11, 27.2MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:05<01:11, 27.4MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:05<01:05, 29.8MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:05<01:15, 25.8MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:06<01:11, 27.3MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:06<01:11, 27.2MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:06<01:10, 27.5MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:06<01:04, 29.8MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:06<01:14, 25.8MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:06<01:10, 27.3MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:06<01:10, 27.1MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:06<01:09, 27.5MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:06<01:04, 29.5MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:07<01:13, 26.2MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:07<01:11, 26.9MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:07<01:11, 26.7MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:07<01:08, 28.0MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:07<01:06, 28.5MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:07<01:08, 27.6MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:07<01:10, 27.0MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:07<01:10, 26.9MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:07<01:09, 27.0MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:08<01:09, 27.1MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:08<01:08, 27.7MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:08<01:08, 27.3MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:08<01:07, 28.0MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.87G/3.74G [01:08<01:03, 29.3MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.87G/3.74G [01:08<01:10, 26.5MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.87G/3.74G [01:08<01:09, 26.9MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:08<01:10, 26.6MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:08<01:06, 27.8MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:08<01:08, 27.2MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:09<01:06, 28.1MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:09<01:03, 29.1MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:09<01:08, 27.1MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:09<01:08, 26.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:09<01:09, 26.7MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:09<01:06, 27.5MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:09<01:08, 26.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:09<01:05, 27.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:09<01:05, 27.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:10<01:05, 27.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:10<01:03, 28.6MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.92G/3.74G [01:10<01:07, 27.1MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:10<01:07, 26.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:10<01:08, 26.4MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:10<01:05, 27.6MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:10<01:07, 26.9MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:10<01:04, 28.2MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:10<01:03, 28.4MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:10<01:04, 27.8MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:11<01:07, 26.6MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:11<01:06, 27.0MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:11<01:05, 27.3MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:11<01:06, 27.0MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:11<01:04, 27.6MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:11<01:05, 27.4MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:11<01:03, 28.2MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:11<01:03, 28.2MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:11<01:03, 27.8MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:12<01:05, 27.0MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:12<01:04, 27.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:12<01:04, 27.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:12<01:06, 26.7MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:12<01:03, 27.8MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:12<01:03, 27.6MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:12<01:02, 28.3MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:12<01:00, 29.0MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:12<01:03, 27.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:12<01:06, 26.3MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:13<01:05, 26.7MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:13<01:03, 27.3MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:13<01:04, 27.0MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:13<01:01, 28.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.01G/3.74G [01:13<01:01, 28.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.01G/3.74G [01:13<01:01, 28.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.01G/3.74G [01:13<00:59, 29.2MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.01G/3.74G [01:13<01:03, 27.3MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:13<01:04, 26.6MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:14<01:05, 26.4MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:14<01:03, 27.0MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:14<01:03, 26.8MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:14<01:00, 28.2MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:14<01:00, 28.2MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:14<01:01, 27.9MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:14<01:02, 27.3MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:14<01:01, 27.7MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:14<01:02, 27.2MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:14<01:03, 26.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:15<01:00, 27.9MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:15<01:01, 27.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.74G [01:15<01:00, 28.0MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.06G/3.74G [01:15<00:58, 28.8MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.06G/3.74G [01:15<01:00, 27.7MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.06G/3.74G [01:15<01:02, 26.9MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:15<01:01, 27.1MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:15<01:01, 27.2MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:15<01:01, 27.0MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:16<01:00, 27.4MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:16<01:00, 27.4MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:16<00:59, 28.1MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:16<00:57, 28.9MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:16<00:59, 27.6MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:16<01:02, 26.4MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:16<01:00, 27.3MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:16<01:00, 27.3MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:16<01:01, 26.9MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:16<01:00, 27.3MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:17<00:57, 28.3MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:17<00:57, 28.2MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:17<00:59, 27.4MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:17<00:58, 28.0MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:17<01:00, 26.8MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:17<00:59, 27.2MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:17<00:58, 27.6MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:17<00:59, 27.2MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:17<00:57, 28.3MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:18<00:55, 29.3MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:18<00:58, 27.6MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:18<01:00, 26.4MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:18<01:00, 26.4MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:18<00:58, 27.2MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.15G/3.74G [01:18<00:57, 27.7MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.15G/3.74G [01:18<00:57, 27.7MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.15G/3.74G [01:18<00:57, 27.5MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.15G/3.74G [01:18<00:56, 28.0MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:19<00:58, 27.2MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:19<00:55, 28.3MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:19<00:58, 26.8MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:19<00:57, 27.6MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:19<00:57, 27.3MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:19<00:57, 27.4MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:19<00:57, 27.5MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:19<00:55, 28.4MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:19<00:56, 27.8MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:19<00:57, 27.1MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:20<00:55, 28.1MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:20<00:58, 26.8MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:20<00:56, 27.3MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:20<00:56, 27.2MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.20G/3.74G [01:20<00:56, 27.5MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.20G/3.74G [01:20<00:56, 27.5MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.20G/3.74G [01:20<00:53, 28.9MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:20<00:55, 27.9MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:20<00:57, 26.5MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:21<00:55, 27.7MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:21<00:56, 27.1MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:21<00:55, 27.4MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:21<00:56, 26.9MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:21<00:52, 28.8MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:21<00:54, 27.8MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:21<00:56, 27.0MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:21<00:53, 28.1MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:21<00:56, 26.5MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:21<00:55, 27.3MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:22<00:55, 27.2MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:22<00:52, 28.3MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:22<00:53, 27.8MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:22<00:56, 26.6MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:22<00:52, 28.3MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:22<00:55, 26.7MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:22<00:53, 27.8MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:22<00:54, 27.3MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:22<00:54, 27.0MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:23<00:52, 28.3MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:23<00:54, 26.9MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:23<00:52, 28.1MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:23<00:53, 27.4MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:23<00:53, 27.5MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:23<00:53, 27.2MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.29G/3.74G [01:23<00:53, 27.4MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.29G/3.74G [01:23<00:51, 28.2MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.29G/3.74G [01:23<00:54, 26.8MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:24<00:50, 28.5MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:24<00:53, 27.1MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:24<00:52, 27.5MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:24<00:52, 27.5MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:24<00:53, 26.9MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:24<00:50, 28.3MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:24<00:53, 26.8MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:24<00:50, 28.3MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:24<00:52, 27.3MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:25<00:51, 27.5MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:25<00:51, 27.6MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:25<00:52, 26.7MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:25<00:49, 28.5MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:25<00:53, 26.4MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.34G/3.74G [01:25<00:49, 28.6MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.34G/3.74G [01:25<00:51, 27.3MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.34G/3.74G [01:25<00:50, 27.6MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:25<00:51, 27.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:25<00:52, 26.5MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:26<00:48, 28.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:26<00:51, 26.9MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:26<00:48, 28.3MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:26<00:50, 27.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:26<00:49, 27.7MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:26<00:49, 27.7MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:26<00:51, 26.6MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:26<00:48, 28.2MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:26<00:50, 26.9MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:27<00:47, 28.6MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:27<00:50, 27.1MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:27<00:49, 27.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:27<00:48, 27.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:27<00:50, 26.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:27<00:49, 27.4MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:27<00:50, 26.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:27<00:46, 28.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:27<00:49, 27.0MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:28<00:49, 26.9MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:28<00:48, 27.3MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:28<00:49, 26.7MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:28<00:45, 29.0MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:28<00:48, 27.5MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:28<00:46, 28.3MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:28<00:47, 27.6MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.74G [01:28<00:48, 26.9MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.74G [01:28<00:48, 27.1MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.74G [01:29<00:49, 26.3MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.43G/3.74G [01:29<00:45, 28.6MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:29<00:47, 27.6MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:29<00:46, 28.1MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:29<00:47, 27.4MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:29<00:47, 27.2MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:29<00:47, 27.2MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:29<00:48, 26.5MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:29<00:45, 28.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:29<00:47, 27.1MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:30<00:45, 28.2MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:30<00:46, 27.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:30<00:46, 27.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:30<00:46, 27.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:30<00:47, 26.8MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.48G/3.74G [01:30<00:44, 28.3MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.48G/3.74G [01:30<00:46, 27.1MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.48G/3.74G [01:30<00:44, 28.0MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.48G/3.74G [01:30<00:45, 27.7MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:31<00:43, 28.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:31<00:46, 27.0MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:31<00:47, 26.4MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:31<00:44, 28.1MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:31<00:45, 27.0MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:31<00:44, 27.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:31<00:43, 28.1MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:31<00:43, 28.1MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:31<00:46, 26.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:32<00:45, 27.2MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:32<00:43, 27.9MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:32<00:45, 26.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:32<00:43, 28.3MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:32<00:44, 27.2MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:32<00:44, 27.5MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:32<00:44, 27.0MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:32<00:44, 27.4MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:32<00:44, 27.2MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:32<00:44, 27.1MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:33<00:42, 28.2MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:33<00:44, 27.1MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:33<00:42, 27.8MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:33<00:44, 27.0MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:33<00:42, 27.6MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:33<00:43, 27.5MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:33<00:43, 27.4MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:33<00:41, 28.2MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.57G/3.74G [01:33<00:43, 27.0MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.57G/3.74G [01:34<00:40, 28.7MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.57G/3.74G [01:34<00:41, 28.0MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:34<00:41, 27.8MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:34<00:42, 27.1MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:34<00:42, 27.3MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:34<00:42, 27.0MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:34<00:43, 26.8MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:34<00:41, 27.7MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:34<00:42, 27.0MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:34<00:39, 28.7MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:35<00:41, 27.7MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:35<00:41, 27.7MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:35<00:41, 27.2MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:35<00:41, 27.2MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:35<00:41, 27.3MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:35<00:41, 27.1MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.62G/3.74G [01:35<00:40, 27.8MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.62G/3.74G [01:35<00:42, 26.7MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.62G/3.74G [01:35<00:38, 28.8MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.62G/3.74G [01:36<00:39, 27.9MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:36<00:40, 27.7MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:36<00:40, 27.4MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:36<00:41, 26.7MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:36<00:41, 26.9MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:36<00:40, 27.0MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:36<00:39, 27.5MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:36<00:40, 27.1MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.65G/3.74G [01:36<00:38, 28.4MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.65G/3.74G [01:36<00:39, 27.8MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.65G/3.74G [01:37<00:38, 28.2MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:37<00:40, 26.7MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:37<00:40, 26.9MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:37<00:39, 27.3MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:37<00:39, 27.1MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:37<00:39, 27.5MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:37<00:38, 27.6MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:37<00:37, 28.7MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:37<00:38, 27.8MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:37<00:37, 28.1MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:38<00:39, 26.8MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:38<00:39, 26.8MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:38<00:38, 27.4MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:38<00:38, 27.1MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:38<00:38, 27.1MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:38<00:38, 27.4MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:38<00:38, 27.4MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:38<00:37, 27.7MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:38<00:36, 28.3MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.71G/3.74G [01:39<00:37, 27.9MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.71G/3.74G [01:39<00:37, 27.2MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.71G/3.74G [01:39<00:37, 27.2MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:39<00:37, 27.1MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:39<00:37, 27.6MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:39<00:37, 27.0MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:39<00:37, 27.3MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:39<00:37, 27.3MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:39<00:37, 27.3MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:39<00:36, 27.8MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:40<00:35, 28.7MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:40<00:36, 27.7MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:40<00:36, 27.5MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:40<00:36, 27.1MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:40<00:36, 27.1MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:40<00:36, 27.2MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:40<00:36, 27.2MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.76G/3.74G [01:40<00:36, 27.3MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.76G/3.74G [01:40<00:35, 27.6MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.76G/3.74G [01:40<00:35, 27.3MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.76G/3.74G [01:41<00:35, 27.3MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:41<00:33, 28.8MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:41<00:36, 26.9MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:41<00:35, 27.6MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:41<00:35, 27.2MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:41<00:35, 27.4MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:41<00:35, 27.1MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:41<00:34, 27.4MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:41<00:34, 27.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:42<00:34, 27.5MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:42<00:32, 28.8MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:42<00:35, 26.8MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:42<00:35, 26.6MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:42<00:33, 28.1MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:42<00:33, 28.0MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:42<00:33, 27.5MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:42<00:33, 27.5MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:42<00:34, 27.2MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:42<00:33, 27.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:43<00:32, 28.5MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:43<00:34, 27.0MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:43<00:33, 27.3MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:43<00:33, 27.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:43<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:43<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:43<00:32, 27.7MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:43<00:33, 27.1MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:43<00:32, 27.3MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:44<00:31, 28.3MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:44<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:44<00:32, 27.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:44<00:32, 27.0MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:44<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:44<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:44<00:32, 27.4MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:44<00:32, 27.2MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:44<00:31, 27.8MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:44<00:31, 27.4MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:45<00:31, 27.2MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:45<00:31, 27.6MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:45<00:31, 27.3MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:45<00:30, 27.8MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:45<00:31, 27.3MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:45<00:31, 27.5MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:45<00:31, 27.2MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:45<00:31, 27.2MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.90G/3.74G [01:45<00:30, 27.5MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.90G/3.74G [01:45<00:30, 28.1MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.90G/3.74G [01:46<00:30, 27.3MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.90G/3.74G [01:46<00:30, 27.6MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:46<00:30, 27.6MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:46<00:30, 27.4MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:46<00:29, 27.7MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:46<00:30, 27.2MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:46<00:30, 27.2MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:46<00:30, 27.1MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:46<00:30, 27.0MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:46<00:29, 27.8MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:47<00:28, 28.2MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:47<00:29, 27.6MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:47<00:28, 27.8MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:47<00:29, 27.7MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:47<00:29, 27.3MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:47<00:28, 27.6MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.95G/3.74G [01:47<00:29, 27.1MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.95G/3.74G [01:47<00:28, 27.7MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.95G/3.74G [01:48<00:41, 18.8MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.96G/3.74G [01:48<00:25, 30.6MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.96G/3.74G [01:48<00:26, 29.5MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:48<00:27, 28.6MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:48<00:26, 28.8MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:48<00:27, 28.0MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:48<00:27, 27.8MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:48<00:27, 28.0MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:48<00:27, 28.2MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:49<00:27, 27.7MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:49<00:27, 27.4MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:49<00:26, 28.0MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:49<00:27, 27.6MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:49<00:26, 27.9MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:49<00:27, 27.4MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:49<00:27, 26.9MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:49<00:26, 27.6MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:49<00:26, 27.9MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:50<00:26, 27.5MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:50<00:26, 27.4MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:50<00:26, 27.7MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:50<00:26, 27.2MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:50<00:25, 27.7MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:50<00:26, 27.4MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:50<00:26, 27.4MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:50<00:25, 27.8MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:50<00:25, 27.5MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.04G/3.74G [01:50<00:25, 27.3MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.04G/3.74G [01:51<00:25, 27.9MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.04G/3.74G [01:51<00:25, 27.7MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.04G/3.74G [01:51<00:25, 27.7MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:51<00:24, 28.2MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:51<00:25, 26.7MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:51<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:51<00:25, 27.4MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:51<00:25, 27.2MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:51<00:25, 27.0MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:52<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:52<00:24, 27.5MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:52<00:24, 27.7MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:52<00:23, 28.1MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:52<00:24, 26.7MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:52<00:23, 28.2MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:52<00:24, 27.3MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:52<00:24, 27.4MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:52<00:24, 27.0MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:52<00:23, 28.1MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:53<00:23, 27.5MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:53<00:23, 27.5MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:53<00:23, 27.3MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:53<00:23, 26.9MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:53<00:22, 28.0MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:53<00:23, 27.5MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:53<00:22, 27.7MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:53<00:23, 27.1MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:53<00:22, 28.0MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:53<00:22, 27.4MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:54<00:22, 28.0MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:54<00:22, 27.2MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:54<00:22, 26.8MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:54<00:21, 27.9MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:54<00:22, 27.3MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:54<00:21, 28.0MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:54<00:22, 26.8MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:54<00:21, 28.1MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:54<00:21, 28.1MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:55<00:22, 26.7MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:55<00:21, 27.4MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:55<00:21, 26.8MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:55<00:20, 28.4MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:55<00:21, 26.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:55<00:20, 28.4MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:55<00:20, 28.0MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:55<00:21, 26.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:55<00:20, 27.4MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:56<00:21, 26.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.18G/3.74G [01:56<00:19, 28.4MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.18G/3.74G [01:56<00:20, 26.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.18G/3.74G [01:56<00:19, 28.2MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:56<00:19, 27.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:56<00:20, 27.6MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:56<00:20, 27.3MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:56<00:20, 26.7MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:56<00:19, 27.8MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:56<00:19, 27.1MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:57<00:19, 28.0MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:57<00:19, 26.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:57<00:18, 28.3MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:57<00:18, 28.1MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:57<00:19, 27.3MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:57<00:19, 27.1MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:57<00:19, 27.1MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:57<00:18, 27.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.23G/3.74G [01:57<00:19, 27.0MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.23G/3.74G [01:58<00:18, 28.1MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.23G/3.74G [01:58<00:18, 26.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:58<00:18, 28.1MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:58<00:17, 28.2MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:58<00:18, 27.0MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:58<00:18, 27.3MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:58<00:18, 26.7MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:58<00:17, 28.3MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:58<00:18, 26.7MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:58<00:17, 28.4MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:59<00:17, 28.1MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:59<00:17, 27.1MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:59<00:17, 27.8MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:59<00:17, 26.9MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:59<00:16, 27.9MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:59<00:17, 26.5MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:59<00:16, 28.1MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:59<00:16, 27.9MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:59<00:16, 27.5MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [02:00<00:16, 28.4MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [02:00<00:16, 26.8MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [02:00<00:16, 27.4MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [02:00<00:16, 26.4MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [02:00<00:15, 28.1MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [02:00<00:16, 27.4MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [02:00<00:16, 27.3MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [02:00<00:15, 28.7MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [02:00<00:15, 27.1MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [02:01<00:15, 27.7MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [02:01<00:16, 26.4MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.32G/3.74G [02:01<00:15, 27.9MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.32G/3.74G [02:01<00:15, 27.4MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.32G/3.74G [02:01<00:15, 27.7MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:01<00:14, 28.5MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:01<00:15, 27.2MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:01<00:14, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:01<00:15, 27.0MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:01<00:14, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:02<00:15, 26.5MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:02<00:14, 27.7MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:02<00:14, 27.6MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:02<00:14, 27.7MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:02<00:13, 28.6MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:02<00:14, 27.3MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:02<00:14, 27.4MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:02<00:14, 26.7MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:02<00:13, 27.6MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.37G/3.74G [02:03<00:13, 26.8MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.37G/3.74G [02:03<00:13, 28.0MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.37G/3.74G [02:03<00:13, 27.9MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:03<00:13, 27.1MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:03<00:12, 27.9MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:03<00:13, 27.5MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:03<00:13, 27.4MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:03<00:13, 27.0MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:03<00:12, 27.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:03<00:13, 26.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:04<00:12, 27.6MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:04<00:12, 27.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:04<00:12, 27.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:04<00:12, 28.1MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:04<00:12, 27.0MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:04<00:11, 27.6MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:04<00:12, 26.7MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:04<00:11, 27.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:04<00:11, 27.3MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:05<00:11, 27.5MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:05<00:11, 27.7MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:05<00:11, 27.6MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:05<00:11, 28.1MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:05<00:11, 27.0MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:05<00:11, 27.6MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:05<00:11, 26.6MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:05<00:10, 27.8MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:05<00:10, 27.2MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:05<00:10, 27.5MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:06<00:10, 27.6MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:06<00:10, 27.7MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.46G/3.74G [02:06<00:10, 28.0MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.46G/3.74G [02:06<00:10, 26.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.46G/3.74G [02:06<00:10, 27.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.46G/3.74G [02:06<00:10, 26.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:06<00:09, 27.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:06<00:09, 27.2MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:06<00:09, 27.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:06<00:09, 27.5MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:07<00:09, 27.4MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:07<00:09, 28.0MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:07<00:09, 27.0MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:07<00:09, 27.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:07<00:09, 26.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:07<00:08, 27.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:07<00:09, 27.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:07<00:08, 27.8MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:07<00:08, 27.8MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.51G/3.74G [02:08<00:08, 27.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.51G/3.74G [02:08<00:08, 27.7MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.51G/3.74G [02:08<00:08, 27.1MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.51G/3.74G [02:08<00:08, 26.3MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:08<00:08, 27.3MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:08<00:07, 28.5MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:08<00:07, 27.7MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:08<00:07, 28.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:08<00:07, 28.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:09<00:07, 27.2MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:09<00:07, 27.2MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:09<00:07, 27.3MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:09<00:07, 27.7MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:09<00:07, 27.0MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:09<00:07, 27.7MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:09<00:07, 27.2MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:09<00:06, 27.9MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:09<00:06, 27.9MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:09<00:06, 27.6MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:10<00:06, 27.6MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:10<00:06, 27.4MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:10<00:06, 27.1MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:10<00:06, 26.9MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:10<00:06, 27.4MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:10<00:06, 27.0MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:10<00:05, 28.1MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:10<00:06, 27.0MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:10<00:05, 27.7MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:10<00:05, 27.9MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:11<00:05, 27.8MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:11<00:05, 26.9MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:11<00:05, 27.1MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.60G/3.74G [02:11<00:05, 27.5MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.60G/3.74G [02:11<00:05, 27.0MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.60G/3.74G [02:11<00:04, 28.2MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:11<00:05, 27.1MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:11<00:04, 27.9MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:11<00:04, 27.6MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:12<00:04, 27.9MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:12<00:04, 27.3MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:12<00:04, 26.6MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:12<00:04, 27.3MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:12<00:04, 27.2MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:12<00:04, 28.2MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:12<00:04, 27.4MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:12<00:03, 27.8MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:12<00:03, 27.5MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:12<00:03, 28.1MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:13<00:03, 27.1MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.65G/3.74G [02:13<00:03, 27.0MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:13<00:03, 27.3MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:13<00:03, 26.3MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:13<00:03, 29.0MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:13<00:03, 27.3MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:13<00:03, 25.6MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:13<00:02, 28.1MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:13<00:02, 27.3MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:14<00:02, 29.0MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:14<00:02, 28.1MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:14<00:02, 27.9MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:14<00:02, 26.7MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:14<00:02, 27.4MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:14<00:02, 27.2MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.69G/3.74G [02:14<00:02, 18.4MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.69G/3.74G [02:14<00:01, 30.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:15<00:01, 29.9MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:15<00:01, 29.4MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:15<00:01, 28.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:15<00:01, 27.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:15<00:01, 28.7MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:15<00:00, 27.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:15<00:00, 28.1MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:15<00:00, 27.5MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:16<00:00, 27.3MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:16<00:00, 27.7MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:16<00:00, 26.7MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:16<00:00, 28.4MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.74G/3.74G [02:16<00:00, 28.3MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.74G/3.74G [02:16<00:00, 27.7MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.74G/3.74G [02:16<00:00, 26.8MiB/s][A
  0%|          | 0.00/29.0 [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.74G/3.74G [02:17<00:00, 27.2MiB/s]


  0%|          | 0.00/6.11k [00:00<?, ?iB/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 9.00/29.0 [00:00<00:01, 10.6iB/s]

  0%|          | 0.00/1.14G [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.11k/6.11k [00:01<00:00, 5.33kiB/s]

  0%|          | 3.06M/1.14G [00:00<00:37, 30.6MiB/s]
  1%|          | 6.12M/1.14G [00:00<00:38, 29.1MiB/s]
  1%|          | 9.37M/1.14G [00:00<00:47, 23.6MiB/s]
  1%|â–         | 14.5M/1.14G [00:00<00:43, 25.6MiB/s]
  2%|â–         | 19.8M/1.14G [00:00<00:42, 26.5MiB/s]
  2%|â–         | 24.9M/1.14G [00:00<00:41, 26.8MiB/s]
  3%|â–Ž         | 30.2M/1.14G [00:01<00:40, 27.2MiB/s]
  3%|â–Ž         | 35.3M/1.14G [00:01<00:40, 27.3MiB/s]
  4%|â–Ž         | 40.5M/1.14G [00:01<00:39, 27.5MiB/s]
  4%|â–         | 45.7M/1.14G [00:01<00:39, 27.5MiB/s]
  4%|â–         | 50.9M/1.14G [00:01<00:39, 27.6MiB/s]
  5%|â–         | 56.1M/1.14G [00:02<00:39, 27.7MiB/s]
  5%|â–Œ         | 61.3M/1.14G [00:02<00:38, 27.7MiB/s]
  6%|â–Œ         | 66.6M/1.14G [00:02<00:38, 27.7MiB/s]
  6%|â–‹         | 71.7M/1.14G [00:02<00:38, 27.7MiB/s]
  7%|â–‹         | 77.0M/1.14G [00:02<00:38, 27.7MiB/s]
  7%|â–‹         | 82.1M/1.14G [00:03<00:38, 27.7MiB/s]
  8%|â–Š         | 87.4M/1.14G [00:03<00:37, 27.7MiB/s]
  8%|â–Š         | 92.6M/1.14G [00:03<00:37, 27.8MiB/s]
  9%|â–Š         | 97.8M/1.14G [00:03<00:37, 27.8MiB/s]
  9%|â–‰         | 103M/1.14G [00:03<00:37, 27.8MiB/s] 
 10%|â–‰         | 108M/1.14G [00:03<00:37, 27.8MiB/s]
 10%|â–‰         | 113M/1.14G [00:04<00:36, 27.7MiB/s]
 10%|â–ˆ         | 119M/1.14G [00:04<00:36, 27.7MiB/s]
 11%|â–ˆ         | 124M/1.14G [00:04<00:36, 27.7MiB/s]
 11%|â–ˆâ–        | 129M/1.14G [00:04<00:36, 27.7MiB/s]
 12%|â–ˆâ–        | 134M/1.14G [00:04<00:36, 27.7MiB/s]
 12%|â–ˆâ–        | 139M/1.14G [00:05<00:36, 27.7MiB/s]
 13%|â–ˆâ–Ž        | 144M/1.14G [00:05<00:35, 27.6MiB/s]
 13%|â–ˆâ–Ž        | 150M/1.14G [00:05<00:35, 27.6MiB/s]
 14%|â–ˆâ–Ž        | 155M/1.14G [00:05<00:35, 27.4MiB/s]
 14%|â–ˆâ–        | 160M/1.14G [00:05<00:35, 27.7MiB/s]
 15%|â–ˆâ–        | 165M/1.14G [00:06<00:34, 27.8MiB/s]
 15%|â–ˆâ–Œ        | 170M/1.14G [00:06<00:34, 27.8MiB/s]
 15%|â–ˆâ–Œ        | 176M/1.14G [00:06<00:34, 27.8MiB/s]
 16%|â–ˆâ–Œ        | 181M/1.14G [00:06<00:34, 27.8MiB/s]
 16%|â–ˆâ–‹        | 186M/1.14G [00:06<00:34, 27.8MiB/s]
 17%|â–ˆâ–‹        | 191M/1.14G [00:06<00:33, 27.8MiB/s]
 17%|â–ˆâ–‹        | 197M/1.14G [00:07<00:34, 27.5MiB/s]
 18%|â–ˆâ–Š        | 202M/1.14G [00:07<00:33, 27.9MiB/s]
 18%|â–ˆâ–Š        | 207M/1.14G [00:07<00:33, 27.8MiB/s]
 19%|â–ˆâ–Š        | 212M/1.14G [00:07<00:33, 27.5MiB/s]
 19%|â–ˆâ–‰        | 217M/1.14G [00:07<00:32, 27.9MiB/s]
 20%|â–ˆâ–‰        | 223M/1.14G [00:08<00:33, 27.6MiB/s]
 20%|â–ˆâ–ˆ        | 228M/1.14G [00:08<00:32, 27.9MiB/s]
 21%|â–ˆâ–ˆ        | 233M/1.14G [00:08<00:32, 27.9MiB/s]
 21%|â–ˆâ–ˆ        | 238M/1.14G [00:08<00:32, 27.8MiB/s]
 21%|â–ˆâ–ˆâ–       | 243M/1.14G [00:08<00:32, 27.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 249M/1.14G [00:09<00:31, 27.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 254M/1.14G [00:09<00:31, 27.8MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 259M/1.14G [00:09<00:31, 27.7MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 264M/1.14G [00:09<00:31, 27.7MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 269M/1.14G [00:09<00:31, 27.7MiB/s]
 24%|â–ˆâ–ˆâ–       | 275M/1.14G [00:09<00:31, 27.7MiB/s]
 25%|â–ˆâ–ˆâ–       | 280M/1.14G [00:10<00:30, 27.7MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 285M/1.14G [00:10<00:30, 27.7MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 290M/1.14G [00:10<00:30, 27.7MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 295M/1.14G [00:10<00:30, 27.8MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 301M/1.14G [00:10<00:30, 27.4MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 306M/1.14G [00:11<00:29, 27.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 311M/1.14G [00:11<00:29, 27.8MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 316M/1.14G [00:11<00:29, 27.5MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 321M/1.14G [00:11<00:29, 27.6MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 327M/1.14G [00:11<00:29, 27.9MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 332M/1.14G [00:12<00:28, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 337M/1.14G [00:12<00:28, 27.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 342M/1.14G [00:12<00:28, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 347M/1.14G [00:12<00:28, 27.6MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 352M/1.14G [00:12<00:28, 27.5MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 358M/1.14G [00:12<00:28, 27.6MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 363M/1.14G [00:13<00:28, 27.6MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 368M/1.14G [00:13<00:27, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 373M/1.14G [00:13<00:27, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 378M/1.14G [00:13<00:25, 30.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 382M/1.14G [00:13<00:23, 31.6MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 386M/1.14G [00:13<00:27, 27.5MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 389M/1.14G [00:14<00:26, 28.3MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 392M/1.14G [00:14<00:24, 30.5MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 396M/1.14G [00:14<00:28, 26.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 399M/1.14G [00:14<00:26, 27.9MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 403M/1.14G [00:14<00:24, 30.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 406M/1.14G [00:14<00:28, 25.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 409M/1.14G [00:14<00:26, 27.5MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 413M/1.14G [00:14<00:24, 30.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 416M/1.14G [00:15<00:28, 25.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 420M/1.14G [00:15<00:26, 27.2MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 424M/1.14G [00:15<00:23, 30.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 427M/1.14G [00:15<00:27, 25.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 430M/1.14G [00:15<00:25, 27.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 434M/1.14G [00:15<00:23, 29.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 437M/1.14G [00:15<00:27, 25.6MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 440M/1.14G [00:15<00:25, 27.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 444M/1.14G [00:15<00:23, 29.6MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 447M/1.14G [00:16<00:27, 25.3MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 451M/1.14G [00:16<00:25, 27.3MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 455M/1.14G [00:16<00:22, 30.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 458M/1.14G [00:16<00:26, 25.9MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 461M/1.14G [00:16<00:25, 27.0MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 465M/1.14G [00:16<00:22, 30.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 468M/1.14G [00:16<00:25, 25.7MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 471M/1.14G [00:17<00:24, 27.0MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 475M/1.14G [00:17<00:21, 30.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 478M/1.14G [00:17<00:25, 25.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 482M/1.14G [00:17<00:24, 27.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 486M/1.14G [00:17<00:21, 30.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 489M/1.14G [00:17<00:25, 25.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 492M/1.14G [00:17<00:23, 27.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 496M/1.14G [00:17<00:21, 29.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 499M/1.14G [00:18<00:25, 25.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 502M/1.14G [00:18<00:23, 27.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 506M/1.14G [00:18<00:21, 29.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 509M/1.14G [00:18<00:24, 25.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 513M/1.14G [00:18<00:22, 27.8MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 516M/1.14G [00:18<00:21, 28.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 519M/1.14G [00:18<00:24, 24.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 523M/1.14G [00:18<00:21, 28.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 526M/1.14G [00:18<00:21, 28.6MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 529M/1.14G [00:19<00:24, 25.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 534M/1.14G [00:19<00:21, 28.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 536M/1.14G [00:19<00:20, 28.9MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 539M/1.14G [00:19<00:23, 25.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 544M/1.14G [00:19<00:20, 29.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 547M/1.14G [00:19<00:20, 29.1MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 550M/1.14G [00:19<00:23, 25.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 554M/1.14G [00:20<00:20, 28.7MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 557M/1.14G [00:20<00:20, 28.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 560M/1.14G [00:20<00:22, 25.1MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 565M/1.14G [00:20<00:19, 28.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 568M/1.14G [00:20<00:19, 28.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 571M/1.14G [00:20<00:22, 25.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 575M/1.14G [00:20<00:19, 29.0MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 578M/1.14G [00:20<00:19, 29.0MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 581M/1.14G [00:21<00:22, 24.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 585M/1.14G [00:21<00:19, 28.7MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 588M/1.14G [00:21<00:18, 28.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 591M/1.14G [00:21<00:21, 24.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 596M/1.14G [00:21<00:18, 28.9MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 599M/1.14G [00:21<00:18, 29.1MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 602M/1.14G [00:21<00:21, 24.9MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 606M/1.14G [00:21<00:18, 28.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 609M/1.14G [00:22<00:18, 29.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 612M/1.14G [00:22<00:21, 24.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 616M/1.14G [00:22<00:17, 28.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 619M/1.14G [00:22<00:17, 29.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 622M/1.14G [00:22<00:20, 25.0MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 627M/1.14G [00:22<00:17, 28.7MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 630M/1.14G [00:22<00:17, 28.6MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 633M/1.14G [00:22<00:20, 25.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 637M/1.14G [00:23<00:17, 29.1MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 640M/1.14G [00:23<00:17, 28.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 643M/1.14G [00:23<00:19, 25.0MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 647M/1.14G [00:23<00:16, 29.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 650M/1.14G [00:23<00:16, 28.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 653M/1.14G [00:23<00:19, 24.9MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 658M/1.14G [00:23<00:16, 29.2MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 661M/1.14G [00:23<00:16, 28.9MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 664M/1.14G [00:24<00:18, 25.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 668M/1.14G [00:24<00:16, 29.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 671M/1.14G [00:24<00:16, 28.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 674M/1.14G [00:24<00:18, 25.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 678M/1.14G [00:24<00:17, 26.4MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 683M/1.14G [00:24<00:14, 31.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 687M/1.14G [00:24<00:16, 28.1MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 690M/1.14G [00:24<00:18, 24.8MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 694M/1.14G [00:25<00:15, 28.7MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 697M/1.14G [00:25<00:15, 28.4MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 700M/1.14G [00:25<00:17, 24.9MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 704M/1.14G [00:25<00:14, 29.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 707M/1.14G [00:25<00:14, 28.6MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 710M/1.14G [00:25<00:17, 24.9MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 715M/1.14G [00:25<00:15, 26.7MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 719M/1.14G [00:25<00:13, 31.6MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 723M/1.14G [00:26<00:14, 28.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 726M/1.14G [00:26<00:16, 24.9MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 730M/1.14G [00:26<00:13, 29.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 733M/1.14G [00:26<00:14, 28.7MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 736M/1.14G [00:26<00:15, 25.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 740M/1.14G [00:26<00:14, 26.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 745M/1.14G [00:26<00:12, 31.9MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 749M/1.14G [00:27<00:13, 28.2MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 752M/1.14G [00:27<00:15, 25.0MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 756M/1.14G [00:27<00:14, 26.5MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 761M/1.14G [00:27<00:11, 31.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 764M/1.14G [00:27<00:13, 28.2MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 767M/1.14G [00:27<00:14, 25.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 772M/1.14G [00:27<00:13, 26.3MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 777M/1.14G [00:28<00:11, 31.9MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 780M/1.14G [00:28<00:12, 28.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 783M/1.14G [00:28<00:14, 25.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 787M/1.14G [00:28<00:13, 26.3MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 792M/1.14G [00:28<00:10, 31.4MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 795M/1.14G [00:28<00:12, 27.8MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 798M/1.14G [00:28<00:13, 24.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 803M/1.14G [00:29<00:12, 26.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 808M/1.14G [00:29<00:10, 31.4MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 811M/1.14G [00:29<00:11, 27.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 814M/1.14G [00:29<00:13, 24.6MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 818M/1.14G [00:29<00:11, 26.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 823M/1.14G [00:29<00:09, 31.5MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 826M/1.14G [00:29<00:11, 27.8MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 829M/1.14G [00:30<00:12, 24.7MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 832M/1.14G [00:30<00:11, 25.7MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 835M/1.14G [00:30<00:13, 22.5MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 839M/1.14G [00:30<00:10, 27.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 844M/1.14G [00:30<00:10, 28.9MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 847M/1.14G [00:30<00:09, 29.0MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 850M/1.14G [00:30<00:10, 26.9MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 854M/1.14G [00:30<00:09, 28.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 859M/1.14G [00:31<00:08, 32.8MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 863M/1.14G [00:31<00:09, 28.5MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 866M/1.14G [00:31<00:10, 25.1MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 870M/1.14G [00:31<00:09, 27.1MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 875M/1.14G [00:31<00:08, 31.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 878M/1.14G [00:31<00:09, 27.9MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 881M/1.14G [00:31<00:10, 24.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 885M/1.14G [00:32<00:09, 26.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 890M/1.14G [00:32<00:07, 31.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 894M/1.14G [00:32<00:08, 28.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 897M/1.14G [00:32<00:09, 24.8MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 901M/1.14G [00:32<00:08, 26.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 906M/1.14G [00:32<00:07, 31.6MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 909M/1.14G [00:32<00:08, 27.8MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 912M/1.14G [00:33<00:09, 24.8MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 916M/1.14G [00:33<00:08, 26.5MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 921M/1.14G [00:33<00:06, 31.7MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 925M/1.14G [00:33<00:07, 27.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 928M/1.14G [00:33<00:08, 24.7MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 932M/1.14G [00:33<00:07, 26.6MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 937M/1.14G [00:33<00:06, 31.2MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 940M/1.14G [00:34<00:07, 27.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 943M/1.14G [00:34<00:07, 24.9MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 948M/1.14G [00:34<00:06, 27.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 952M/1.14G [00:34<00:05, 31.1MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 956M/1.14G [00:34<00:06, 27.5MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 959M/1.14G [00:34<00:07, 25.1MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 963M/1.14G [00:34<00:05, 29.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 966M/1.14G [00:34<00:06, 28.0MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 969M/1.14G [00:35<00:06, 24.9MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 973M/1.14G [00:35<00:06, 27.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 978M/1.14G [00:35<00:05, 31.5MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 982M/1.14G [00:35<00:05, 27.7MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 985M/1.14G [00:35<00:06, 24.6MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 989M/1.14G [00:35<00:05, 27.1MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 994M/1.14G [00:35<00:04, 31.6MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 997M/1.14G [00:36<00:05, 27.4MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.00G/1.14G [00:36<00:05, 24.7MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.00G/1.14G [00:36<00:04, 27.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.01G/1.14G [00:36<00:04, 31.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.01G/1.14G [00:36<00:04, 27.3MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.02G/1.14G [00:36<00:04, 24.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.02G/1.14G [00:36<00:04, 26.9MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.02G/1.14G [00:37<00:03, 31.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.03G/1.14G [00:37<00:03, 27.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.03G/1.14G [00:37<00:04, 24.5MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.04G/1.14G [00:37<00:03, 27.0MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.04G/1.14G [00:37<00:03, 30.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.04G/1.14G [00:37<00:03, 26.8MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.05G/1.14G [00:37<00:03, 26.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.05G/1.14G [00:37<00:02, 30.1MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.05G/1.14G [00:38<00:03, 26.2MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:03, 26.5MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:02, 30.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:02, 26.3MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 26.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 30.3MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 26.3MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.08G/1.14G [00:39<00:02, 26.6MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.08G/1.14G [00:39<00:01, 29.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.08G/1.14G [00:39<00:02, 25.9MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.09G/1.14G [00:39<00:01, 26.8MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.09G/1.14G [00:39<00:01, 29.9MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.09G/1.14G [00:39<00:01, 26.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:39<00:01, 26.8MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:39<00:01, 29.9MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:40<00:01, 26.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.11G/1.14G [00:40<00:01, 27.1MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.11G/1.14G [00:40<00:00, 29.9MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.12G/1.14G [00:40<00:00, 25.9MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.12G/1.14G [00:40<00:00, 26.9MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.12G/1.14G [00:40<00:00, 29.8MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 25.9MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 27.0MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 29.8MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.14G/1.14G [00:41<00:00, 25.8MiB/s]

  0%|          | 0.00/104M [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.14G/1.14G [00:42<00:00, 26.9MiB/s]


  9%|â–Š         | 8.92M/104M [00:00<00:01, 89.2MiB/s][A

 20%|â–ˆâ–‰        | 20.7M/104M [00:00<00:00, 106MiB/s] [A

 31%|â–ˆâ–ˆâ–ˆ       | 32.3M/104M [00:00<00:00, 111MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44.0M/104M [00:00<00:00, 113MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55.6M/104M [00:00<00:00, 114MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67.5M/104M [00:00<00:00, 116MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79.1M/104M [00:00<00:00, 116MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91.0M/104M [00:00<00:00, 117MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 103M/104M [00:00<00:00, 117MiB/s] [A/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Downloading: "https://dl.fbaipublicfiles.com/encodec/v0/encodec_24khz-d7cc33bc.th" to /home/n0x/.cache/torch/hub/checkpoints/encodec_24khz-d7cc33bc.th
 > Model's license - MIT
 > Check https://choosealicense.com/licenses/mit/ for more info.
 > Using model: bark

  0%|          | 0.00/88.9M [00:00<?, ?B/s]
  9%|â–Š         | 7.75M/88.9M [00:00<00:01, 81.2MB/s]
 21%|â–ˆâ–ˆâ–       | 19.0M/88.9M [00:00<00:00, 103MB/s] 
 34%|â–ˆâ–ˆâ–ˆâ–      | 30.2M/88.9M [00:00<00:00, 109MB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 41.5M/88.9M [00:00<00:00, 112MB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 52.8M/88.9M [00:00<00:00, 114MB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 64.0M/88.9M [00:00<00:00, 115MB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 75.2M/88.9M [00:00<00:00, 116MB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 86.5M/88.9M [00:00<00:00, 116MB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88.9M/88.9M [00:00<00:00, 113MB/s]
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 19, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/bark").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104M/104M [00:11<00:00, 9.26MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 19, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/bark").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 19, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/bark").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 5, in <module>
    from tortoise.api import TTS
ImportError: cannot import name 'TTS' from 'tortoise.api' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63
    gen_audio = tts.tts_with_preset(
                                    ^
IndentationError: unindent does not match any outer indentation level
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [97811]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:54290 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in generate_audio
    gen_audio = tts.tts_with_preset(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 321, in tts_with_preset
    return self.tts(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 384, in tts
    auto_conditioning, diffusion_conditioning, auto_conds, _ = self.get_conditioning_latents(voice_samples, return_mels=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 266, in get_conditioning_latents
    auto_conds.append(format_conditioning(vs, device=self.device))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 82, in format_conditioning
    clip = clip[:, rand_start:rand_start + cond_length]
IndexError: too many indices for tensor of dimension 1
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [97811]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [99231]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
INFO:     127.0.0.1:41374 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 83, in generate_audio
    gen_audio = tts.tts_with_preset(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 321, in tts_with_preset
    return self.tts(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 384, in tts
    auto_conditioning, diffusion_conditioning, auto_conds, _ = self.get_conditioning_latents(voice_samples, return_mels=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 266, in get_conditioning_latents
    auto_conds.append(format_conditioning(vs, device=self.device))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 83, in format_conditioning
    mel_clip = TorchMelSpectrogram()(clip.unsqueeze(0)).squeeze(0)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py", line 321, in forward
    assert len(inp.shape) == 2
AssertionError
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [99231]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [99676]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:58146 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 83, in generate_audio
    gen_audio = tts.tts_with_preset(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 321, in tts_with_preset
    return self.tts(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 384, in tts
    auto_conditioning, diffusion_conditioning, auto_conds, _ = self.get_conditioning_latents(voice_samples, return_mels=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 260, in get_conditioning_latents
    voice_samples = [v.to(self.device) for v in voice_samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 260, in <listcomp>
    voice_samples = [v.to(self.device) for v in voice_samples]
AttributeError: 'numpy.ndarray' object has no attribute 'to'
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [99676]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [100145]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:45398 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 84, in generate_audio
    gen_audio = tts.tts_with_preset(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 321, in tts_with_preset
    return self.tts(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 384, in tts
    auto_conditioning, diffusion_conditioning, auto_conds, _ = self.get_conditioning_latents(voice_samples, return_mels=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 266, in get_conditioning_latents
    auto_conds.append(format_conditioning(vs, device=self.device))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 82, in format_conditioning
    clip = clip[:, rand_start:rand_start + cond_length]
IndexError: too many indices for tensor of dimension 1
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [100145]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [100609]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:42228 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42240 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42256 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42266 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42274 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42280 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42284 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:42294 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34258 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34268 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34276 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34288 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34298 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34306 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34310 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34318 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34334 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:34340 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51798 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51804 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51808 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51816 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51822 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51824 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51836 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51842 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:51858 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47736 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47746 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47762 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47772 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47780 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47794 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47806 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47816 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47820 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:47832 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37094 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37108 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37116 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37128 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37136 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37142 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37150 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37156 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37166 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:37178 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50852 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50864 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50878 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50882 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50892 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(1, repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     127.0.0.1:50904 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 85, in generate_audio
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [100609]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [101042]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:47326 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:55466 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:55474 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:55476 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:55478 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:55488 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
Initial shape: torch.Size([1, 441000])
INFO:     127.0.0.1:49254 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    voice_samples = process_voice_samples(speaker_wav_path)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 63, in process_voice_samples
    voice_samples = voice_samples.repeat(repeats_needed)
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [101042]
INFO:     Started server process [102016]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:57770 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     127.0.0.1:57784 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     127.0.0.1:57788 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     127.0.0.1:57802 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     127.0.0.1:57810 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     127.0.0.1:57824 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in generate_audio
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 90, in <listcomp>
    reference_clips = [utils.audio.load_audio(p, 22050) for p in clips_paths]
NameError: name 'utils' is not defined
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [102016]
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = api.TextToSpeech()
NameError: name 'api' is not defined. Did you mean: 'app'?
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = api.TextToSpeech()
NameError: name 'api' is not defined. Did you mean: 'app'?
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = api.TextToSpeech()
NameError: name 'api' is not defined. Did you mean: 'app'?
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = api.TextToSpeech()
NameError: name 'api' is not defined. Did you mean: 'app'?
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [102687]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/24 [00:00<?, ?it/s]
  4%|â–         | 1/24 [00:03<01:13,  3.21s/it]
  8%|â–Š         | 2/24 [00:05<00:57,  2.62s/it]
 12%|â–ˆâ–Ž        | 3/24 [00:07<00:47,  2.24s/it]
 17%|â–ˆâ–‹        | 4/24 [00:08<00:40,  2.04s/it]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [102966]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/24 [00:00<?, ?it/s]
  4%|â–         | 1/24 [00:02<00:50,  2.20s/it]
  8%|â–Š         | 2/24 [00:04<00:44,  2.01s/it]
 12%|â–ˆâ–Ž        | 3/24 [00:05<00:39,  1.87s/it]
 17%|â–ˆâ–‹        | 4/24 [00:07<00:37,  1.89s/it]
 21%|â–ˆâ–ˆ        | 5/24 [00:09<00:36,  1.93s/it]
 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:11<00:33,  1.83s/it]
 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:13<00:30,  1.81s/it]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:15<00:30,  1.88s/it]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:17<00:28,  1.90s/it]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:18<00:26,  1.89s/it]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:20<00:24,  1.88s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:22<00:22,  1.88s/it]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:24<00:20,  1.82s/it]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:26<00:17,  1.79s/it]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [00:27<00:15,  1.74s/it]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:28<00:12,  1.54s/it]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:29<00:09,  1.40s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:30<00:07,  1.27s/it]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:31<00:06,  1.24s/it]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [00:33<00:04,  1.19s/it]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:34<00:03,  1.26s/it]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:02,  1.25s/it]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:36<00:01,  1.19s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:37<00:00,  1.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:37<00:00,  1.58s/it]
Computing best candidates using CLVP

  0%|          | 0/24 [00:00<?, ?it/s]
  4%|â–         | 1/24 [00:02<01:03,  2.75s/it]
 12%|â–ˆâ–Ž        | 3/24 [00:03<00:18,  1.11it/s]
 17%|â–ˆâ–‹        | 4/24 [00:03<00:12,  1.60it/s]
 21%|â–ˆâ–ˆ        | 5/24 [00:03<00:10,  1.81it/s]
 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:04<00:08,  2.22it/s]
 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:04<00:06,  2.62it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:04<00:04,  3.28it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:04<00:04,  3.73it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:04<00:03,  4.44it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:05<00:03,  3.88it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:05<00:03,  3.97it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:05<00:02,  4.81it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:05<00:01,  5.55it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [00:05<00:01,  6.21it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:05<00:01,  6.50it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:05<00:01,  6.46it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:06<00:00,  6.59it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:06<00:00,  6.62it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [00:06<00:00,  6.58it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:06<00:00,  6.54it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:06<00:00,  6.60it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:06<00:00,  6.49it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:06<00:00,  6.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:06<00:00,  3.45it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/80 [00:00<?, ?it/s]
  2%|â–Ž         | 2/80 [00:00<00:05, 14.57it/s]
  5%|â–Œ         | 4/80 [00:00<00:04, 16.15it/s]
  8%|â–Š         | 6/80 [00:00<00:04, 17.51it/s]
 10%|â–ˆ         | 8/80 [00:00<00:04, 14.82it/s]
 14%|â–ˆâ–        | 11/80 [00:00<00:03, 17.25it/s]
 16%|â–ˆâ–‹        | 13/80 [00:00<00:03, 17.86it/s]
 20%|â–ˆâ–ˆ        | 16/80 [00:00<00:03, 19.85it/s]
 24%|â–ˆâ–ˆâ–       | 19/80 [00:01<00:02, 20.92it/s]
 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:01<00:02, 21.61it/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:01<00:02, 22.07it/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:01<00:02, 22.46it/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:01<00:02, 22.13it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:01<00:02, 22.25it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:01<00:01, 21.92it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:01<00:01, 22.24it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:02<00:01, 21.98it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [00:02<00:01, 21.89it/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [00:02<00:01, 22.55it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [00:02<00:01, 23.01it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [00:02<00:01, 23.39it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [00:02<00:00, 23.64it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [00:02<00:00, 23.79it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [00:02<00:00, 23.86it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [00:03<00:00, 23.98it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [00:03<00:00, 24.11it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [00:03<00:00, 24.13it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [00:03<00:00, 24.11it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [00:03<00:00, 24.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:03<00:00, 22.01it/s]
/home/n0x/vocal-fun-ai-node/./tts.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(gen_audio).unsqueeze(0),
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py:245: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  src = src.T
INFO:     127.0.0.1:55292 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 94, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f3c7f0b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f3c7f0637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f3bf61df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f3bf61dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f3bf61e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f3bf61d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f3bf61dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f3b8fb30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f3b8fb28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55b2271de282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55b2271d4b4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55b2271ebebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55b2271c89a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f3c80f0e59e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f3c80f0e3b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55b2271d4b4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55b22731c10a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55b2271d1c1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55b2271ceeed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/24 [00:00<?, ?it/s]
  4%|â–         | 1/24 [00:01<00:45,  2.00s/it]
  8%|â–Š         | 2/24 [00:03<00:42,  1.92s/it]
 12%|â–ˆâ–Ž        | 3/24 [00:06<00:43,  2.08s/it]
 17%|â–ˆâ–‹        | 4/24 [00:08<00:41,  2.09s/it]
 21%|â–ˆâ–ˆ        | 5/24 [00:09<00:37,  1.95s/it]
 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:11<00:33,  1.88s/it]
 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:13<00:32,  1.93s/it]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:15<00:30,  1.89s/it]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:17<00:28,  1.90s/it]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:20<00:29,  2.12s/it]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:21<00:24,  1.87s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:22<00:19,  1.67s/it]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:23<00:16,  1.52s/it]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:25<00:14,  1.44s/it]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [00:26<00:12,  1.44s/it]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:27<00:10,  1.36s/it]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:28<00:09,  1.30s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:29<00:07,  1.25s/it]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:31<00:06,  1.23s/it]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [00:32<00:04,  1.20s/it]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:03,  1.26s/it]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:34<00:02,  1.27s/it]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:36<00:01,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:37<00:00,  1.21s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:37<00:00,  1.55s/it]
Computing best candidates using CLVP

  0%|          | 0/24 [00:00<?, ?it/s]
  8%|â–Š         | 2/24 [00:00<00:01, 15.50it/s]
 17%|â–ˆâ–‹        | 4/24 [00:00<00:01, 12.68it/s]
 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:00<00:01, 12.01it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:00<00:01, 11.77it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:00<00:01, 11.08it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:01<00:01, 10.70it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:01<00:00, 10.85it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:01<00:00, 10.82it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:01<00:00, 10.82it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [00:01<00:00, 10.66it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:01<00:00, 10.89it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.03it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.15it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/80 [00:00<?, ?it/s]
  4%|â–         | 3/80 [00:00<00:03, 23.54it/s]
  9%|â–‰         | 7/80 [00:00<00:02, 27.78it/s]
 14%|â–ˆâ–        | 11/80 [00:00<00:02, 29.01it/s]
 19%|â–ˆâ–‰        | 15/80 [00:00<00:02, 29.57it/s]
 24%|â–ˆâ–ˆâ–       | 19/80 [00:00<00:02, 29.88it/s]
 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:00<00:01, 30.02it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:00<00:01, 30.14it/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:01<00:01, 30.13it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:01<00:01, 30.24it/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:01<00:01, 30.36it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:01<00:01, 30.36it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [00:01<00:01, 30.35it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [00:01<00:00, 30.34it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [00:01<00:00, 30.22it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [00:01<00:00, 29.79it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [00:02<00:00, 29.98it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [00:02<00:00, 30.05it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [00:02<00:00, 30.16it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [00:02<00:00, 30.25it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [00:02<00:00, 30.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.94it/s]
INFO:     127.0.0.1:42216 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 94, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f3c7f0b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f3c7f0637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f3bf61df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f3bf61dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f3bf61e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f3bf61d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f3bf61dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f3b8fb30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f3b8fb28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55b2271de282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55b2271d4b4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55b2271ebebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55b2271c89a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55b2271cab57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55b2271fab40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f3c80f0e59e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f3c80f0e3b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55b2271d4b4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55b22731c10a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55b2271d1c1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55b2271ceeed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55b2271c8ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55b2271cdb7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55b2271deaec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/24 [00:00<?, ?it/s]
  4%|â–         | 1/24 [00:01<00:33,  1.44s/it]
  8%|â–Š         | 2/24 [00:03<00:33,  1.52s/it]
 12%|â–ˆâ–Ž        | 3/24 [00:04<00:29,  1.41s/it]
 17%|â–ˆâ–‹        | 4/24 [00:05<00:26,  1.31s/it]
 21%|â–ˆâ–ˆ        | 5/24 [00:07<00:27,  1.44s/it]
 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:31,  1.74s/it]
 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:33,  1.99s/it]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [104110]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.16s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.05s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.02s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.66it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  4.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.40it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.49it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 10%|â–ˆ         | 3/30 [00:00<00:00, 29.86it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 49.68it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:00<00:00, 55.10it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 57.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 55.78it/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py:245: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  src = src.T
INFO:     127.0.0.1:50896 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.16s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.30s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.17s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.30it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.12it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 34.47it/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:00<00:00, 50.23it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:00<00:00, 55.53it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 57.78it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 55.78it/s]
INFO:     127.0.0.1:37790 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.18s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.23s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.48s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.78s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.14it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.07it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.38it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 34.25it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:00, 39.77it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 42.05it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 39.21it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:00<00:00, 37.80it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 39.97it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 39.76it/s]
INFO:     127.0.0.1:49902 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:08,  2.74s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.44s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.13s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  1.98s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.12s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.58it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.83it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.27it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 40.06it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 42.55it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 45.30it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 46.75it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 47.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 47.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 46.17it/s]
INFO:     127.0.0.1:60040 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.02s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.02s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.02s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.02s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.50it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.73it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 41.82it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 42.64it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 40.18it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 41.79it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 42.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 42.50it/s]
INFO:     127.0.0.1:59142 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.78s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.73s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.54s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.69s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.68s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  9.61it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.94it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.97it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 43.48it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 43.59it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 43.84it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 42.99it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 43.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.43it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.39it/s]
INFO:     127.0.0.1:35020 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    torchaudio.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.28s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.20s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.76s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.55s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.72s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.13it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.05it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 58.97it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 60.78it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 61.48it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 61.83it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 61.46it/s]
INFO:     127.0.0.1:53250 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.24s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.11s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.19s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.07it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.09it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:00<00:00, 60.98it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 61.14it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:00<00:00, 60.83it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 60.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 60.35it/s]
INFO:     127.0.0.1:49718 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.13s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.19s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.23s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.21s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.40it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.02it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 58.59it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 60.21it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 60.69it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 60.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 60.58it/s]
INFO:     127.0.0.1:45580 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.14s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.32s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.26s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.24s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.24s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.00it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 57.77it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 59.61it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 60.28it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 60.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 60.06it/s]
INFO:     127.0.0.1:54436 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.26s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.20s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.21s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.21s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.40it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.13it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:00<00:00, 60.73it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 60.55it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:00<00:00, 60.24it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 60.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 60.55it/s]
INFO:     127.0.0.1:56490 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.26s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.85s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:02,  2.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.71s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.76s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.12it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:00<00:00, 60.83it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 61.37it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:00<00:00, 59.73it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 60.30it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 60.08it/s]
INFO:     127.0.0.1:36086 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.21s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.31s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.29s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.36s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.33s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.52it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 55.42it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 58.50it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 57.58it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 58.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 58.33it/s]
INFO:     127.0.0.1:60692 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # Save with correct dimensions [channels, samples]
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.38s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.24s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.25s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.19s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.22s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.93it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 57.24it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 59.75it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 60.79it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 58.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 58.99it/s]
INFO:     127.0.0.1:52884 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.09s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.08s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.07s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 15.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.07it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 49.73it/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:00<00:00, 47.03it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:00<00:00, 53.84it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 56.99it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 55.65it/s]
INFO:     127.0.0.1:59146 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 102, in generate_audio
    # tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 313, in save
    return backend.save(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 316, in save
    save_audio(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py", line 257, in save_audio
    s.write_audio_chunk(0, src)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py", line 469, in write_audio_chunk
    self._s.write_audio_chunk(i, chunk, pts)
RuntimeError: Input Tensor has to be 2D.
Exception raised from validate_audio_input at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_writer/tensor_converter.cpp:31 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9e034b9446 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9e034637ad in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x57287 (0x7f9d7a5df287 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #3: <unknown function> + 0x57c3c (0x7f9d7a5dfc3c in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #4: torio::io::TensorConverter::convert(at::Tensor const&) + 0x33 (0x7f9d7a5e1863 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #5: torio::io::EncodeProcess::process(at::Tensor const&, std::optional<double> const&) + 0xbe (0x7f9d7a5d072e in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #6: torio::io::StreamingMediaEncoder::write_audio_chunk(int, at::Tensor const&, std::optional<double> const&) + 0xa5 (0x7f9d7a5dbec5 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/libtorio_ffmpeg4.so)
frame #7: <unknown function> + 0x39496 (0x7f9d13f30496 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #8: <unknown function> + 0x31d47 (0x7f9d13f28d47 in /home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torio/lib/_torio_ffmpeg4.so)
frame #9: <unknown function> + 0x18b282 (0x55849a2f9282 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #10: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #11: <unknown function> + 0x198ebb (0x55849a306ebb in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #12: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #13: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #14: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #15: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #16: _PyEval_EvalFrameDefault + 0x6d2 (0x55849a2e39a2 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #17: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #18: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #19: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #20: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #21: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #22: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #23: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #25: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #27: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #29: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #31: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #33: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #35: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #36: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #37: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #38: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #39: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #40: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #41: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #42: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #43: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #44: _PyEval_EvalFrameDefault + 0x2887 (0x55849a2e5b57 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #45: <unknown function> + 0x1a7b40 (0x55849a315b40 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #46: <unknown function> + 0x959e (0x7f9e0530759e in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #47: <unknown function> + 0x93b4 (0x7f9e053073b4 in /usr/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so)
frame #48: _PyObject_MakeTpCall + 0x25b (0x55849a2efb4b in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #49: <unknown function> + 0x2c910a (0x55849a43710a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #50: <unknown function> + 0x17ec1f (0x55849a2ecc1f in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #51: _PyEval_EvalFrameDefault + 0x6c1d (0x55849a2e9eed in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #52: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #53: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #54: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #55: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #56: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #57: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #58: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #59: _PyEval_EvalFrameDefault + 0x818 (0x55849a2e3ae8 in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #60: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #61: _PyEval_EvalFrameDefault + 0x58aa (0x55849a2e8b7a in /home/n0x/vocal-fun-ai-node/venv/bin/python)
frame #62: _PyFunction_Vectorcall + 0x7c (0x55849a2f9aec in /home/n0x/vocal-fun-ai-node/venv/bin/python)

INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [104110]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 218, in __init__
    self.autoregressive.post_init_gpt2_config(use_deepspeed=use_deepspeed, kv_cache=kv_cache, half=self.half)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/autoregressive.py", line 380, in post_init_gpt2_config
    import deepspeed
ModuleNotFoundError: No module named 'deepspeed'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [105333]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.57s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.25s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.11s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.18s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.58it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  4.33it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.02it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.97it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.42it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 10%|â–ˆ         | 3/30 [00:00<00:00, 28.44it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:00, 38.95it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 42.44it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:00<00:00, 44.21it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:00<00:00, 45.21it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 46.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.90it/s]
INFO:     127.0.0.1:44434 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44446 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.15s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.15s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.20s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.73it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 39.85it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:00, 40.93it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 41.41it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 42.16it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 40.57it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:00<00:00, 39.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 40.35it/s]
INFO:     127.0.0.1:44446 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.26s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.23s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:15<00:04,  4.94s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.77s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.90s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.27it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.53it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
  3%|â–Ž         | 1/30 [00:00<00:04,  6.80it/s]
  7%|â–‹         | 2/30 [00:00<00:03,  8.37it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:02,  9.42it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:02,  9.92it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:02, 10.22it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:01<00:01, 10.47it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:01, 10.67it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:01<00:01, 10.87it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:01<00:01, 11.00it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:01<00:01, 11.16it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:01<00:00, 11.39it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:02<00:00, 11.54it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:02<00:00, 11.68it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:02<00:00, 11.79it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:02<00:00, 11.90it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 12.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 11.08it/s]
INFO:     127.0.0.1:48652 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [105333]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 218, in __init__
    self.autoregressive.post_init_gpt2_config(use_deepspeed=use_deepspeed, kv_cache=kv_cache, half=self.half)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/autoregressive.py", line 380, in post_init_gpt2_config
    import deepspeed
ModuleNotFoundError: No module named 'deepspeed'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 24, in <module>
    tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True, device='cuda' if torch.cuda.is_available() else 'cpu')
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py", line 218, in __init__
    self.autoregressive.post_init_gpt2_config(use_deepspeed=use_deepspeed, kv_cache=kv_cache, half=self.half)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/autoregressive.py", line 380, in post_init_gpt2_config
    import deepspeed
ModuleNotFoundError: No module named 'deepspeed'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [106762]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.84s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.42s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.30s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.28s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.05it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.10it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.73it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.27it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.98it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 10%|â–ˆ         | 3/30 [00:00<00:00, 27.34it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:00, 38.74it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 42.24it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:00<00:00, 44.23it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:00<00:00, 45.70it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 46.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.92it/s]
INFO:     127.0.0.1:46752 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.24s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.27s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.28s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.24s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.25s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.50it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.80it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 33.57it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:00, 37.94it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 40.28it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 41.29it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 41.44it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:00<00:00, 42.11it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 40.85it/s]
INFO:     127.0.0.1:46752 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:09<00:27,  9.16s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:18<00:18,  9.25s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:26<00:08,  8.61s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:34<00:00,  8.43s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:34<00:00,  8.62s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.85it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.97it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
  3%|â–Ž         | 1/30 [00:00<00:07,  4.01it/s]
  7%|â–‹         | 2/30 [00:00<00:05,  4.68it/s]
 10%|â–ˆ         | 3/30 [00:00<00:05,  5.04it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:04,  5.24it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:04,  5.37it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:01<00:04,  5.49it/s]
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:01<00:04,  5.62it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:03,  5.72it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  5.81it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:01<00:03,  5.91it/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:03,  6.01it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:02<00:02,  6.15it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:02<00:02,  6.78it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  7.27it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:01,  7.71it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:02<00:01,  8.07it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  8.37it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01,  8.64it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:02<00:01,  8.86it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:03<00:01,  9.07it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:03<00:00,  9.20it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:03<00:00,  9.35it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:03<00:00,  9.46it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  9.60it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:03<00:00,  9.64it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  9.74it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:03<00:00,  9.95it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00, 10.11it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  7.48it/s]
INFO:     127.0.0.1:51496 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [106762]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [107736]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.44s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.17s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.08s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.15it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  8.95it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.82it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 32.72it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:00, 40.33it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 43.60it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 44.99it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 46.15it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:00<00:00, 46.91it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 44.77it/s]
INFO:     127.0.0.1:46596 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.05s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.02s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 10.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.94it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 47.52it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 48.04it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 47.13it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 47.82it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 47.50it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 47.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 47.67it/s]
INFO:     127.0.0.1:46596 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.22s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.25s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.16s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.67it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 34.59it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:00, 39.77it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:00<00:00, 41.38it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 43.06it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 43.82it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:00<00:00, 44.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 42.86it/s]
INFO:     127.0.0.1:52310 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.21it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.19it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.18it/s]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.77it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 44.32it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 44.96it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 45.45it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 45.87it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 46.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 46.46it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 45.98it/s]
INFO:     127.0.0.1:34114 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.53s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.46s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.45s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.40s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.43s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.78it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 13%|â–ˆâ–Ž        | 4/30 [00:00<00:00, 31.66it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:00, 32.32it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:00<00:00, 32.98it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:00<00:00, 33.51it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 33.39it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:00<00:00, 33.71it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 33.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 33.44it/s]
INFO:     127.0.0.1:41428 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.12s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.10s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.04s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.74it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.84it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 47.03it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 46.29it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 46.62it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 46.48it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 45.95it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 46.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 46.51it/s]
INFO:     127.0.0.1:38564 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.47it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.52it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.44it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.53it/s]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.92it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 48.19it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 48.91it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:00<00:00, 49.55it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:00<00:00, 49.70it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 50.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 49.75it/s]
INFO:     127.0.0.1:56288 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.17s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.20s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.19s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 12.74it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.84it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 40.63it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 41.71it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:00<00:00, 42.52it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 42.75it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:00<00:00, 42.44it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 42.79it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 42.49it/s]
INFO:     127.0.0.1:37104 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [107736]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [15533]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.48s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.24s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.16s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.12s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.17s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  7.83it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  5.54it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.87it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 10%|â–ˆ         | 3/30 [00:00<00:00, 29.86it/s]
 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:00, 39.02it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 41.98it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:00<00:00, 43.51it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:00<00:00, 44.14it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 45.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 43.38it/s]
INFO:     127.0.0.1:52592 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52592 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:25,  8.41s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:15<00:15,  7.80s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:22<00:07,  7.38s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.24s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.42s/it]
Computing best candidates using CLVP

/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location="cpu")
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.autoregressive.load_state_dict(torch.load(get_model_path('autoregressive.pth', models_dir)), strict=False)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(get_model_path('diffusion_decoder.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(get_model_path('clvp2.pth', models_dir)))
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/api.py:233: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.vocoder.load_state_dict(torch.load(get_model_path('vocoder.pth', models_dir), map_location=torch.device('cpu'))['model_g'])
INFO:     Started server process [19438]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.18s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.02s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.00s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.09it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.67it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 47.14it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:00<00:00, 59.15it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 63.16it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:00<00:00, 65.12it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 63.37it/s]
INFO:     127.0.0.1:53566 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53566 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/tortoise/models/arch_util.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.mel_norms = torch.load(self.mel_norm_file)
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.28it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.30it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.28it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.31it/s]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 16.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.71it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 53.44it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 62.12it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 65.09it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 66.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 65.05it/s]
INFO:     127.0.0.1:37488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37488 - "POST /generate_audio HTTP/1.1" 200 OK
Generating autoregressive samples..

  0%|          | 0/4 [00:00<?, ?it/s]
 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.01it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.08s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/it]
Computing best candidates using CLVP

  0%|          | 0/4 [00:00<?, ?it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 16.25it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 15.90it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 15.94it/s]
Transforming autoregressive outputs into audio..

  0%|          | 0/30 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:00, 52.84it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:00<00:00, 61.53it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:00<00:00, 64.55it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 64.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 63.57it/s]
INFO:     127.0.0.1:37488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38820 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38820 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44074 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44074 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [19438]
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 1, in <module>
    from fastapi import FastAPI
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/__init__.py", line 7, in <module>
    from .applications import FastAPI as FastAPI
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 3, in <module>
    from fastapi import routing
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 20, in <module>
    from fastapi import params
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/params.py", line 4, in <module>
    from pydantic.fields import FieldInfo, Undefined
ImportError: cannot import name 'Undefined' from 'pydantic.fields' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/pydantic/fields.py)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 1, in <module>
    from fastapi import FastAPI
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/__init__.py", line 7, in <module>
    from .applications import FastAPI as FastAPI
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 3, in <module>
    from fastapi import routing
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 20, in <module>
    from fastapi import params
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/params.py", line 4, in <module>
    from pydantic.fields import FieldInfo, Undefined
ImportError: cannot import name 'Undefined' from 'pydantic.fields' (/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/pydantic/fields.py)
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1.1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v1.1'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1.1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v1.1'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1.1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v1.1'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1.1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v1.1'
 > You must agree to the terms of service to use this model.
 | > Please see the terms of service at https://coqui.ai/cpml.txt
 | > "I have read, understood and agreed the Terms and Conditions." - [y/n]
 | | >  > Downloading model to /home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1

0.00iB [00:00, ?iB/s]
0.00iB [00:00, ?iB/s]
 > Model's license - CPML
 > Check https://coqui.ai/cpml.txt for more info.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 95, in load_config
    data = read_json_with_comments(config_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 22, in read_json_with_comments
    data = json.loads(input_str)
  File "/usr/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
 > tts_models/multilingual/multi-dataset/xtts_v1 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 95, in load_config
    data = read_json_with_comments(config_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 22, in read_json_with_comments
    data = json.loads(input_str)
  File "/usr/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
 > tts_models/multilingual/multi-dataset/xtts_v1 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 95, in load_config
    data = read_json_with_comments(config_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 22, in read_json_with_comments
    data = json.loads(input_str)
  File "/usr/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
 > tts_models/multilingual/multi-dataset/xtts_v1 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v1").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 95, in load_config
    data = read_json_with_comments(config_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 22, in read_json_with_comments
    data = json.loads(input_str)
  File "/usr/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'tortoise-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'tortoise-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'tortoise-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts-v2'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v2'
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
 > Failed to download the model file to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/lib/python3.10/socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7fb5283934c0>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fb5283934c0>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/en/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 361, in download_model
    raise e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 354, in download_model
    self._download_github_model(model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 252, in _download_github_model
    self._download_model_files(model_item["github_rls_url"], output_path, self.progress_bar)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 547, in _download_model_files
    r = requests.get(file_url, stream=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fb5283934c0>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
 > Failed to download the model file to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/lib/python3.10/socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7f0c72e52710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f0c72e52710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/en/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 361, in download_model
    raise e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 354, in download_model
    self._download_github_model(model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 252, in _download_github_model
    self._download_model_files(model_item["github_rls_url"], output_path, self.progress_bar)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 547, in _download_model_files
    r = requests.get(file_url, stream=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f0c72e52710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
 > Failed to download the model file to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/lib/python3.10/socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7f62fec7b370>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f62fec7b370>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/en/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 361, in download_model
    raise e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 354, in download_model
    self._download_github_model(model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 252, in _download_github_model
    self._download_model_files(model_item["github_rls_url"], output_path, self.progress_bar)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 547, in _download_model_files
    r = requests.get(file_url, stream=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f62fec7b370>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
 > Failed to download the model file to /home/n0x/.local/share/tts/tts_models--en--multi-dataset--tortoise-v2
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/lib/python3.10/socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7fd1789ba710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fd1789ba710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/en/multi-dataset/tortoise-v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 361, in download_model
    raise e
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 354, in download_model
    self._download_github_model(model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 252, in _download_github_model
    self._download_model_files(model_item["github_rls_url"], output_path, self.progress_bar)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 547, in _download_model_files
    r = requests.get(file_url, stream=True)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='app.coqui.ai', port=443): Max retries exceeded with url: /tts_model/autoregressive.pth (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fd1789ba710>: Failed to resolve 'app.coqui.ai' ([Errno -2] Name or service not known)"))
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 369, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 392, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 179, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 142, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 337, in download_model
    model_item, model_full_name, model = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 294, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
INFO:     Started server process [41389]
INFO:uvicorn.error:Started server process [41389]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [41389]
INFO:uvicorn.error:Finished server process [41389]
 > tts_models/en/vctk/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > initialization of speaker-embedding layers.
INFO:     Started server process [41682]
INFO:uvicorn.error:Started server process [41682]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [41682]
INFO:uvicorn.error:Finished server process [41682]
 > tts_models/en/vctk/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > initialization of speaker-embedding layers.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 81, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 185, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/config/__init__.py", line 91, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
NotADirectoryError: [Errno 20] Not a directory: '/home/n0x/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2/model.pth/config.json'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [44317]
INFO:uvicorn.error:Started server process [44317]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [44317]
INFO:uvicorn.error:Finished server process [44317]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [44834]
INFO:uvicorn.error:Started server process [44834]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [44834]
INFO:uvicorn.error:Finished server process [44834]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [45814]
INFO:uvicorn.error:Started server process [45814]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [45814]
INFO:uvicorn.error:Finished server process [45814]
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.speakers = torch.load(speaker_file_path)
/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [46777]
INFO:uvicorn.error:Started server process [46777]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.855548620223999
 > Real-time factor: 0.6241586385760797
INFO:     127.0.0.1:50852 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50852 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [46777]
INFO:uvicorn.error:Finished server process [46777]
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 419, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 442, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 419, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 442, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
 > tts_models/multilingual/multi-dataset/your_tts is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/your_tts").to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 419, in download_model
    output_model_path, output_config_path = self._find_files(output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 442, in _find_files
    raise ValueError(" [!] Model file not found in the output path")
ValueError:  [!] Model file not found in the output path
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:881: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ar_path, map_location=torch.device("cpu"))
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:888: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(diff_path), strict=strict)
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:891: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(clvp_path), strict=strict)
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:896: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [47762]
INFO:uvicorn.error:Started server process [47762]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
 > tts_models/en/multi-dataset/tortoise-v2 is already downloaded.
 > Using model: tortoise
INFO:     127.0.0.1:58512 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 332, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 233, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 332, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 233, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [47762]
INFO:uvicorn.error:Finished server process [47762]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:881: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ar_path, map_location=torch.device("cpu"))
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:888: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.diffusion.load_state_dict(torch.load(diff_path), strict=strict)
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:891: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.clvp.load_state_dict(torch.load(clvp_path), strict=strict)
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:896: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
INFO:     Started server process [47994]
INFO:uvicorn.error:Started server process [47994]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:485: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py:492: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(
 > tts_models/en/multi-dataset/tortoise-v2 is already downloaded.
 > Using model: tortoise
 > Text splitted to sentences.
['Make America great again!!!']
Generating autoregressive samples..

  0%|          | 0/16 [00:00<?, ?it/s]
  0%|          | 0/16 [00:00<?, ?it/s]
INFO:     127.0.0.1:57284 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 334, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 276, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 386, in tts
    outputs = self.tts_model.synthesize(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 526, in synthesize
    outputs = self.inference_with_config(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 596, in inference_with_config
    return self.inference(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 722, in inference
    codes = autoregressive.inference_speech(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/tortoise/autoregressive.py", line 599, in inference_speech
    gen = self.inference_model.generate(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2012, in generate
    self._validate_model_kwargs(model_kwargs.copy())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 1388, in _validate_model_kwargs
    raise ValueError(
ValueError: The following `model_kwargs` are not used by the model: ['speaker_wav'] (note: typos in the generate arguments will also show up in this list)
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 334, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 276, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 386, in tts
    outputs = self.tts_model.synthesize(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 526, in synthesize
    outputs = self.inference_with_config(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 596, in inference_with_config
    return self.inference(text, **settings)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/tortoise.py", line 722, in inference
    codes = autoregressive.inference_speech(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/tortoise/autoregressive.py", line 599, in inference_speech
    gen = self.inference_model.generate(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2012, in generate
    self._validate_model_kwargs(model_kwargs.copy())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 1388, in _validate_model_kwargs
    raise ValueError(
ValueError: The following `model_kwargs` are not used by the model: ['speaker_wav'] (note: typos in the generate arguments will also show up in this list)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [47994]
INFO:uvicorn.error:Finished server process [47994]
/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
INFO:     Started server process [48539]
INFO:uvicorn.error:Started server process [48539]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
 > tts_models/en/vctk/vits is already downloaded.
 > Using model: vits
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > initialization of speaker-embedding layers.
 > Text splitted to sentences.
['Make America great again!!!']
INFO:     127.0.0.1:36142 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 334, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 276, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 398, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/utils/synthesis.py", line 221, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/utils/synthesis.py", line 53, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/vits.py", line 1161, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/vocoder/models/hifigan_generator.py", line 251, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 74, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 334, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 276, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 398, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/utils/synthesis.py", line 221, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/utils/synthesis.py", line 53, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/vits.py", line 1161, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/vocoder/models/hifigan_generator.py", line 251, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [48539]
INFO:uvicorn.error:Finished server process [48539]
 > Downloading model to /home/n0x/.local/share/tts/tts_models--en--ek1--tacotron2

  0%|          | 0.00/347M [00:00<?, ?iB/s]
  1%|          | 4.21M/347M [00:00<00:17, 19.6MiB/s]
  2%|â–         | 8.42M/347M [00:00<00:17, 19.5MiB/s]
  3%|â–Ž         | 10.5M/347M [00:00<00:25, 13.3MiB/s]
  6%|â–Œ         | 19.8M/347M [00:00<00:10, 30.2MiB/s]
  7%|â–‹         | 24.3M/347M [00:01<00:12, 26.8MiB/s]
  9%|â–‰         | 31.5M/347M [00:01<00:11, 27.7MiB/s]
 12%|â–ˆâ–        | 41.9M/347M [00:01<00:09, 32.3MiB/s]
 15%|â–ˆâ–Œ        | 52.4M/347M [00:01<00:08, 35.1MiB/s]
 16%|â–ˆâ–‹        | 56.7M/347M [00:02<00:13, 21.3MiB/s]
 18%|â–ˆâ–Š        | 60.9M/347M [00:02<00:13, 20.6MiB/s]
 18%|â–ˆâ–Š        | 63.5M/347M [00:02<00:16, 17.3MiB/s]
 21%|â–ˆâ–ˆ        | 73.4M/347M [00:03<00:11, 23.3MiB/s]
 24%|â–ˆâ–ˆâ–       | 83.9M/347M [00:03<00:09, 28.6MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 94.4M/347M [00:03<00:07, 32.0MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 105M/347M [00:03<00:07, 34.3MiB/s] 
 31%|â–ˆâ–ˆâ–ˆâ–      | 109M/347M [00:04<00:07, 30.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 113M/347M [00:04<00:08, 27.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 116M/347M [00:04<00:11, 19.3MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 118M/347M [00:05<00:15, 15.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 120M/347M [00:05<00:14, 15.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 122M/347M [00:05<00:14, 15.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 124M/347M [00:05<00:13, 16.6MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 126M/347M [00:05<00:13, 16.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 127M/347M [00:05<00:17, 12.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 136M/347M [00:05<00:10, 21.0MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147M/347M [00:06<00:07, 27.4MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 149M/347M [00:06<00:08, 23.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152M/347M [00:06<00:15, 13.0MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 153M/347M [00:07<00:15, 12.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 155M/347M [00:07<00:14, 13.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 157M/347M [00:07<00:13, 14.2MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 159M/347M [00:07<00:17, 11.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 168M/347M [00:07<00:09, 18.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 170M/347M [00:07<00:09, 18.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 172M/347M [00:08<00:09, 17.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 176M/347M [00:08<00:09, 17.4MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 178M/347M [00:08<00:12, 13.6MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 180M/347M [00:08<00:16, 10.4MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 181M/347M [00:09<00:17, 9.77MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 182M/347M [00:09<00:16, 10.2MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 183M/347M [00:09<00:15, 10.7MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 186M/347M [00:09<00:12, 12.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187M/347M [00:09<00:11, 14.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 189M/347M [00:09<00:16, 9.56MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 193M/347M [00:10<00:11, 12.9MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 197M/347M [00:10<00:09, 15.2MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 199M/347M [00:10<00:12, 12.2MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210M/347M [00:10<00:06, 21.0MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 220M/347M [00:11<00:04, 25.9MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 231M/347M [00:11<00:03, 30.7MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 234M/347M [00:12<00:06, 16.7MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 236M/347M [00:12<00:06, 16.3MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 238M/347M [00:12<00:06, 16.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 240M/347M [00:12<00:06, 17.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 242M/347M [00:12<00:08, 12.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 252M/347M [00:13<00:04, 20.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 262M/347M [00:13<00:03, 26.3MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 266M/347M [00:13<00:03, 22.3MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 269M/347M [00:13<00:04, 18.4MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 271M/347M [00:14<00:04, 16.7MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 273M/347M [00:14<00:05, 13.8MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 275M/347M [00:14<00:04, 14.7MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 277M/347M [00:14<00:04, 15.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 278M/347M [00:14<00:04, 16.2MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 280M/347M [00:14<00:03, 16.8MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 282M/347M [00:14<00:03, 17.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 284M/347M [00:15<00:05, 11.0MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294M/347M [00:15<00:02, 21.3MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 304M/347M [00:15<00:01, 27.6MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 307M/347M [00:15<00:01, 26.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 309M/347M [00:15<00:01, 23.8MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 312M/347M [00:16<00:01, 23.3MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 314M/347M [00:16<00:01, 21.2MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 316M/347M [00:16<00:02, 15.2MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 325M/347M [00:16<00:00, 23.0MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329M/347M [00:16<00:00, 21.9MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 334M/347M [00:17<00:00, 21.2MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 336M/347M [00:17<00:00, 16.4MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 346M/347M [00:17<00:00, 23.2MiB/s] > Model's license - apache 2.0
 > Check https://choosealicense.com/licenses/apache-2.0/ for more info.
 > Downloading model to /home/n0x/.local/share/tts/vocoder_models--en--ek1--wavegrad


  0%|          | 0.00/190M [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347M/347M [00:20<00:00, 17.2MiB/s]


  2%|â–         | 3.00M/190M [00:00<00:06, 30.0MiB/s][A

  6%|â–Œ         | 10.5M/190M [00:00<00:05, 34.1MiB/s][A

 11%|â–ˆ         | 21.0M/190M [00:00<00:04, 35.3MiB/s][A

 15%|â–ˆâ–Œ        | 28.9M/190M [00:00<00:03, 45.4MiB/s][A

 18%|â–ˆâ–Š        | 34.2M/190M [00:00<00:04, 35.9MiB/s][A

 22%|â–ˆâ–ˆâ–       | 41.9M/190M [00:01<00:04, 34.4MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 52.4M/190M [00:01<00:03, 37.0MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 62.9M/190M [00:01<00:03, 37.6MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 73.4M/190M [00:01<00:03, 38.2MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83.9M/190M [00:02<00:02, 38.8MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 87.8M/190M [00:02<00:03, 33.6MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 91.2M/190M [00:02<00:03, 30.0MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 94.1M/190M [00:02<00:03, 27.5MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96.7M/190M [00:03<00:04, 20.4MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 98.7M/190M [00:03<00:05, 18.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103M/190M [00:03<00:04, 18.2MiB/s] [A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 105M/190M [00:03<00:05, 14.6MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 115M/190M [00:03<00:03, 22.8MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 126M/190M [00:04<00:02, 27.7MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 129M/190M [00:04<00:03, 17.1MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 131M/190M [00:04<00:03, 15.8MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 132M/190M [00:05<00:03, 16.2MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 134M/190M [00:05<00:03, 16.6MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 136M/190M [00:05<00:03, 16.5MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 138M/190M [00:05<00:04, 12.8MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 147M/190M [00:05<00:02, 19.6MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 157M/190M [00:06<00:01, 25.8MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160M/190M [00:06<00:01, 26.7MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 163M/190M [00:06<00:01, 13.5MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 166M/190M [00:07<00:01, 13.3MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 168M/190M [00:07<00:01, 11.6MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 178M/190M [00:07<00:00, 19.8MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181M/190M [00:07<00:00, 19.8MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 183M/190M [00:07<00:00, 19.8MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 185M/190M [00:07<00:00, 19.9MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 187M/190M [00:08<00:00, 19.8MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 189M/190M [00:08<00:00, 13.1MiB/s][A/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
INFO:     Started server process [50253]
INFO:uvicorn.error:Started server process [50253]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
 > Model's license - apache 2.0
 > Check https://choosealicense.com/licenses/apache-2.0/ for more info.
 > Using model: Tacotron2
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:-10
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:0
 | > fft_size:1024
 | > power:1.8
 | > preemphasis:0.99
 | > griffin_lim_iters:60
 | > signal_norm:True
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:8000.0
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:1.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:True
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > Model's reduction rate `r` is set to: 2
 > Vocoder Model: wavegrad
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.8659181594848633
 > Real-time factor: 1.0104001821375548
INFO:     127.0.0.1:35002 - "POST /generate_audio HTTP/1.1" 200 OK


/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
INFO:     Started server process [50862]
INFO:uvicorn.error:Started server process [50862]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
 > tts_models/en/ek1/tacotron2 is already downloaded.
 > vocoder_models/en/ek1/wavegrad is already downloaded.
 > Using model: Tacotron2
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:-10
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:0
 | > fft_size:1024
 | > power:1.8
 | > preemphasis:0.99
 | > griffin_lim_iters:60
 | > signal_norm:True
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:8000.0
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:1.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:True
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > Model's reduction rate `r` is set to: 2
 > Vocoder Model: wavegrad
 > Text splitted to sentences.
['Muslims are the real shit!']
 > Processing time: 1.1849300861358643
 > Real-time factor: 0.6416431335779913
INFO:     127.0.0.1:60642 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41834 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41834 - "POST /generate_audio HTTP/1.1" 200 OK
 > Text splitted to sentences.
['Shut the fuck up']
 > Processing time: 0.6558308601379395
 > Real-time factor: 0.537666213044377
INFO:     127.0.0.1:35830 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [50862]
INFO:uvicorn.error:Finished server process [50862]
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="path/to/model/dir/", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: 'path/to/model/dir/text_2.pt'

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="path/to/model/dir/", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: 'path/to/model/dir/text_2.pt'

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="path/to/model/dir/", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: 'path/to/model/dir/text_2.pt'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="/home/n0x/.local/share/tts/suno/bark", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: '/home/n0x/.local/share/tts/suno/bark/text_2.pt'

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="/home/n0x/.local/share/tts/suno/bark", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: '/home/n0x/.local/share/tts/suno/bark/text_2.pt'

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 40, in <module>
    model.load_checkpoint(config, checkpoint_dir="/home/n0x/.local/share/tts/suno/bark", eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 54, in _download
    with open(to_local_path, "wb") as file:
FileNotFoundError: [Errno 2] No such file or directory: '/home/n0x/.local/share/tts/suno/bark/text_2.pt'

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [54919]
INFO:uvicorn.error:Started server process [54919]
INFO:     Waiting for application startup.
INFO:uvicorn.error:Waiting for application startup.
INFO:     Application startup complete.
INFO:uvicorn.error:Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:uvicorn.error:Shutting down
INFO:     Waiting for application shutdown.
INFO:uvicorn.error:Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:uvicorn.error:Application shutdown complete.
INFO:     Finished server process [54919]
INFO:uvicorn.error:Finished server process [54919]
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, cache_dir="/home/n0x/.local/share/tts/suno/bark").to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'cache_dir'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, cache_dir="/home/n0x/.local/share/tts/suno/bark").to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'cache_dir'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, cache_dir="/home/n0x/.local/share/tts/suno/bark").to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'cache_dir'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, cache_dir="/home/n0x/.local/share/tts/suno/bark").to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'cache_dir'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, cache_dir="/home/n0x/.local/share/tts/suno/bark").to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'cache_dir'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--bark

  0%|          | 0.00/3.93G [00:00<?, ?iB/s]
  0%|          | 64.5k/3.93G [00:00<3:10:13, 345kiB/s]
  0%|          | 212k/3.93G [00:00<1:48:21, 605kiB/s] 
  0%|          | 493k/3.93G [00:00<1:04:49, 1.01MiB/s]
  0%|          | 1.08M/3.93G [00:00<35:35, 1.84MiB/s] 
  0%|          | 2.22M/3.93G [00:00<19:24, 3.38MiB/s]
  0%|          | 4.55M/3.93G [00:01<10:09, 6.45MiB/s]
  0%|          | 9.17M/3.93G [00:01<05:16, 12.4MiB/s]
  0%|          | 14.4M/3.93G [00:01<03:47, 17.3MiB/s]
  0%|          | 19.6M/3.93G [00:01<03:10, 20.6MiB/s]
  1%|          | 24.8M/3.93G [00:01<02:53, 22.5MiB/s]
  1%|          | 28.9M/3.93G [00:01<02:31, 25.7MiB/s]
  1%|          | 31.6M/3.93G [00:02<02:46, 23.5MiB/s]
  1%|          | 35.3M/3.93G [00:02<02:34, 25.2MiB/s]
  1%|          | 39.2M/3.93G [00:02<02:17, 28.3MiB/s]
  1%|          | 42.2M/3.93G [00:02<02:31, 25.7MiB/s]
  1%|          | 45.7M/3.93G [00:02<02:26, 26.5MiB/s]
  1%|â–         | 50.5M/3.93G [00:02<02:02, 31.7MiB/s]
  1%|â–         | 53.8M/3.93G [00:02<02:20, 27.7MiB/s]
  1%|â–         | 56.8M/3.93G [00:03<02:27, 26.2MiB/s]
  2%|â–         | 59.6M/3.93G [00:03<02:28, 26.2MiB/s]
  2%|â–         | 62.3M/3.93G [00:03<02:33, 25.2MiB/s]
  2%|â–         | 66.4M/3.93G [00:03<02:21, 27.3MiB/s]
  2%|â–         | 70.0M/3.93G [00:03<02:11, 29.3MiB/s]
  2%|â–         | 73.0M/3.93G [00:03<02:29, 25.8MiB/s]
  2%|â–         | 76.8M/3.93G [00:03<02:19, 27.7MiB/s]
  2%|â–         | 80.7M/3.93G [00:03<02:06, 30.4MiB/s]
  2%|â–         | 83.8M/3.93G [00:04<02:26, 26.3MiB/s]
  2%|â–         | 87.2M/3.93G [00:04<02:20, 27.4MiB/s]
  2%|â–         | 90.5M/3.93G [00:04<02:13, 28.8MiB/s]
  2%|â–         | 93.5M/3.93G [00:04<02:21, 27.2MiB/s]
  2%|â–         | 96.9M/3.93G [00:04<02:17, 28.0MiB/s]
  3%|â–Ž         | 99.8M/3.93G [00:04<02:22, 26.9MiB/s]
  3%|â–Ž         | 103M/3.93G [00:04<02:20, 27.2MiB/s] 
  3%|â–Ž         | 107M/3.93G [00:04<02:04, 30.8MiB/s]
  3%|â–Ž         | 110M/3.93G [00:04<02:25, 26.3MiB/s]
  3%|â–Ž         | 113M/3.93G [00:05<02:22, 26.9MiB/s]
  3%|â–Ž         | 117M/3.93G [00:05<02:06, 30.2MiB/s]
  3%|â–Ž         | 120M/3.93G [00:05<02:22, 26.7MiB/s]
  3%|â–Ž         | 124M/3.93G [00:05<02:22, 26.8MiB/s]
  3%|â–Ž         | 127M/3.93G [00:05<02:24, 26.4MiB/s]
  3%|â–Ž         | 130M/3.93G [00:05<02:19, 27.2MiB/s]
  3%|â–Ž         | 133M/3.93G [00:05<02:07, 29.9MiB/s]
  3%|â–Ž         | 136M/3.93G [00:05<02:19, 27.3MiB/s]
  4%|â–Ž         | 139M/3.93G [00:06<02:18, 27.3MiB/s]
  4%|â–Ž         | 143M/3.93G [00:06<02:07, 29.8MiB/s]
  4%|â–Ž         | 146M/3.93G [00:06<02:27, 25.7MiB/s]
  4%|â–         | 150M/3.93G [00:06<02:18, 27.4MiB/s]
  4%|â–         | 154M/3.93G [00:06<02:00, 31.5MiB/s]
  4%|â–         | 157M/3.93G [00:06<02:16, 27.6MiB/s]
  4%|â–         | 160M/3.93G [00:06<02:24, 26.2MiB/s]
  4%|â–         | 165M/3.93G [00:06<01:59, 31.6MiB/s]
  4%|â–         | 168M/3.93G [00:07<02:18, 27.2MiB/s]
  4%|â–         | 171M/3.93G [00:07<02:23, 26.2MiB/s]
  4%|â–         | 174M/3.93G [00:07<02:18, 27.2MiB/s]
  5%|â–         | 177M/3.93G [00:07<02:25, 25.8MiB/s]
  5%|â–         | 181M/3.93G [00:07<02:19, 26.9MiB/s]
  5%|â–         | 185M/3.93G [00:07<02:01, 30.9MiB/s]
  5%|â–         | 188M/3.93G [00:07<02:16, 27.4MiB/s]
  5%|â–         | 191M/3.93G [00:07<02:21, 26.4MiB/s]
  5%|â–         | 195M/3.93G [00:08<02:15, 27.6MiB/s]
  5%|â–Œ         | 198M/3.93G [00:08<02:23, 26.0MiB/s]
  5%|â–Œ         | 202M/3.93G [00:08<02:16, 27.3MiB/s]
  5%|â–Œ         | 206M/3.93G [00:08<02:06, 29.5MiB/s]
  5%|â–Œ         | 209M/3.93G [00:08<02:15, 27.4MiB/s]
  5%|â–Œ         | 212M/3.93G [00:08<02:18, 26.9MiB/s]
  5%|â–Œ         | 216M/3.93G [00:08<02:10, 28.5MiB/s]
  6%|â–Œ         | 219M/3.93G [00:08<02:20, 26.4MiB/s]
  6%|â–Œ         | 222M/3.93G [00:09<02:16, 27.2MiB/s]
  6%|â–Œ         | 227M/3.93G [00:09<02:03, 30.0MiB/s]
  6%|â–Œ         | 230M/3.93G [00:09<02:18, 26.7MiB/s]
  6%|â–Œ         | 233M/3.93G [00:09<02:15, 27.2MiB/s]
  6%|â–Œ         | 237M/3.93G [00:09<02:03, 29.8MiB/s]
  6%|â–Œ         | 240M/3.93G [00:09<02:21, 26.1MiB/s]
  6%|â–Œ         | 243M/3.93G [00:09<02:15, 27.3MiB/s]
  6%|â–‹         | 247M/3.93G [00:09<02:01, 30.4MiB/s]
  6%|â–‹         | 250M/3.93G [00:10<02:22, 25.9MiB/s]
  6%|â–‹         | 254M/3.93G [00:10<02:14, 27.4MiB/s]
  7%|â–‹         | 257M/3.93G [00:10<02:18, 26.5MiB/s]
  7%|â–‹         | 260M/3.93G [00:10<02:18, 26.6MiB/s]
  7%|â–‹         | 263M/3.93G [00:10<02:13, 27.4MiB/s]
  7%|â–‹         | 266M/3.93G [00:10<02:16, 26.9MiB/s]
  7%|â–‹         | 269M/3.93G [00:10<02:09, 28.4MiB/s]
  7%|â–‹         | 272M/3.93G [00:10<02:08, 28.4MiB/s]
  7%|â–‹         | 275M/3.93G [00:10<02:12, 27.6MiB/s]
  7%|â–‹         | 279M/3.93G [00:11<02:02, 30.0MiB/s]
  7%|â–‹         | 282M/3.93G [00:11<02:16, 26.8MiB/s]
  7%|â–‹         | 285M/3.93G [00:11<02:13, 27.4MiB/s]
  7%|â–‹         | 288M/3.93G [00:11<02:01, 29.9MiB/s]
  7%|â–‹         | 292M/3.93G [00:11<02:22, 25.6MiB/s]
  7%|â–‹         | 294M/3.93G [00:11<03:12, 18.9MiB/s]
  8%|â–Š         | 299M/3.93G [00:11<02:31, 24.0MiB/s]
  8%|â–Š         | 303M/3.93G [00:11<02:09, 28.1MiB/s]
  8%|â–Š         | 308M/3.93G [00:12<01:54, 31.6MiB/s]
  8%|â–Š         | 311M/3.93G [00:12<01:57, 30.7MiB/s]
  8%|â–Š         | 315M/3.93G [00:12<01:48, 33.4MiB/s]
  8%|â–Š         | 319M/3.93G [00:12<02:03, 29.3MiB/s]
  8%|â–Š         | 322M/3.93G [00:12<02:07, 28.3MiB/s]
  8%|â–Š         | 327M/3.93G [00:12<02:09, 27.9MiB/s]
  8%|â–Š         | 330M/3.93G [00:12<02:04, 28.8MiB/s]
  8%|â–Š         | 333M/3.93G [00:13<02:15, 26.5MiB/s]
  9%|â–Š         | 337M/3.93G [00:13<02:08, 28.1MiB/s]
  9%|â–Š         | 342M/3.93G [00:13<01:47, 33.3MiB/s]
  9%|â–‰         | 345M/3.93G [00:13<02:07, 28.2MiB/s]
  9%|â–‰         | 348M/3.93G [00:13<02:17, 26.1MiB/s]
  9%|â–‰         | 353M/3.93G [00:13<02:13, 26.8MiB/s]
  9%|â–‰         | 356M/3.93G [00:13<02:01, 29.4MiB/s]
  9%|â–‰         | 359M/3.93G [00:13<02:20, 25.4MiB/s]
  9%|â–‰         | 363M/3.93G [00:14<02:11, 27.2MiB/s]
  9%|â–‰         | 367M/3.93G [00:14<01:54, 31.1MiB/s]
  9%|â–‰         | 371M/3.93G [00:14<02:14, 26.5MiB/s]
  9%|â–‰         | 373M/3.93G [00:14<02:18, 25.8MiB/s]
 10%|â–‰         | 378M/3.93G [00:14<01:56, 30.4MiB/s]
 10%|â–‰         | 381M/3.93G [00:14<02:10, 27.3MiB/s]
 10%|â–‰         | 384M/3.93G [00:14<02:18, 25.6MiB/s]
 10%|â–‰         | 388M/3.93G [00:14<02:05, 28.3MiB/s]
 10%|â–‰         | 391M/3.93G [00:15<02:18, 25.6MiB/s]
 10%|â–ˆ         | 394M/3.93G [00:15<02:10, 27.1MiB/s]
 10%|â–ˆ         | 398M/3.93G [00:15<01:54, 30.8MiB/s]
 10%|â–ˆ         | 402M/3.93G [00:15<02:12, 26.6MiB/s]
 10%|â–ˆ         | 405M/3.93G [00:15<02:10, 26.9MiB/s]
 10%|â–ˆ         | 409M/3.93G [00:15<01:52, 31.3MiB/s]
 10%|â–ˆ         | 412M/3.93G [00:15<02:03, 28.6MiB/s]
 11%|â–ˆ         | 415M/3.93G [00:15<02:20, 25.0MiB/s]
 11%|â–ˆ         | 420M/3.93G [00:16<01:59, 29.5MiB/s]
 11%|â–ˆ         | 423M/3.93G [00:16<02:13, 26.3MiB/s]
 11%|â–ˆ         | 426M/3.93G [00:16<02:16, 25.8MiB/s]
 11%|â–ˆ         | 430M/3.93G [00:16<02:01, 28.9MiB/s]
 11%|â–ˆ         | 433M/3.93G [00:16<02:12, 26.5MiB/s]
 11%|â–ˆ         | 436M/3.93G [00:16<02:11, 26.7MiB/s]
 11%|â–ˆ         | 440M/3.93G [00:16<01:56, 30.0MiB/s]
 11%|â–ˆâ–        | 443M/3.93G [00:16<02:03, 28.2MiB/s]
 11%|â–ˆâ–        | 446M/3.93G [00:17<02:10, 26.8MiB/s]
 11%|â–ˆâ–        | 450M/3.93G [00:17<01:55, 30.2MiB/s]
 12%|â–ˆâ–        | 453M/3.93G [00:17<02:20, 24.7MiB/s]
 12%|â–ˆâ–        | 457M/3.93G [00:17<02:09, 26.8MiB/s]
 12%|â–ˆâ–        | 459M/3.93G [00:17<02:07, 27.2MiB/s]
 12%|â–ˆâ–        | 462M/3.93G [00:17<02:10, 26.7MiB/s]
 12%|â–ˆâ–        | 467M/3.93G [00:17<01:56, 29.8MiB/s]
 12%|â–ˆâ–        | 470M/3.93G [00:17<02:02, 28.2MiB/s]
 12%|â–ˆâ–        | 473M/3.93G [00:18<02:12, 26.2MiB/s]
 12%|â–ˆâ–        | 477M/3.93G [00:18<01:57, 29.4MiB/s]
 12%|â–ˆâ–        | 480M/3.93G [00:18<02:11, 26.3MiB/s]
 12%|â–ˆâ–        | 483M/3.93G [00:18<02:08, 26.9MiB/s]
 12%|â–ˆâ–        | 486M/3.93G [00:18<02:05, 27.5MiB/s]
 12%|â–ˆâ–        | 488M/3.93G [00:18<02:10, 26.5MiB/s]
 13%|â–ˆâ–Ž        | 492M/3.93G [00:18<02:01, 28.4MiB/s]
 13%|â–ˆâ–Ž        | 495M/3.93G [00:18<02:07, 27.0MiB/s]
 13%|â–ˆâ–Ž        | 498M/3.93G [00:18<02:02, 28.0MiB/s]
 13%|â–ˆâ–Ž        | 502M/3.93G [00:19<01:54, 29.9MiB/s]
 13%|â–ˆâ–Ž        | 505M/3.93G [00:19<02:20, 24.3MiB/s]
 13%|â–ˆâ–Ž        | 509M/3.93G [00:19<02:02, 28.0MiB/s]
 13%|â–ˆâ–Ž        | 512M/3.93G [00:19<01:53, 30.0MiB/s]
 13%|â–ˆâ–Ž        | 515M/3.93G [00:19<02:12, 25.9MiB/s]
 13%|â–ˆâ–Ž        | 519M/3.93G [00:19<02:02, 27.9MiB/s]
 13%|â–ˆâ–Ž        | 523M/3.93G [00:19<01:50, 30.8MiB/s]
 13%|â–ˆâ–Ž        | 526M/3.93G [00:20<02:12, 25.8MiB/s]
 13%|â–ˆâ–Ž        | 529M/3.93G [00:20<02:04, 27.3MiB/s]
 14%|â–ˆâ–Ž        | 533M/3.93G [00:20<01:55, 29.4MiB/s]
 14%|â–ˆâ–Ž        | 536M/3.93G [00:20<02:13, 25.5MiB/s]
 14%|â–ˆâ–Ž        | 540M/3.93G [00:20<02:00, 28.2MiB/s]
 14%|â–ˆâ–        | 543M/3.93G [00:20<02:01, 27.9MiB/s]
 14%|â–ˆâ–        | 546M/3.93G [00:20<02:06, 26.7MiB/s]
 14%|â–ˆâ–        | 549M/3.93G [00:20<02:07, 26.5MiB/s]
 14%|â–ˆâ–        | 551M/3.93G [00:20<02:12, 25.6MiB/s]
 14%|â–ˆâ–        | 555M/3.93G [00:21<01:53, 29.7MiB/s]
 14%|â–ˆâ–        | 558M/3.93G [00:21<01:58, 28.6MiB/s]
 14%|â–ˆâ–        | 561M/3.93G [00:21<02:04, 27.2MiB/s]
 14%|â–ˆâ–        | 565M/3.93G [00:21<01:59, 28.2MiB/s]
 14%|â–ˆâ–        | 568M/3.93G [00:21<02:10, 25.8MiB/s]
 15%|â–ˆâ–        | 571M/3.93G [00:21<02:00, 27.9MiB/s]
 15%|â–ˆâ–        | 576M/3.93G [00:21<01:41, 33.0MiB/s]
 15%|â–ˆâ–        | 579M/3.93G [00:21<01:58, 28.2MiB/s]
 15%|â–ˆâ–        | 582M/3.93G [00:22<02:07, 26.3MiB/s]
 15%|â–ˆâ–        | 586M/3.93G [00:22<01:59, 28.1MiB/s]
 15%|â–ˆâ–        | 589M/3.93G [00:22<02:10, 25.6MiB/s]
 15%|â–ˆâ–Œ        | 592M/3.93G [00:22<02:03, 27.1MiB/s]
 15%|â–ˆâ–Œ        | 596M/3.93G [00:22<01:48, 30.7MiB/s]
 15%|â–ˆâ–Œ        | 599M/3.93G [00:22<02:09, 25.7MiB/s]
 15%|â–ˆâ–Œ        | 602M/3.93G [00:22<02:02, 27.1MiB/s]
 15%|â–ˆâ–Œ        | 607M/3.93G [00:22<01:48, 30.7MiB/s]
 15%|â–ˆâ–Œ        | 610M/3.93G [00:23<02:06, 26.3MiB/s]
 16%|â–ˆâ–Œ        | 613M/3.93G [00:23<02:01, 27.2MiB/s]
 16%|â–ˆâ–Œ        | 616M/3.93G [00:23<01:53, 29.2MiB/s]
 16%|â–ˆâ–Œ        | 619M/3.93G [00:23<02:15, 24.4MiB/s]
 16%|â–ˆâ–Œ        | 623M/3.93G [00:23<01:59, 27.8MiB/s]
 16%|â–ˆâ–Œ        | 627M/3.93G [00:23<01:46, 31.0MiB/s]
 16%|â–ˆâ–Œ        | 631M/3.93G [00:23<02:03, 26.7MiB/s]
 16%|â–ˆâ–Œ        | 634M/3.93G [00:23<02:01, 27.1MiB/s]
 16%|â–ˆâ–Œ        | 637M/3.93G [00:23<01:53, 29.1MiB/s]
 16%|â–ˆâ–‹        | 640M/3.93G [00:24<02:03, 26.7MiB/s]
 16%|â–ˆâ–‹        | 643M/3.93G [00:24<01:57, 28.1MiB/s]
 16%|â–ˆâ–‹        | 646M/3.93G [00:24<02:07, 25.7MiB/s]
 17%|â–ˆâ–‹        | 649M/3.93G [00:24<02:03, 26.7MiB/s]
 17%|â–ˆâ–‹        | 653M/3.93G [00:24<01:52, 29.1MiB/s]
 17%|â–ˆâ–‹        | 656M/3.93G [00:24<02:04, 26.3MiB/s]
 17%|â–ˆâ–‹        | 659M/3.93G [00:24<01:54, 28.5MiB/s]
 17%|â–ˆâ–‹        | 662M/3.93G [00:24<01:55, 28.3MiB/s]
 17%|â–ˆâ–‹        | 665M/3.93G [00:25<02:04, 26.3MiB/s]
 17%|â–ˆâ–‹        | 669M/3.93G [00:25<01:54, 28.6MiB/s]
 17%|â–ˆâ–‹        | 672M/3.93G [00:25<01:59, 27.4MiB/s]
 17%|â–ˆâ–‹        | 675M/3.93G [00:25<01:59, 27.3MiB/s]
 17%|â–ˆâ–‹        | 678M/3.93G [00:25<01:52, 28.9MiB/s]
 17%|â–ˆâ–‹        | 681M/3.93G [00:25<02:03, 26.4MiB/s]
 17%|â–ˆâ–‹        | 685M/3.93G [00:25<01:56, 28.0MiB/s]
 17%|â–ˆâ–‹        | 688M/3.93G [00:25<01:58, 27.3MiB/s]
 18%|â–ˆâ–Š        | 691M/3.93G [00:25<01:57, 27.7MiB/s]
 18%|â–ˆâ–Š        | 695M/3.93G [00:26<01:41, 31.8MiB/s]
 18%|â–ˆâ–Š        | 698M/3.93G [00:26<02:04, 25.9MiB/s]
 18%|â–ˆâ–Š        | 701M/3.93G [00:26<02:02, 26.4MiB/s]
 18%|â–ˆâ–Š        | 705M/3.93G [00:26<01:43, 31.2MiB/s]
 18%|â–ˆâ–Š        | 709M/3.93G [00:26<02:02, 26.3MiB/s]
 18%|â–ˆâ–Š        | 712M/3.93G [00:26<02:04, 25.9MiB/s]
 18%|â–ˆâ–Š        | 716M/3.93G [00:26<01:47, 30.1MiB/s]
 18%|â–ˆâ–Š        | 719M/3.93G [00:26<01:57, 27.4MiB/s]
 18%|â–ˆâ–Š        | 722M/3.93G [00:27<02:04, 25.9MiB/s]
 18%|â–ˆâ–Š        | 726M/3.93G [00:27<01:49, 29.2MiB/s]
 19%|â–ˆâ–Š        | 729M/3.93G [00:27<02:06, 25.3MiB/s]
 19%|â–ˆâ–Š        | 732M/3.93G [00:27<02:00, 26.7MiB/s]
 19%|â–ˆâ–Š        | 735M/3.93G [00:27<01:58, 26.9MiB/s]
 19%|â–ˆâ–Š        | 738M/3.93G [00:27<01:58, 27.0MiB/s]
 19%|â–ˆâ–‰        | 741M/3.93G [00:27<01:49, 29.2MiB/s]
 19%|â–ˆâ–‰        | 744M/3.93G [00:27<02:05, 25.4MiB/s]
 19%|â–ˆâ–‰        | 748M/3.93G [00:28<01:54, 27.7MiB/s]
 19%|â–ˆâ–‰        | 751M/3.93G [00:28<01:49, 29.0MiB/s]
 19%|â–ˆâ–‰        | 754M/3.93G [00:28<01:59, 26.5MiB/s]
 19%|â–ˆâ–‰        | 757M/3.93G [00:28<01:52, 28.3MiB/s]
 19%|â–ˆâ–‰        | 760M/3.93G [00:28<01:56, 27.2MiB/s]
 19%|â–ˆâ–‰        | 763M/3.93G [00:28<01:54, 27.6MiB/s]
 19%|â–ˆâ–‰        | 766M/3.93G [00:28<01:54, 27.8MiB/s]
 20%|â–ˆâ–‰        | 769M/3.93G [00:28<01:56, 27.2MiB/s]
 20%|â–ˆâ–‰        | 772M/3.93G [00:28<01:49, 28.9MiB/s]
 20%|â–ˆâ–‰        | 775M/3.93G [00:29<01:57, 26.9MiB/s]
 20%|â–ˆâ–‰        | 778M/3.93G [00:29<01:51, 28.4MiB/s]
 20%|â–ˆâ–‰        | 781M/3.93G [00:29<01:56, 27.0MiB/s]
 20%|â–ˆâ–‰        | 784M/3.93G [00:29<01:56, 27.0MiB/s]
 20%|â–ˆâ–‰        | 787M/3.93G [00:29<01:57, 26.7MiB/s]
 20%|â–ˆâ–ˆ        | 790M/3.93G [00:29<01:57, 26.7MiB/s]
 20%|â–ˆâ–ˆ        | 793M/3.93G [00:29<01:47, 29.1MiB/s]
 20%|â–ˆâ–ˆ        | 796M/3.93G [00:29<01:56, 27.0MiB/s]
 20%|â–ˆâ–ˆ        | 799M/3.93G [00:29<01:53, 27.6MiB/s]
 20%|â–ˆâ–ˆ        | 802M/3.93G [00:30<01:56, 26.8MiB/s]
 20%|â–ˆâ–ˆ        | 805M/3.93G [00:30<01:54, 27.4MiB/s]
 21%|â–ˆâ–ˆ        | 808M/3.93G [00:30<01:46, 29.3MiB/s]
 21%|â–ˆâ–ˆ        | 811M/3.93G [00:30<01:56, 26.9MiB/s]
 21%|â–ˆâ–ˆ        | 815M/3.93G [00:30<01:48, 28.8MiB/s]
 21%|â–ˆâ–ˆ        | 818M/3.93G [00:30<01:53, 27.5MiB/s]
 21%|â–ˆâ–ˆ        | 820M/3.93G [00:30<01:54, 27.2MiB/s]
 21%|â–ˆâ–ˆ        | 824M/3.93G [00:30<01:50, 28.1MiB/s]
 21%|â–ˆâ–ˆ        | 826M/3.93G [00:30<01:54, 27.2MiB/s]
 21%|â–ˆâ–ˆ        | 830M/3.93G [00:30<01:49, 28.4MiB/s]
 21%|â–ˆâ–ˆ        | 832M/3.93G [00:31<01:59, 25.9MiB/s]
 21%|â–ˆâ–ˆ        | 836M/3.93G [00:31<01:51, 27.8MiB/s]
 21%|â–ˆâ–ˆâ–       | 839M/3.93G [00:31<01:55, 26.7MiB/s]
 21%|â–ˆâ–ˆâ–       | 841M/3.93G [00:31<01:58, 26.2MiB/s]
 21%|â–ˆâ–ˆâ–       | 845M/3.93G [00:31<01:48, 28.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 848M/3.93G [00:31<01:51, 27.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 851M/3.93G [00:31<01:47, 28.7MiB/s]
 22%|â–ˆâ–ˆâ–       | 854M/3.93G [00:31<01:54, 26.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 857M/3.93G [00:31<01:52, 27.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 860M/3.93G [00:32<01:47, 28.5MiB/s]
 22%|â–ˆâ–ˆâ–       | 863M/3.93G [00:32<01:51, 27.5MiB/s]
 22%|â–ˆâ–ˆâ–       | 866M/3.93G [00:32<01:49, 28.1MiB/s]
 22%|â–ˆâ–ˆâ–       | 869M/3.93G [00:32<01:52, 27.3MiB/s]
 22%|â–ˆâ–ˆâ–       | 871M/3.93G [00:32<01:51, 27.5MiB/s]
 22%|â–ˆâ–ˆâ–       | 874M/3.93G [00:32<01:58, 25.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 877M/3.93G [00:32<01:50, 27.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 881M/3.93G [00:32<01:47, 28.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 883M/3.93G [00:32<01:50, 27.7MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 886M/3.93G [00:33<01:53, 26.9MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 889M/3.93G [00:33<01:48, 28.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 892M/3.93G [00:33<01:48, 28.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 895M/3.93G [00:33<01:47, 28.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 898M/3.93G [00:33<01:50, 27.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 901M/3.93G [00:33<01:56, 26.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 904M/3.93G [00:33<01:49, 27.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 907M/3.93G [00:33<01:46, 28.3MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 910M/3.93G [00:34<03:08, 16.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 912M/3.93G [00:34<02:47, 18.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 915M/3.93G [00:34<02:38, 19.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 918M/3.93G [00:34<02:27, 20.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 921M/3.93G [00:34<02:02, 24.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 924M/3.93G [00:34<01:55, 26.0MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 928M/3.93G [00:34<01:44, 28.8MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 931M/3.93G [00:34<01:39, 30.1MiB/s]
 24%|â–ˆâ–ˆâ–       | 935M/3.93G [00:34<01:34, 31.8MiB/s]
 24%|â–ˆâ–ˆâ–       | 939M/3.93G [00:35<01:28, 33.9MiB/s]
 24%|â–ˆâ–ˆâ–       | 942M/3.93G [00:35<01:33, 31.9MiB/s]
 24%|â–ˆâ–ˆâ–       | 947M/3.93G [00:35<01:21, 36.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 951M/3.93G [00:35<01:21, 36.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 955M/3.93G [00:35<01:25, 34.8MiB/s]
 24%|â–ˆâ–ˆâ–       | 958M/3.93G [00:35<01:29, 33.1MiB/s]
 24%|â–ˆâ–ˆâ–       | 962M/3.93G [00:35<01:37, 30.4MiB/s]
 25%|â–ˆâ–ˆâ–       | 965M/3.93G [00:35<01:42, 28.9MiB/s]
 25%|â–ˆâ–ˆâ–       | 968M/3.93G [00:36<01:39, 29.7MiB/s]
 25%|â–ˆâ–ˆâ–       | 971M/3.93G [00:36<01:43, 28.7MiB/s]
 25%|â–ˆâ–ˆâ–       | 975M/3.93G [00:36<01:39, 29.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 978M/3.93G [00:36<01:41, 29.2MiB/s]
 25%|â–ˆâ–ˆâ–       | 981M/3.93G [00:36<01:48, 27.3MiB/s]
 25%|â–ˆâ–ˆâ–       | 983M/3.93G [00:36<01:48, 27.1MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 986M/3.93G [00:36<01:48, 27.2MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 989M/3.93G [00:36<01:45, 28.0MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 992M/3.93G [00:36<01:50, 26.5MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 995M/3.93G [00:36<01:42, 28.8MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 998M/3.93G [00:37<01:48, 27.0MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 1.00G/3.93G [00:37<01:49, 26.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.00G/3.93G [00:37<01:56, 25.1MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:37<01:47, 27.3MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:37<01:36, 30.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:37<01:50, 26.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:37<01:46, 27.3MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:37<01:47, 27.2MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:38<01:50, 26.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:38<01:46, 27.2MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:38<01:45, 27.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:38<01:40, 28.8MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.03G/3.93G [00:38<01:44, 27.6MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:38<01:43, 28.0MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:38<01:46, 27.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:38<01:47, 26.9MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:38, 29.2MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:38<01:42, 28.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:39<01:41, 28.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:39<01:34, 30.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:39<01:48, 26.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:39<01:41, 28.4MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:39<01:41, 28.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:39<01:46, 26.9MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:39<01:33, 30.7MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:39<01:44, 27.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:40<01:46, 26.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.08G/3.93G [00:40<01:35, 29.9MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:40<01:46, 26.8MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:40<01:43, 27.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:40<01:34, 30.0MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:40<01:51, 25.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:40<01:43, 27.5MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:40<01:39, 28.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:41<01:49, 25.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:41<01:44, 27.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:41<01:43, 27.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:41<01:41, 27.8MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:41<01:34, 29.7MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:41<01:50, 25.4MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:41<01:42, 27.5MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:41<01:45, 26.6MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:41<01:41, 27.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.13G/3.93G [00:42<01:32, 30.4MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:42<01:43, 26.9MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:42<01:41, 27.7MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:42<01:34, 29.6MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:42<01:51, 25.1MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:42<01:39, 27.9MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:42<01:38, 28.3MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:42<01:43, 26.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:42<01:33, 29.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:43<01:43, 26.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:43<01:41, 27.4MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:43<01:34, 29.2MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:43<01:49, 25.2MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:43<01:41, 27.1MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:43<01:41, 27.2MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.18G/3.93G [00:43<01:39, 27.7MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:43<01:32, 29.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:44<01:47, 25.5MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:44<01:39, 27.5MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:44<01:39, 27.6MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:44<01:38, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:44<01:32, 29.6MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:44<01:46, 25.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:44<01:39, 27.5MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:44<01:39, 27.3MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:44<01:38, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:45<01:33, 29.1MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:45<01:40, 27.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:45<01:38, 27.5MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.23G/3.93G [00:45<01:40, 27.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.23G/3.93G [00:45<01:38, 27.6MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.23G/3.93G [00:45<01:33, 28.9MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:45<01:39, 27.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:45<01:38, 27.4MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:45<01:40, 26.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:46<01:37, 27.5MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:46<01:33, 28.9MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:46<01:39, 27.0MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:46<01:36, 27.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:46<01:39, 27.0MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:46<01:36, 27.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:46<01:33, 28.5MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:46<01:39, 26.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:46<01:35, 27.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:47<01:38, 27.0MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.93G [00:47<01:36, 27.5MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:47<01:32, 28.8MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:47<01:38, 27.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:36, 27.3MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:38, 26.8MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:35, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:47<01:35, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:47<01:36, 27.4MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:48<01:31, 28.7MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:48<01:38, 26.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:48<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:48<01:38, 26.7MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:48<01:34, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:48<01:34, 27.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:48<01:36, 27.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:48<01:27, 29.7MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:48<01:39, 26.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.33G/3.93G [00:49<01:32, 28.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.33G/3.93G [00:49<01:34, 27.5MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.33G/3.93G [00:49<01:36, 27.0MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:49<01:33, 27.8MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:49<01:36, 26.8MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:49<01:33, 27.7MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:49<01:33, 27.7MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:49<01:35, 27.0MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:49<01:27, 29.4MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:50<01:36, 26.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:50<01:33, 27.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:50<01:35, 27.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:50<01:35, 27.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:50<01:29, 28.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:50<01:33, 27.5MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:50<01:32, 27.8MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.38G/3.93G [00:50<01:35, 26.8MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:50<01:31, 28.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:51<01:32, 27.5MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:51<01:33, 27.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:51<01:27, 29.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:51<01:35, 26.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:51<01:32, 27.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:51<01:34, 26.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:51<01:29, 28.2MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:51<01:30, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:51<01:33, 27.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:52<01:39, 25.5MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:52<01:30, 27.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:52<01:29, 28.3MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:52<01:40, 25.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:52<01:28, 28.5MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.43G/3.93G [00:52<01:26, 28.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:52<01:31, 27.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:52<01:29, 28.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:52<01:27, 28.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:53<01:30, 27.7MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:53<01:24, 29.4MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:53<01:34, 26.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:53<01:31, 27.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:53<01:28, 28.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:53<01:30, 27.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:53<01:24, 29.5MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:53<01:34, 26.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:53<01:31, 26.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:54<01:27, 28.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:54<01:30, 27.2MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:54<01:23, 29.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:54<01:33, 26.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:54<01:29, 27.3MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:54<01:28, 27.7MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:54<01:30, 27.1MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:54<01:23, 29.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:54<01:31, 26.7MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:55<01:27, 27.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:55<01:30, 26.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:55<01:29, 27.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:55<01:24, 28.7MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:55<01:29, 27.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:55<01:25, 28.3MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:55<01:31, 26.4MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:55<01:27, 27.6MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:55<01:27, 27.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:56<01:28, 27.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:56<01:24, 28.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:56<01:29, 26.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:56<01:26, 27.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:56<02:15, 17.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:56<01:17, 30.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:56<01:16, 31.1MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:57<01:23, 28.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:57<01:23, 28.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:57<01:22, 28.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:57<01:26, 27.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:57<01:23, 28.3MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:57<01:23, 28.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:57<01:25, 27.6MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:57<01:21, 29.1MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:57<01:30, 26.2MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:58<01:24, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:58<01:24, 27.7MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:58<01:27, 27.0MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:58<01:20, 29.1MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:58<01:29, 26.2MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:58<01:23, 28.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:58<01:25, 27.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:58<01:25, 27.3MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:58<01:22, 28.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:59<01:24, 27.6MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:59<01:24, 27.7MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:59<01:27, 26.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:59<01:22, 28.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:59<01:24, 27.3MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:59<01:25, 27.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:59<01:22, 28.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.62G/3.93G [00:59<01:25, 27.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:59<01:21, 28.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [01:00<01:27, 26.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [01:00<01:21, 28.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [01:00<01:22, 27.8MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [01:00<01:24, 27.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [01:00<01:19, 28.9MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [01:00<01:26, 26.5MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [01:00<01:22, 27.8MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [01:00<01:25, 26.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [01:00<01:23, 27.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [01:01<01:20, 28.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [01:01<01:23, 27.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [01:01<01:20, 28.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.93G [01:01<01:26, 26.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.93G [01:01<01:20, 28.0MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.67G/3.93G [01:01<01:21, 27.9MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [01:01<01:22, 27.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [01:01<01:20, 28.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [01:01<01:22, 27.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [01:01<01:22, 27.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:02<01:22, 27.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:02<01:19, 28.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:02<01:23, 26.8MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:02<01:20, 27.8MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:02<01:20, 27.8MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:02<01:21, 27.6MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:02<01:19, 28.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:02<01:20, 27.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:02<01:19, 27.9MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:03<01:23, 26.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [01:03<01:19, 27.8MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [01:03<01:20, 27.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.72G/3.93G [01:03<01:20, 27.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:03<01:17, 28.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:03<01:21, 27.0MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:03<01:17, 28.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:03<01:23, 26.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:03<01:19, 27.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:04<01:19, 27.7MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:04<01:20, 27.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:04<01:18, 27.9MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:04<01:20, 27.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:04<01:18, 27.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:04<01:20, 27.0MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:04<01:19, 27.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:04<01:19, 27.4MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:04<01:18, 27.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.77G/3.93G [01:04<01:17, 28.0MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.77G/3.93G [01:05<01:19, 27.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.77G/3.93G [01:05<01:16, 28.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.77G/3.93G [01:05<01:19, 27.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:05<01:18, 27.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:05<01:18, 27.4MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:05<01:18, 27.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:05<01:18, 27.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:05<01:18, 27.5MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:05<01:17, 27.7MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:06<01:18, 27.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:06<01:14, 28.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:06<01:18, 27.1MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:06<01:17, 27.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:06<01:17, 27.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:06<01:19, 26.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:06<01:20, 26.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.82G/3.93G [01:06<01:15, 27.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.82G/3.93G [01:06<01:13, 28.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:06<01:17, 27.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:07<01:15, 27.8MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:07<01:16, 27.5MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:07<01:15, 28.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:07<01:16, 27.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:07<01:16, 27.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:07<01:15, 27.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:07<01:15, 27.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:07<01:13, 28.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:07<01:18, 26.6MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:08<01:15, 27.5MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:08<01:14, 27.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:08<01:17, 26.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:08<01:14, 27.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:08<01:13, 28.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:08<01:14, 27.9MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.87G/3.93G [01:08<01:17, 26.8MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [01:08<01:13, 28.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [01:08<01:14, 27.6MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:08<01:16, 27.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:09<01:14, 27.4MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:09<01:15, 27.1MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:09<01:13, 27.9MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:09<01:12, 28.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:09<01:13, 27.7MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:09<01:17, 26.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:09<01:14, 27.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:09<01:14, 27.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:09<01:14, 27.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:10<01:12, 28.0MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:10<01:10, 28.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:10<01:13, 27.7MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:10<01:16, 26.4MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.92G/3.93G [01:10<01:13, 27.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [01:10<01:12, 27.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [01:10<01:13, 27.2MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:10<01:11, 28.0MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:10<01:11, 28.2MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:10<01:12, 27.5MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:11<01:15, 26.4MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:11<01:12, 27.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:11<01:12, 27.5MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:11<01:13, 27.1MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:11<01:10, 28.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:11<01:10, 28.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:11<01:12, 27.5MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:11<01:14, 26.6MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:11<01:11, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:12<01:11, 27.5MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:12<01:12, 27.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:12<01:11, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:12<01:09, 28.1MiB/s]/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 411, in download_model
    self.create_dir_and_download_model(model_name, model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 334, in create_dir_and_download_model
    os.makedirs(output_path, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/n0x'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 411, in download_model
    self.create_dir_and_download_model(model_name, model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 334, in create_dir_and_download_model
    os.makedirs(output_path, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/n0x'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 171, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 129, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 411, in download_model
    self.create_dir_and_download_model(model_name, model_item, output_path)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/manage.py", line 334, in create_dir_and_download_model
    os.makedirs(output_path, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/n0x'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > Downloading model to /home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark

  0%|          | 0.00/3.93G [00:00<?, ?iB/s]
  0%|          | 539k/3.93G [00:00<12:10, 5.39MiB/s]
  0%|          | 3.98M/3.93G [00:00<02:55, 22.4MiB/s]
  0%|          | 7.52M/3.93G [00:00<02:59, 21.9MiB/s]
  0%|          | 12.7M/3.93G [00:00<02:36, 25.0MiB/s]
  0%|          | 17.9M/3.93G [00:00<02:29, 26.2MiB/s]
  1%|          | 23.1M/3.93G [00:00<02:25, 26.9MiB/s]
  1%|          | 28.3M/3.93G [00:01<02:22, 27.4MiB/s]
  1%|          | 33.5M/3.93G [00:01<02:20, 27.7MiB/s]
  1%|          | 38.8M/3.93G [00:01<02:19, 27.9MiB/s]
  1%|          | 44.0M/3.93G [00:01<02:18, 28.1MiB/s]
  1%|          | 49.2M/3.93G [00:01<02:18, 28.1MiB/s]
  1%|â–         | 54.4M/3.93G [00:02<02:17, 28.1MiB/s]
  2%|â–         | 59.6M/3.93G [00:02<02:17, 28.2MiB/s]
  2%|â–         | 64.8M/3.93G [00:02<02:17, 28.2MiB/s]
  2%|â–         | 70.0M/3.93G [00:02<02:17, 28.2MiB/s]
  2%|â–         | 75.2M/3.93G [00:02<02:16, 28.2MiB/s]
  2%|â–         | 80.4M/3.93G [00:02<02:16, 28.2MiB/s]
  2%|â–         | 85.6M/3.93G [00:03<02:16, 28.2MiB/s]
  2%|â–         | 90.8M/3.93G [00:03<02:16, 28.3MiB/s]
  2%|â–         | 96.0M/3.93G [00:03<02:16, 28.2MiB/s]
  3%|â–Ž         | 101M/3.93G [00:03<02:15, 28.3MiB/s] 
  3%|â–Ž         | 106M/3.93G [00:03<02:15, 28.2MiB/s]
  3%|â–Ž         | 112M/3.93G [00:04<02:15, 28.3MiB/s]
  3%|â–Ž         | 117M/3.93G [00:04<02:15, 28.2MiB/s]
  3%|â–Ž         | 122M/3.93G [00:04<02:15, 28.2MiB/s]
  3%|â–Ž         | 127M/3.93G [00:04<02:15, 28.1MiB/s]
  3%|â–Ž         | 132M/3.93G [00:04<02:14, 28.2MiB/s]
  3%|â–Ž         | 138M/3.93G [00:04<02:14, 28.3MiB/s]
  4%|â–Ž         | 143M/3.93G [00:05<02:14, 28.2MiB/s]
  4%|â–Ž         | 146M/3.93G [00:05<02:13, 28.4MiB/s]
  4%|â–         | 149M/3.93G [00:05<02:13, 28.3MiB/s]
  4%|â–         | 153M/3.93G [00:05<02:13, 28.4MiB/s]
  4%|â–         | 158M/3.93G [00:05<02:14, 28.0MiB/s]
  4%|â–         | 164M/3.93G [00:05<02:13, 28.2MiB/s]
  4%|â–         | 169M/3.93G [00:06<02:13, 28.2MiB/s]
  4%|â–         | 174M/3.93G [00:06<02:13, 28.3MiB/s]
  5%|â–         | 179M/3.93G [00:06<02:13, 28.2MiB/s]
  5%|â–         | 184M/3.93G [00:06<02:12, 28.2MiB/s]
  5%|â–         | 190M/3.93G [00:06<02:12, 28.2MiB/s]
  5%|â–         | 195M/3.93G [00:06<02:12, 28.2MiB/s]
  5%|â–Œ         | 200M/3.93G [00:07<02:12, 28.2MiB/s]
  5%|â–Œ         | 205M/3.93G [00:07<02:12, 28.2MiB/s]
  5%|â–Œ         | 210M/3.93G [00:07<02:13, 28.0MiB/s]
  5%|â–Œ         | 215M/3.93G [00:07<02:12, 28.1MiB/s]
  6%|â–Œ         | 221M/3.93G [00:07<02:11, 28.2MiB/s]
  6%|â–Œ         | 226M/3.93G [00:08<02:12, 27.9MiB/s]
  6%|â–Œ         | 231M/3.93G [00:08<02:12, 28.0MiB/s]
  6%|â–Œ         | 236M/3.93G [00:08<02:11, 28.1MiB/s]
  6%|â–Œ         | 241M/3.93G [00:08<02:10, 28.2MiB/s]
  6%|â–‹         | 247M/3.93G [00:08<02:10, 28.2MiB/s]
  6%|â–‹         | 252M/3.93G [00:09<02:10, 28.2MiB/s]
  7%|â–‹         | 257M/3.93G [00:09<02:10, 28.2MiB/s]
  7%|â–‹         | 262M/3.93G [00:09<02:11, 27.9MiB/s]
  7%|â–‹         | 267M/3.93G [00:09<02:09, 28.3MiB/s]
  7%|â–‹         | 273M/3.93G [00:09<02:09, 28.4MiB/s]
  7%|â–‹         | 278M/3.93G [00:09<02:09, 28.2MiB/s]
  7%|â–‹         | 283M/3.93G [00:10<02:09, 28.3MiB/s]
  7%|â–‹         | 288M/3.93G [00:10<02:10, 28.0MiB/s]
  7%|â–‹         | 293M/3.93G [00:10<02:08, 28.4MiB/s]
  8%|â–Š         | 299M/3.93G [00:10<02:08, 28.3MiB/s]
  8%|â–Š         | 304M/3.93G [00:10<02:08, 28.3MiB/s]
  8%|â–Š         | 309M/3.93G [00:11<02:08, 28.3MiB/s]
  8%|â–Š         | 314M/3.93G [00:11<02:07, 28.3MiB/s]
  8%|â–Š         | 320M/3.93G [00:11<02:07, 28.3MiB/s]
  8%|â–Š         | 325M/3.93G [00:11<02:07, 28.2MiB/s]
  8%|â–Š         | 330M/3.93G [00:11<02:07, 28.2MiB/s]
  9%|â–Š         | 335M/3.93G [00:11<02:07, 28.2MiB/s]
  9%|â–Š         | 340M/3.93G [00:12<02:07, 28.2MiB/s]
  9%|â–‰         | 346M/3.93G [00:12<02:07, 28.3MiB/s]
  9%|â–‰         | 351M/3.93G [00:12<02:07, 28.0MiB/s]
  9%|â–‰         | 356M/3.93G [00:12<02:07, 28.0MiB/s]
  9%|â–‰         | 361M/3.93G [00:12<02:05, 28.4MiB/s]
  9%|â–‰         | 366M/3.93G [00:13<02:06, 28.3MiB/s]
  9%|â–‰         | 371M/3.93G [00:13<02:07, 28.0MiB/s]
 10%|â–‰         | 377M/3.93G [00:13<02:06, 28.1MiB/s]
 10%|â–‰         | 382M/3.93G [00:13<02:04, 28.5MiB/s]
 10%|â–‰         | 387M/3.93G [00:13<02:04, 28.4MiB/s]
 10%|â–‰         | 392M/3.93G [00:14<02:05, 28.1MiB/s]
 10%|â–ˆ         | 398M/3.93G [00:14<02:07, 27.8MiB/s]
 10%|â–ˆ         | 403M/3.93G [00:14<02:03, 28.6MiB/s]
 10%|â–ˆ         | 408M/3.93G [00:14<02:03, 28.6MiB/s]
 11%|â–ˆ         | 413M/3.93G [00:14<02:05, 28.1MiB/s]
 11%|â–ˆ         | 418M/3.93G [00:14<02:04, 28.2MiB/s]
 11%|â–ˆ         | 424M/3.93G [00:15<02:03, 28.5MiB/s]
 11%|â–ˆ         | 429M/3.93G [00:15<02:03, 28.4MiB/s]
 11%|â–ˆ         | 434M/3.93G [00:15<02:03, 28.3MiB/s]
 11%|â–ˆ         | 439M/3.93G [00:15<02:04, 28.0MiB/s]
 11%|â–ˆâ–        | 444M/3.93G [00:15<02:03, 28.4MiB/s]
 11%|â–ˆâ–        | 450M/3.93G [00:16<02:03, 28.3MiB/s]
 12%|â–ˆâ–        | 455M/3.93G [00:16<02:04, 28.0MiB/s]
 12%|â–ˆâ–        | 460M/3.93G [00:16<02:02, 28.4MiB/s]
 12%|â–ˆâ–        | 465M/3.93G [00:16<02:02, 28.3MiB/s]
 12%|â–ˆâ–        | 470M/3.93G [00:16<02:03, 28.0MiB/s]
 12%|â–ˆâ–        | 476M/3.93G [00:16<02:03, 28.1MiB/s]
 12%|â–ˆâ–        | 481M/3.93G [00:17<02:01, 28.4MiB/s]
 12%|â–ˆâ–        | 486M/3.93G [00:17<02:01, 28.4MiB/s]
 12%|â–ˆâ–        | 491M/3.93G [00:17<02:02, 28.1MiB/s]
 13%|â–ˆâ–Ž        | 496M/3.93G [00:17<02:01, 28.4MiB/s]
 13%|â–ˆâ–Ž        | 502M/3.93G [00:17<02:01, 28.3MiB/s]
 13%|â–ˆâ–Ž        | 507M/3.93G [00:18<02:01, 28.3MiB/s]
 13%|â–ˆâ–Ž        | 512M/3.93G [00:18<02:00, 28.3MiB/s]
 13%|â–ˆâ–Ž        | 517M/3.93G [00:18<02:00, 28.3MiB/s]
 13%|â–ˆâ–Ž        | 523M/3.93G [00:18<02:00, 28.3MiB/s]
 13%|â–ˆâ–Ž        | 528M/3.93G [00:18<02:00, 28.3MiB/s]
 14%|â–ˆâ–Ž        | 533M/3.93G [00:18<02:00, 28.2MiB/s]
 14%|â–ˆâ–Ž        | 538M/3.93G [00:19<02:00, 28.1MiB/s]
 14%|â–ˆâ–        | 543M/3.93G [00:19<02:00, 28.1MiB/s]
 14%|â–ˆâ–        | 548M/3.93G [00:19<02:00, 28.1MiB/s]
 14%|â–ˆâ–        | 553M/3.93G [00:19<02:00, 28.0MiB/s]
 14%|â–ˆâ–        | 559M/3.93G [00:19<02:00, 28.0MiB/s]
 14%|â–ˆâ–        | 564M/3.93G [00:19<01:43, 32.5MiB/s]
 14%|â–ˆâ–        | 567M/3.93G [00:20<01:57, 28.8MiB/s]
 14%|â–ˆâ–        | 570M/3.93G [00:20<02:10, 25.7MiB/s]
 15%|â–ˆâ–        | 574M/3.93G [00:20<02:03, 27.2MiB/s]
 15%|â–ˆâ–        | 579M/3.93G [00:20<01:43, 32.4MiB/s]
 15%|â–ˆâ–        | 583M/3.93G [00:20<02:08, 26.0MiB/s]
 15%|â–ˆâ–        | 586M/3.93G [00:20<02:11, 25.4MiB/s]
 15%|â–ˆâ–        | 590M/3.93G [00:20<02:00, 27.7MiB/s]
 15%|â–ˆâ–Œ        | 595M/3.93G [00:21<01:40, 33.1MiB/s]
 15%|â–ˆâ–Œ        | 598M/3.93G [00:21<01:56, 28.7MiB/s]
 15%|â–ˆâ–Œ        | 601M/3.93G [00:21<02:10, 25.5MiB/s]
 15%|â–ˆâ–Œ        | 605M/3.93G [00:21<02:02, 27.1MiB/s]
 16%|â–ˆâ–Œ        | 610M/3.93G [00:21<01:42, 32.4MiB/s]
 16%|â–ˆâ–Œ        | 614M/3.93G [00:21<01:59, 27.8MiB/s]
 16%|â–ˆâ–Œ        | 617M/3.93G [00:21<02:11, 25.2MiB/s]
 16%|â–ˆâ–Œ        | 621M/3.93G [00:22<02:02, 27.0MiB/s]
 16%|â–ˆâ–Œ        | 626M/3.93G [00:22<01:41, 32.5MiB/s]
 16%|â–ˆâ–Œ        | 629M/3.93G [00:22<01:57, 28.2MiB/s]
 16%|â–ˆâ–Œ        | 632M/3.93G [00:22<02:10, 25.4MiB/s]
 16%|â–ˆâ–Œ        | 636M/3.93G [00:22<02:01, 27.2MiB/s]
 16%|â–ˆâ–‹        | 641M/3.93G [00:22<01:42, 32.1MiB/s]
 16%|â–ˆâ–‹        | 645M/3.93G [00:22<01:57, 27.9MiB/s]
 16%|â–ˆâ–‹        | 648M/3.93G [00:23<02:10, 25.3MiB/s]
 17%|â–ˆâ–‹        | 652M/3.93G [00:23<01:59, 27.4MiB/s]
 17%|â–ˆâ–‹        | 657M/3.93G [00:23<01:41, 32.1MiB/s]
 17%|â–ˆâ–‹        | 660M/3.93G [00:23<01:57, 27.8MiB/s]
 17%|â–ˆâ–‹        | 663M/3.93G [00:23<02:08, 25.6MiB/s]
 17%|â–ˆâ–‹        | 667M/3.93G [00:23<01:59, 27.3MiB/s]
 17%|â–ˆâ–‹        | 672M/3.93G [00:23<01:42, 31.8MiB/s]
 17%|â–ˆâ–‹        | 675M/3.93G [00:24<01:58, 27.6MiB/s]
 17%|â–ˆâ–‹        | 678M/3.93G [00:24<02:05, 26.0MiB/s]
 17%|â–ˆâ–‹        | 683M/3.93G [00:24<01:59, 27.3MiB/s]
 17%|â–ˆâ–‹        | 687M/3.93G [00:24<01:42, 31.7MiB/s]
 18%|â–ˆâ–Š        | 691M/3.93G [00:24<01:58, 27.5MiB/s]
 18%|â–ˆâ–Š        | 694M/3.93G [00:24<02:05, 25.9MiB/s]
 18%|â–ˆâ–Š        | 698M/3.93G [00:24<01:58, 27.3MiB/s]
 18%|â–ˆâ–Š        | 703M/3.93G [00:24<01:42, 31.5MiB/s]
 18%|â–ˆâ–Š        | 706M/3.93G [00:25<01:58, 27.3MiB/s]
 18%|â–ˆâ–Š        | 709M/3.93G [00:25<02:03, 26.1MiB/s]
 18%|â–ˆâ–Š        | 714M/3.93G [00:25<01:57, 27.3MiB/s]
 18%|â–ˆâ–Š        | 718M/3.93G [00:25<01:41, 31.6MiB/s]
 18%|â–ˆâ–Š        | 722M/3.93G [00:25<01:57, 27.4MiB/s]
 18%|â–ˆâ–Š        | 725M/3.93G [00:25<02:02, 26.2MiB/s]
 19%|â–ˆâ–Š        | 729M/3.93G [00:25<01:57, 27.3MiB/s]
 19%|â–ˆâ–Š        | 734M/3.93G [00:26<01:40, 31.7MiB/s]
 19%|â–ˆâ–Š        | 737M/3.93G [00:26<01:56, 27.4MiB/s]
 19%|â–ˆâ–‰        | 740M/3.93G [00:26<02:35, 20.5MiB/s]
 19%|â–ˆâ–‰        | 747M/3.93G [00:26<01:50, 28.8MiB/s]
 19%|â–ˆâ–‰        | 750M/3.93G [00:26<01:47, 29.6MiB/s]
 19%|â–ˆâ–‰        | 755M/3.93G [00:26<01:36, 32.9MiB/s]
 19%|â–ˆâ–‰        | 758M/3.93G [00:26<01:50, 28.9MiB/s]
 19%|â–ˆâ–‰        | 762M/3.93G [00:27<01:57, 26.9MiB/s]
 19%|â–ˆâ–‰        | 766M/3.93G [00:27<01:45, 29.9MiB/s]
 20%|â–ˆâ–‰        | 769M/3.93G [00:27<01:49, 28.9MiB/s]
 20%|â–ˆâ–‰        | 772M/3.93G [00:27<02:01, 26.1MiB/s]
 20%|â–ˆâ–‰        | 776M/3.93G [00:27<01:53, 27.8MiB/s]
 20%|â–ˆâ–‰        | 780M/3.93G [00:27<01:40, 31.4MiB/s]
 20%|â–ˆâ–‰        | 784M/3.93G [00:27<01:56, 27.0MiB/s]
 20%|â–ˆâ–‰        | 786M/3.93G [00:28<01:56, 27.1MiB/s]
 20%|â–ˆâ–ˆ        | 791M/3.93G [00:28<01:38, 32.0MiB/s]
 20%|â–ˆâ–ˆ        | 795M/3.93G [00:28<01:53, 27.5MiB/s]
 20%|â–ˆâ–ˆ        | 798M/3.93G [00:28<02:01, 25.8MiB/s]
 20%|â–ˆâ–ˆ        | 802M/3.93G [00:28<01:45, 29.6MiB/s]
 20%|â–ˆâ–ˆ        | 805M/3.93G [00:28<01:51, 28.1MiB/s]
 21%|â–ˆâ–ˆ        | 808M/3.93G [00:28<01:59, 26.1MiB/s]
 21%|â–ˆâ–ˆ        | 812M/3.93G [00:28<01:45, 29.6MiB/s]
 21%|â–ˆâ–ˆ        | 815M/3.93G [00:29<01:51, 28.1MiB/s]
 21%|â–ˆâ–ˆ        | 818M/3.93G [00:29<01:59, 26.1MiB/s]
 21%|â–ˆâ–ˆ        | 822M/3.93G [00:29<01:44, 29.7MiB/s]
 21%|â–ˆâ–ˆ        | 826M/3.93G [00:29<01:50, 28.1MiB/s]
 21%|â–ˆâ–ˆ        | 828M/3.93G [00:29<01:57, 26.4MiB/s]
 21%|â–ˆâ–ˆ        | 833M/3.93G [00:29<01:43, 30.0MiB/s]
 21%|â–ˆâ–ˆ        | 836M/3.93G [00:29<01:50, 28.1MiB/s]
 21%|â–ˆâ–ˆâ–       | 839M/3.93G [00:29<01:57, 26.2MiB/s]
 21%|â–ˆâ–ˆâ–       | 843M/3.93G [00:29<01:43, 29.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 846M/3.93G [00:30<01:50, 28.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 849M/3.93G [00:30<01:57, 26.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 854M/3.93G [00:30<01:43, 29.7MiB/s]
 22%|â–ˆâ–ˆâ–       | 857M/3.93G [00:30<01:49, 28.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 859M/3.93G [00:30<01:56, 26.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 864M/3.93G [00:30<01:42, 29.9MiB/s]
 22%|â–ˆâ–ˆâ–       | 867M/3.93G [00:30<01:49, 28.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 870M/3.93G [00:30<01:57, 26.2MiB/s]
 22%|â–ˆâ–ˆâ–       | 874M/3.93G [00:31<01:43, 29.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 877M/3.93G [00:31<01:51, 27.4MiB/s]
 22%|â–ˆâ–ˆâ–       | 880M/3.93G [00:31<01:49, 27.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 884M/3.93G [00:31<01:37, 31.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 887M/3.93G [00:31<01:54, 26.7MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 890M/3.93G [00:31<01:50, 27.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 894M/3.93G [00:31<01:38, 31.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 898M/3.93G [00:31<01:54, 26.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 901M/3.93G [00:32<01:50, 27.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 904M/3.93G [00:32<01:39, 30.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 908M/3.93G [00:32<01:56, 26.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 911M/3.93G [00:32<01:49, 27.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 915M/3.93G [00:32<01:40, 30.2MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 918M/3.93G [00:32<01:55, 26.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 921M/3.93G [00:32<01:49, 27.5MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 924M/3.93G [00:32<01:43, 29.0MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 927M/3.93G [00:33<01:54, 26.3MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 931M/3.93G [00:33<01:47, 28.0MiB/s]
 24%|â–ˆâ–ˆâ–       | 935M/3.93G [00:33<01:42, 29.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 938M/3.93G [00:33<01:53, 26.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 942M/3.93G [00:33<01:45, 28.3MiB/s]
 24%|â–ˆâ–ˆâ–       | 945M/3.93G [00:33<01:42, 29.2MiB/s]
 24%|â–ˆâ–ˆâ–       | 948M/3.93G [00:33<01:53, 26.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 952M/3.93G [00:33<01:44, 28.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 955M/3.93G [00:33<01:41, 29.2MiB/s]
 24%|â–ˆâ–ˆâ–       | 958M/3.93G [00:34<01:56, 25.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 962M/3.93G [00:34<01:42, 29.0MiB/s]
 25%|â–ˆâ–ˆâ–       | 965M/3.93G [00:34<01:41, 29.3MiB/s]
 25%|â–ˆâ–ˆâ–       | 969M/3.93G [00:34<01:51, 26.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 973M/3.93G [00:34<01:37, 30.4MiB/s]
 25%|â–ˆâ–ˆâ–       | 976M/3.93G [00:34<01:43, 28.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 979M/3.93G [00:34<01:50, 26.8MiB/s]
 25%|â–ˆâ–ˆâ–       | 983M/3.93G [00:34<01:41, 29.2MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 986M/3.93G [00:35<01:47, 27.4MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 989M/3.93G [00:35<01:45, 27.9MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 993M/3.93G [00:35<01:32, 31.9MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 996M/3.93G [00:35<01:48, 27.1MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 999M/3.93G [00:35<01:47, 27.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.00G/3.93G [00:35<01:41, 28.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:35<01:48, 26.9MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:35<01:46, 27.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.01G/3.93G [00:36<01:32, 31.5MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:36<01:48, 26.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:36<01:47, 27.1MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.02G/3.93G [00:36<01:32, 31.3MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:36<01:48, 26.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.03G/3.93G [00:36<01:50, 26.4MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.03G/3.93G [00:36<01:40, 29.0MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:36<01:46, 27.1MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:37<01:45, 27.4MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.04G/3.93G [00:37<01:32, 31.2MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:37<01:48, 26.6MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:37<01:46, 27.1MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.05G/3.93G [00:37<01:32, 31.0MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:37<01:48, 26.6MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.06G/3.93G [00:37<01:46, 27.1MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:37<01:33, 30.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:38<01:48, 26.4MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.07G/3.93G [00:38<01:45, 27.1MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:38<01:32, 31.0MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:38<01:47, 26.6MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.08G/3.93G [00:38<01:44, 27.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:38<01:33, 30.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:38<01:48, 26.1MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.09G/3.93G [00:38<01:44, 27.3MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:38<01:33, 30.5MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:39<01:47, 26.3MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.10G/3.93G [00:39<01:43, 27.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:39<01:33, 30.3MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:39<01:47, 26.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.11G/3.93G [00:39<01:42, 27.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:39<01:32, 30.5MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:39<01:46, 26.3MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.12G/3.93G [00:39<01:41, 27.6MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:40<01:32, 30.4MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.13G/3.93G [00:40<01:46, 26.3MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.13G/3.93G [00:40<01:40, 27.8MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:40<01:35, 29.4MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:40<01:46, 26.1MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.14G/3.93G [00:40<01:38, 28.4MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:40<01:38, 28.4MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:40<01:41, 27.3MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.15G/3.93G [00:41<01:33, 29.7MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:41<01:41, 27.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:41<01:40, 27.6MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.16G/3.93G [00:41<01:30, 30.6MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:41<01:45, 26.1MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:41<01:39, 27.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.17G/3.93G [00:41<01:48, 25.4MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:41<01:41, 27.3MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.18G/3.93G [00:41<01:34, 29.1MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.18G/3.93G [00:42<01:35, 28.9MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:42<01:39, 27.7MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:42<01:30, 30.2MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.19G/3.93G [00:42<01:38, 27.7MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:42<01:38, 27.9MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:42<01:29, 30.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.20G/3.93G [00:42<01:44, 26.2MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:42<01:38, 27.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:43<01:31, 29.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.21G/3.93G [00:43<01:44, 26.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:43<01:36, 28.2MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:43<01:36, 28.2MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.22G/3.93G [00:43<01:38, 27.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.23G/3.93G [00:43<01:31, 29.6MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.23G/3.93G [00:43<01:39, 27.2MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.23G/3.93G [00:43<01:36, 27.9MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:43<01:27, 30.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:44<01:42, 26.2MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.24G/3.93G [00:44<01:36, 27.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:44<01:28, 30.5MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:44<01:42, 26.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.25G/3.93G [00:44<01:37, 27.6MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:44<01:28, 30.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:44<01:42, 26.2MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.93G [00:44<01:36, 27.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:45<01:27, 30.4MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:45<01:41, 26.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.93G [00:45<01:35, 27.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.93G [00:45<01:27, 30.3MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:45<01:41, 26.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.28G/3.93G [00:45<01:34, 28.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:45<01:29, 29.7MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:45<01:41, 26.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.29G/3.93G [00:46<01:34, 28.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:46<01:34, 28.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:46<01:34, 27.8MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.30G/3.93G [00:46<01:24, 31.2MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:46<01:37, 27.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:46<01:35, 27.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.31G/3.93G [00:46<01:25, 30.5MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:46<01:39, 26.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:46<01:35, 27.5MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.32G/3.93G [00:47<01:27, 29.8MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.33G/3.93G [00:47<01:39, 26.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.33G/3.93G [00:47<01:33, 27.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.33G/3.93G [00:47<01:32, 28.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:47<01:33, 27.8MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:47<01:23, 31.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.34G/3.93G [00:47<01:36, 27.0MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:47<01:33, 27.7MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:48<01:25, 30.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.35G/3.93G [00:48<01:39, 25.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:48<01:31, 28.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:48<01:28, 29.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.36G/3.93G [00:48<01:38, 26.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:48<01:31, 28.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:48<01:31, 28.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.37G/3.93G [00:48<01:30, 28.3MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.38G/3.93G [00:48<01:23, 30.6MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:49<01:36, 26.5MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.38G/3.93G [00:49<01:30, 28.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:49<01:24, 30.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:49<01:37, 26.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:49<01:30, 28.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.39G/3.93G [00:49<01:29, 28.5MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:49<01:32, 27.3MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:49<01:25, 29.6MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.40G/3.93G [00:50<01:33, 26.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:50<01:30, 27.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:50<01:24, 30.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.41G/3.93G [00:50<01:37, 25.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:50<01:29, 28.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:50<01:26, 29.2MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.42G/3.93G [00:50<01:35, 26.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:50<01:28, 28.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:50<01:29, 28.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.43G/3.93G [00:51<01:29, 27.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:51<01:20, 31.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:51<01:34, 26.5MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.44G/3.93G [00:51<01:29, 27.7MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:51<01:21, 30.5MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:51<01:34, 26.3MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.45G/3.93G [00:51<01:29, 27.7MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:51<01:22, 30.2MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:52<01:40, 24.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.46G/3.93G [00:52<01:36, 25.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:52<01:19, 30.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.47G/3.93G [00:52<01:26, 28.5MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.48G/3.93G [00:52<01:28, 27.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:52<01:21, 30.3MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.48G/3.93G [00:52<01:29, 27.4MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:52<01:27, 28.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:52<01:20, 30.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.49G/3.93G [00:53<01:33, 26.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:53<01:27, 28.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:53<01:22, 29.5MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.50G/3.93G [00:53<01:32, 26.4MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:53<01:25, 28.4MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:53<01:27, 27.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:53<01:26, 27.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.51G/3.93G [00:53<01:18, 30.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:54<01:31, 26.3MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.52G/3.93G [00:54<01:26, 27.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.52G/3.93G [00:54<01:20, 30.0MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:54<01:31, 26.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:54<01:25, 28.2MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.53G/3.93G [00:54<01:24, 28.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:54<01:27, 27.5MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:54<01:20, 29.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.54G/3.93G [00:55<01:29, 26.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:55<01:25, 27.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:55<01:20, 29.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.55G/3.93G [00:55<01:28, 27.0MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:55<01:23, 28.6MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:55<01:25, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.56G/3.93G [00:55<01:24, 28.1MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:55<01:19, 29.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:55<01:28, 26.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.57G/3.93G [00:56<01:23, 28.3MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:56<01:24, 27.8MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:56<01:24, 27.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.58G/3.93G [00:56<01:16, 30.6MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:56<01:28, 26.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:56<01:23, 28.0MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:56<01:20, 29.0MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.59G/3.93G [00:56<01:25, 27.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:56<01:23, 28.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:57<01:25, 27.3MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.60G/3.93G [00:57<01:22, 28.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:57<01:16, 30.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:57<01:27, 26.6MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.61G/3.93G [00:57<01:22, 28.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:57<01:22, 28.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.62G/3.93G [00:57<01:22, 28.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.62G/3.93G [00:57<01:18, 29.5MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:57<01:26, 26.7MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:58<01:21, 28.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.63G/3.93G [00:58<01:21, 28.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:58<01:22, 27.8MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:58<01:18, 29.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.93G [00:58<01:26, 26.5MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:58<01:20, 28.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:58<01:21, 28.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:58<01:22, 27.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.93G [00:58<01:17, 29.4MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [00:59<01:25, 26.6MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [00:59<01:20, 28.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.93G [00:59<01:20, 28.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.93G [00:59<01:21, 27.9MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.93G [00:59<01:16, 29.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.67G/3.93G [00:59<01:25, 26.4MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [00:59<01:19, 28.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [00:59<01:18, 28.6MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.68G/3.93G [00:59<01:20, 27.9MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:00<01:16, 29.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:00<01:24, 26.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.69G/3.93G [01:00<01:19, 28.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:00<01:18, 28.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:00<01:21, 27.4MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:00<01:15, 29.4MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.70G/3.93G [01:00<01:23, 26.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:00<01:18, 28.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:00<01:16, 29.2MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.71G/3.93G [01:01<01:20, 27.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [01:01<01:20, 27.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.72G/3.93G [01:01<01:22, 26.9MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.72G/3.93G [01:01<01:18, 28.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:01<01:16, 28.8MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:01<01:18, 28.0MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.73G/3.93G [01:01<01:14, 29.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:01<01:20, 27.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:01<01:18, 28.0MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:02<01:20, 27.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.74G/3.93G [01:02<01:20, 27.2MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:02<01:13, 29.7MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:02<01:19, 27.6MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.75G/3.93G [01:02<01:18, 27.8MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:02<01:19, 27.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:02<01:18, 27.8MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.76G/3.93G [01:02<01:13, 29.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.77G/3.93G [01:03<02:06, 17.1MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:03<01:08, 31.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:03<01:10, 30.8MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.78G/3.93G [01:03<01:10, 30.6MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:03<01:13, 29.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:03<01:13, 29.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.79G/3.93G [01:03<01:12, 29.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:04<01:16, 27.8MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:04<01:15, 28.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.80G/3.93G [01:04<01:17, 27.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:04<01:14, 28.5MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:04<01:13, 28.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.81G/3.93G [01:04<01:18, 27.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.82G/3.93G [01:04<01:14, 28.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.82G/3.93G [01:04<01:14, 28.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:04<01:15, 28.1MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.82G/3.93G [01:04<01:16, 27.7MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:05<01:15, 28.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:05<01:11, 29.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.83G/3.93G [01:05<01:16, 27.6MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:05<01:14, 28.3MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:05<01:16, 27.3MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.84G/3.93G [01:05<01:12, 28.9MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:05<01:13, 28.5MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:05<01:15, 27.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:05<01:10, 29.5MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.85G/3.93G [01:06<01:17, 26.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:06<01:13, 28.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:06<01:13, 28.3MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.86G/3.93G [01:06<01:15, 27.3MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.87G/3.93G [01:06<01:10, 29.4MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [01:06<01:13, 28.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.87G/3.93G [01:06<01:14, 27.7MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:06<01:15, 27.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:06<01:13, 28.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:07<01:12, 28.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.88G/3.93G [01:07<01:13, 27.7MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:07<01:12, 28.1MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:07<01:12, 28.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.89G/3.93G [01:07<01:13, 27.9MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:07<01:14, 27.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:07<01:11, 28.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.90G/3.93G [01:07<01:11, 28.4MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:07<01:13, 27.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:07<01:12, 28.0MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:08<01:11, 28.2MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.91G/3.93G [01:08<01:12, 28.0MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.92G/3.93G [01:08<01:12, 27.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [01:08<01:09, 28.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.92G/3.93G [01:08<01:10, 28.7MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:08<01:13, 27.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:08<01:11, 27.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.93G/3.93G [01:08<01:11, 28.1MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:08<01:11, 28.1MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:09<01:11, 27.8MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:09<01:11, 28.1MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.94G/3.93G [01:09<01:09, 28.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:09<01:11, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:09<01:10, 28.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.95G/3.93G [01:09<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:09<01:10, 28.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:09<01:11, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:09<01:10, 27.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.96G/3.93G [01:09<01:08, 28.8MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:10<01:10, 28.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:10<01:10, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.97G/3.93G [01:10<01:09, 28.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [01:10<01:09, 28.3MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [01:10<01:10, 27.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.98G/3.93G [01:10<01:10, 27.8MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:10<01:08, 28.3MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:10<01:09, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:10<01:10, 27.8MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.99G/3.93G [01:11<01:08, 28.2MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [01:11<01:08, 28.3MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [01:11<01:09, 27.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.00G/3.93G [01:11<01:09, 28.0MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:11<01:07, 28.6MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:11<01:08, 28.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:11<01:08, 27.9MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.01G/3.93G [01:11<01:08, 28.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.93G [01:11<01:08, 28.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.93G [01:11<01:09, 27.5MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.93G [01:12<01:07, 28.2MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [01:12<01:07, 28.4MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [01:12<01:07, 28.3MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.93G [01:12<01:08, 27.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:12<01:07, 28.2MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:12<01:07, 28.1MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:12<01:08, 27.6MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.93G [01:12<01:08, 27.7MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [01:12<01:06, 28.3MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [01:13<01:06, 28.5MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.93G [01:13<01:08, 27.3MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [01:13<01:07, 27.7MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [01:13<01:07, 28.0MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.93G [01:13<01:05, 28.5MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:13<01:05, 28.7MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:13<01:04, 29.1MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:13<01:06, 28.1MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.07G/3.93G [01:13<01:07, 27.7MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [01:13<01:07, 27.4MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [01:14<01:06, 27.7MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.08G/3.93G [01:14<01:05, 28.4MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.09G/3.93G [01:14<01:05, 28.1MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.09G/3.93G [01:14<01:05, 28.2MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.09G/3.93G [01:14<01:04, 28.4MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:14<01:05, 27.9MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:14<01:06, 27.5MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:14<01:06, 27.6MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.10G/3.93G [01:14<01:02, 29.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [01:15<01:05, 27.8MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [01:15<01:05, 27.8MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.11G/3.93G [01:15<01:04, 28.4MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:15<01:05, 27.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:15<01:04, 28.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:15<01:04, 28.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.12G/3.93G [01:15<01:03, 28.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [01:15<01:05, 27.8MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [01:15<01:03, 28.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.13G/3.93G [01:15<01:03, 28.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [01:16<01:04, 27.8MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [01:16<01:03, 28.2MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [01:16<01:04, 27.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.14G/3.93G [01:16<01:04, 27.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [01:16<01:04, 27.7MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [01:16<01:02, 28.4MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.15G/3.93G [01:16<01:03, 28.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.16G/3.93G [01:16<01:04, 27.6MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.16G/3.93G [01:16<01:03, 28.0MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.16G/3.93G [01:17<01:04, 27.5MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:17<01:02, 28.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:17<01:01, 28.7MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:17<01:01, 28.5MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.17G/3.93G [01:17<01:03, 27.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [01:17<01:00, 29.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [01:17<01:03, 27.5MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.18G/3.93G [01:17<01:03, 27.5MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:17<01:02, 27.8MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:17<01:01, 28.6MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:18<01:01, 28.4MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.19G/3.93G [01:18<01:02, 28.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [01:18<00:59, 29.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [01:18<01:03, 27.4MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.20G/3.93G [01:18<01:02, 27.7MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.21G/3.93G [01:18<01:02, 27.7MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.21G/3.93G [01:18<01:00, 28.5MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.21G/3.93G [01:18<01:00, 28.3MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:18<01:01, 27.8MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:19<00:59, 28.8MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:19<01:02, 27.4MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.22G/3.93G [01:19<01:01, 27.6MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [01:19<01:00, 28.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [01:19<01:00, 28.4MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.23G/3.93G [01:19<01:00, 28.2MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:19<01:00, 27.9MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:19<00:59, 28.7MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:19<01:01, 27.3MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.24G/3.93G [01:19<01:00, 27.7MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.25G/3.93G [01:20<00:59, 28.4MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.25G/3.93G [01:20<00:59, 28.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.25G/3.93G [01:20<01:00, 27.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.26G/3.93G [01:20<01:00, 27.7MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.26G/3.93G [01:20<00:58, 28.7MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.26G/3.93G [01:20<00:58, 28.4MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:20<00:58, 28.6MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:20<01:00, 27.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:20<01:00, 27.5MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.27G/3.93G [01:20<00:58, 28.6MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [01:21<00:59, 27.7MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [01:21<00:57, 28.7MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.28G/3.93G [01:21<00:59, 27.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:21<00:58, 28.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:21<00:59, 27.6MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:21<00:59, 27.7MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.29G/3.93G [01:21<00:58, 28.2MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [01:21<00:58, 27.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [01:21<00:56, 28.8MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.30G/3.93G [01:22<00:57, 28.3MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.31G/3.93G [01:22<00:57, 28.4MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.31G/3.93G [01:22<00:58, 27.6MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.31G/3.93G [01:22<00:58, 27.6MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:22<00:57, 28.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:22<00:57, 27.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:22<00:58, 27.8MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.32G/3.93G [01:22<00:57, 28.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:22<00:56, 28.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:22<00:56, 28.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.33G/3.93G [01:23<00:56, 28.5MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [01:23<01:02, 25.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [01:23<01:00, 26.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.34G/3.93G [01:23<00:58, 27.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:23<00:54, 29.0MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:23<00:54, 29.2MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:23<00:55, 28.7MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.35G/3.93G [01:24<01:22, 19.2MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.36G/3.93G [01:24<00:50, 31.2MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [01:24<00:51, 30.7MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [01:24<00:53, 29.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.37G/3.93G [01:24<00:53, 29.3MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:24<00:53, 29.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:24<00:53, 29.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:24<00:55, 28.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.38G/3.93G [01:24<00:54, 28.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [01:25<00:55, 27.9MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [01:25<00:54, 28.3MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.39G/3.93G [01:25<00:53, 28.6MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:25<00:54, 28.3MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:25<00:53, 28.5MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.40G/3.93G [01:25<00:54, 28.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.41G/3.93G [01:25<00:53, 28.8MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.41G/3.93G [01:25<00:55, 27.7MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.93G [01:25<00:54, 27.9MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.93G [01:25<00:54, 27.8MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [01:26<00:54, 28.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [01:26<00:53, 28.4MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.93G [01:26<00:53, 28.3MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:26<00:53, 28.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:26<00:54, 27.5MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:26<00:54, 27.8MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.93G [01:26<00:53, 28.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [01:26<00:52, 28.5MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [01:26<00:53, 28.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.44G/3.93G [01:27<00:53, 28.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:27<00:52, 28.3MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:27<00:52, 28.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:27<00:52, 28.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.45G/3.93G [01:27<00:53, 27.6MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.46G/3.93G [01:27<00:53, 27.6MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.46G/3.93G [01:27<00:53, 27.6MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.46G/3.93G [01:27<00:51, 28.3MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:27<00:52, 28.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:27<00:52, 28.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:28<00:51, 28.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.47G/3.93G [01:28<00:51, 28.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:28<00:51, 28.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:28<00:52, 27.8MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.48G/3.93G [01:28<00:52, 27.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:28<00:52, 27.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:28<00:50, 28.8MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:28<00:50, 28.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.49G/3.93G [01:28<00:51, 28.0MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [01:28<00:51, 27.7MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [01:29<00:51, 28.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.50G/3.93G [01:29<00:50, 28.5MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.51G/3.93G [01:29<00:50, 28.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.51G/3.93G [01:29<00:50, 28.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.51G/3.93G [01:29<00:51, 27.5MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:29<00:49, 28.6MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:29<00:49, 28.8MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:29<00:50, 28.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.52G/3.93G [01:29<00:50, 27.8MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [01:30<00:50, 27.9MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [01:30<00:49, 28.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.53G/3.93G [01:30<00:50, 28.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:30<00:49, 28.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:30<00:50, 27.5MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:30<00:49, 28.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.54G/3.93G [01:30<00:49, 28.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [01:30<00:48, 28.4MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [01:30<00:48, 28.6MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.55G/3.93G [01:30<00:49, 27.7MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.56G/3.93G [01:31<00:49, 27.9MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.56G/3.93G [01:31<00:50, 27.5MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.56G/3.93G [01:31<00:47, 28.7MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.56G/3.93G [01:31<00:48, 28.4MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:31<00:48, 28.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:31<00:48, 28.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.57G/3.93G [01:31<00:48, 27.9MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:31<00:48, 27.9MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:31<00:49, 27.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:31<00:47, 28.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.58G/3.93G [01:32<00:48, 27.7MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [01:32<00:47, 28.5MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [01:32<00:48, 27.7MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.59G/3.93G [01:32<00:47, 28.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:32<00:47, 28.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:32<00:48, 27.7MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.60G/3.93G [01:32<00:47, 27.9MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.61G/3.93G [01:32<00:48, 27.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.61G/3.93G [01:32<00:46, 28.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.61G/3.93G [01:33<00:46, 28.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.61G/3.93G [01:33<00:46, 28.4MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [01:33<00:46, 28.2MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [01:33<00:47, 27.6MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.62G/3.93G [01:33<00:46, 28.2MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:33<00:46, 28.0MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:33<00:48, 27.2MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:33<00:49, 26.1MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.63G/3.93G [01:33<00:50, 25.9MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:33<00:43, 29.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:34<00:44, 28.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.64G/3.93G [01:34<00:44, 29.1MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:34<00:44, 28.7MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:34<00:45, 28.5MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.65G/3.93G [01:34<00:45, 28.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:34<00:45, 28.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:34<00:44, 28.6MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:34<00:44, 28.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.66G/3.93G [01:34<00:45, 28.2MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:35<00:46, 27.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:35<00:44, 28.5MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.67G/3.93G [01:35<00:45, 27.6MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:35<00:44, 28.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:35<00:44, 28.3MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.68G/3.93G [01:35<00:44, 27.9MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:35<00:44, 28.1MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:35<00:44, 27.9MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:35<00:43, 28.3MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.69G/3.93G [01:35<00:44, 27.8MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:36<00:44, 27.9MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:36<00:44, 27.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.70G/3.93G [01:36<00:43, 28.3MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:36<00:43, 28.0MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:36<00:43, 28.0MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:36<00:43, 28.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.71G/3.93G [01:36<00:42, 28.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [01:36<00:43, 28.3MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [01:36<00:43, 27.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.72G/3.93G [01:36<00:43, 28.0MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:37<00:43, 27.7MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:37<00:42, 28.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:37<00:42, 28.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.73G/3.93G [01:37<00:42, 28.3MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:37<00:42, 27.9MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:37<00:42, 28.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.74G/3.93G [01:37<00:42, 28.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [01:37<00:42, 27.8MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [01:37<00:42, 28.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.75G/3.93G [01:38<00:42, 27.5MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.75G/3.93G [01:38<00:41, 28.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [01:38<00:41, 28.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [01:38<00:41, 28.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.76G/3.93G [01:38<00:41, 28.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:38<00:41, 28.5MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:38<00:41, 28.3MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:38<00:41, 28.0MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.77G/3.93G [01:38<00:41, 28.1MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:38<00:41, 27.6MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:39<00:40, 28.2MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.78G/3.93G [01:39<00:41, 28.0MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:39<00:40, 28.1MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:39<00:41, 27.8MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:39<00:39, 28.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.79G/3.93G [01:39<00:40, 28.1MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.80G/3.93G [01:39<00:41, 27.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.80G/3.93G [01:39<00:40, 27.8MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.80G/3.93G [01:39<00:40, 27.7MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:39<00:40, 27.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:40<00:40, 28.1MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:40<00:39, 28.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.81G/3.93G [01:40<00:40, 27.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [01:40<00:38, 28.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [01:40<00:39, 28.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.82G/3.93G [01:40<00:40, 27.6MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:40<00:39, 28.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:40<00:39, 28.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.83G/3.93G [01:40<00:38, 28.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:41<00:39, 27.6MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:41<00:38, 28.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:41<00:38, 28.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.84G/3.93G [01:41<00:39, 27.9MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.85G/3.93G [01:41<00:39, 27.9MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.85G/3.93G [01:41<00:39, 27.5MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.85G/3.93G [01:41<00:38, 27.8MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:41<00:38, 28.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:41<00:38, 28.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:41<00:38, 27.9MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.86G/3.93G [01:42<00:37, 28.7MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:42<00:37, 28.1MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:42<00:37, 28.1MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.87G/3.93G [01:42<00:37, 28.0MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:42<00:38, 27.6MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:42<00:38, 27.5MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:42<00:37, 28.4MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.88G/3.93G [01:42<00:37, 28.4MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:42<00:37, 27.8MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:42<00:36, 28.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.89G/3.93G [01:43<00:37, 28.0MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.90G/3.93G [01:43<00:36, 28.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.90G/3.93G [01:43<00:37, 27.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.90G/3.93G [01:43<00:37, 27.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.90G/3.93G [01:43<00:37, 27.5MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:43<00:35, 28.7MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:43<00:35, 28.7MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.91G/3.93G [01:43<00:36, 27.9MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:43<00:36, 28.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:44<00:38, 26.5MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.92G/3.93G [01:44<00:38, 26.3MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:44<00:38, 26.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:44<00:33, 29.6MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.93G/3.93G [01:44<00:34, 28.9MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:44<00:34, 28.8MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:44<00:34, 29.3MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:44<00:34, 29.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.94G/3.93G [01:44<00:35, 28.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.95G/3.93G [01:45<00:34, 28.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.95G/3.93G [01:45<00:35, 28.1MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.95G/3.93G [01:45<00:55, 17.7MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.96G/3.93G [01:45<00:31, 31.3MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:45<00:31, 30.4MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:45<00:31, 30.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.97G/3.93G [01:45<00:32, 29.8MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:46<00:33, 28.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:46<00:33, 28.6MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.98G/3.93G [01:46<00:33, 28.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:46<00:32, 28.9MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:46<00:32, 28.9MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:46<00:33, 28.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.99G/3.93G [01:46<00:33, 28.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.00G/3.93G [01:46<00:33, 27.6MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.00G/3.93G [01:46<00:33, 28.0MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.00G/3.93G [01:46<00:33, 28.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:47<00:32, 28.6MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:47<00:32, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:47<00:32, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.01G/3.93G [01:47<00:32, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:47<00:32, 27.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:47<00:32, 27.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.02G/3.93G [01:47<00:33, 27.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:47<00:32, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:47<00:32, 28.1MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:47<00:31, 28.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.03G/3.93G [01:48<00:31, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:48<00:31, 28.3MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:48<00:31, 28.2MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.04G/3.93G [01:48<00:31, 27.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.05G/3.93G [01:48<00:31, 27.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.05G/3.93G [01:48<00:32, 27.1MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.05G/3.93G [01:48<00:31, 28.1MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.05G/3.93G [01:48<00:31, 27.9MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:48<00:30, 28.5MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:49<00:30, 28.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.06G/3.93G [01:49<00:31, 27.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:49<00:31, 27.9MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:49<00:31, 27.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:49<00:31, 27.6MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.07G/3.93G [01:49<00:30, 27.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.08G/3.93G [01:49<00:30, 28.3MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.08G/3.93G [01:49<00:30, 28.1MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.08G/3.93G [01:49<00:29, 28.6MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:49<00:29, 29.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:50<00:30, 27.4MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.09G/3.93G [01:50<00:30, 27.7MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.10G/3.93G [01:50<00:30, 27.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.10G/3.93G [01:50<00:29, 27.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.10G/3.93G [01:50<00:29, 28.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.10G/3.93G [01:50<00:28, 28.7MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:50<00:28, 28.8MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:50<00:29, 28.2MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.11G/3.93G [01:50<00:29, 28.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:51<00:29, 27.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:51<00:29, 28.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:51<00:29, 27.5MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.12G/3.93G [01:51<00:28, 28.6MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:51<00:28, 28.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:51<00:28, 28.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.13G/3.93G [01:51<00:28, 28.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:51<00:29, 27.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:51<00:28, 28.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.14G/3.93G [01:51<00:29, 27.1MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.15G/3.93G [01:52<00:27, 28.7MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:52<00:27, 28.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:52<00:28, 28.0MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.15G/3.93G [01:52<00:28, 27.8MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:52<00:27, 27.9MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:52<00:27, 28.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.16G/3.93G [01:52<00:28, 27.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:52<00:27, 27.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:52<00:27, 28.2MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:52<00:26, 28.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.17G/3.93G [01:53<00:26, 28.7MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:53<00:27, 27.9MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:53<00:26, 28.3MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.18G/3.93G [01:53<00:27, 27.5MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:53<00:27, 27.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:53<00:27, 27.4MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:53<00:26, 28.5MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.19G/3.93G [01:53<00:25, 28.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [01:53<00:25, 28.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [01:54<00:26, 28.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.20G/3.93G [01:54<00:26, 28.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:54<00:25, 28.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:54<00:26, 27.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:54<00:26, 27.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.21G/3.93G [01:54<00:28, 25.5MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [01:54<00:27, 26.5MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.22G/3.93G [01:54<00:24, 29.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:54<00:24, 28.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:55<00:24, 29.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:55<00:24, 29.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.23G/3.93G [01:55<00:24, 29.1MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:55<00:24, 28.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:55<00:25, 27.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.24G/3.93G [01:55<00:24, 27.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.25G/3.93G [01:55<00:25, 27.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:55<00:24, 28.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:55<00:24, 28.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.25G/3.93G [01:55<00:23, 29.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [01:56<00:24, 28.0MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [01:56<00:24, 27.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.26G/3.93G [01:56<00:24, 27.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:56<00:24, 27.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:56<00:23, 27.9MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.27G/3.93G [01:56<00:23, 28.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [01:56<00:22, 28.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [01:56<00:23, 28.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [01:56<00:22, 28.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.28G/3.93G [01:56<00:22, 28.3MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [01:57<00:23, 27.4MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [01:57<00:23, 27.4MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.29G/3.93G [01:57<00:23, 27.6MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.30G/3.93G [01:57<00:22, 28.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [01:57<00:22, 28.3MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [01:57<00:22, 28.3MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.30G/3.93G [01:57<00:22, 28.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [01:57<00:21, 28.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [01:57<00:22, 28.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.31G/3.93G [01:58<00:22, 27.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [01:58<00:22, 27.1MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [01:58<00:21, 28.1MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [01:58<00:21, 28.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.32G/3.93G [01:58<00:21, 28.5MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [01:58<00:21, 28.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [01:58<00:21, 28.1MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.33G/3.93G [01:58<00:21, 28.3MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [01:58<00:21, 27.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [01:58<00:21, 27.4MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [01:59<00:21, 27.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.34G/3.93G [01:59<00:21, 28.1MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [01:59<00:20, 28.5MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [01:59<00:20, 27.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.35G/3.93G [01:59<00:19, 29.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [01:59<00:20, 28.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [01:59<00:20, 27.5MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [01:59<00:21, 27.2MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.36G/3.93G [01:59<00:20, 28.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [01:59<00:20, 27.7MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [02:00<00:20, 27.8MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.37G/3.93G [02:00<00:19, 29.3MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:00<00:19, 28.5MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:00<00:19, 28.2MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.38G/3.93G [02:00<00:20, 27.2MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [02:00<00:19, 27.9MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [02:00<00:19, 27.7MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.39G/3.93G [02:00<00:19, 28.5MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.39G/3.93G [02:00<00:19, 28.3MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:01<00:19, 28.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:01<00:18, 28.5MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.40G/3.93G [02:01<00:18, 28.1MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:01<00:19, 27.7MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:01<00:19, 27.6MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:01<00:18, 28.1MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.41G/3.93G [02:01<00:18, 28.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [02:01<00:18, 27.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [02:01<00:17, 28.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.42G/3.93G [02:01<00:18, 27.8MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.43G/3.93G [02:02<00:29, 17.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.43G/3.93G [02:02<00:15, 31.6MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.44G/3.93G [02:02<00:16, 30.5MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.44G/3.93G [02:02<00:16, 29.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:02<00:16, 30.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:02<00:16, 29.2MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.45G/3.93G [02:03<00:16, 28.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:03<00:16, 28.7MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:03<00:16, 28.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:03<00:16, 28.5MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.46G/3.93G [02:03<00:16, 27.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:03<00:16, 28.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:03<00:16, 28.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.47G/3.93G [02:03<00:16, 28.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:03<00:16, 27.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:03<00:16, 27.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:04<00:15, 28.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.48G/3.93G [02:04<00:16, 28.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.49G/3.93G [02:04<00:15, 28.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.49G/3.93G [02:04<00:15, 27.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.49G/3.93G [02:04<00:15, 27.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:04<00:15, 27.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:04<00:15, 28.1MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:04<00:15, 27.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.50G/3.93G [02:04<00:15, 27.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:04<00:15, 27.3MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:05<00:16, 26.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.51G/3.93G [02:05<00:15, 28.0MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [02:05<00:14, 28.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [02:05<00:14, 28.9MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.52G/3.93G [02:05<00:14, 28.8MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:05<00:14, 28.7MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:05<00:13, 29.2MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:05<00:14, 27.7MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.53G/3.93G [02:05<00:14, 27.8MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.54G/3.93G [02:06<00:13, 28.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.54G/3.93G [02:06<00:13, 28.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.54G/3.93G [02:06<00:14, 27.6MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.55G/3.93G [02:06<00:14, 27.4MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.55G/3.93G [02:06<00:13, 29.1MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.55G/3.93G [02:06<00:13, 28.1MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.56G/3.93G [02:06<00:13, 28.0MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.56G/3.93G [02:06<00:13, 28.1MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.56G/3.93G [02:06<00:13, 27.9MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.56G/3.93G [02:06<00:13, 27.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.57G/3.93G [02:07<00:13, 28.1MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.57G/3.93G [02:07<00:12, 28.6MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.57G/3.93G [02:07<00:12, 28.2MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.58G/3.93G [02:07<00:12, 28.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.58G/3.93G [02:07<00:12, 28.0MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.58G/3.93G [02:07<00:12, 28.0MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.58G/3.93G [02:07<00:12, 28.0MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.59G/3.93G [02:07<00:12, 27.7MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.59G/3.93G [02:07<00:12, 27.6MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.59G/3.93G [02:08<00:12, 28.2MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.60G/3.93G [02:08<00:11, 28.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.60G/3.93G [02:08<00:11, 28.1MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.60G/3.93G [02:08<00:11, 27.8MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.60G/3.93G [02:08<00:11, 28.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.61G/3.93G [02:08<00:11, 28.4MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.61G/3.93G [02:08<00:11, 28.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.61G/3.93G [02:08<00:11, 28.0MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.62G/3.93G [02:08<00:11, 27.8MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.62G/3.93G [02:08<00:11, 27.7MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.62G/3.93G [02:09<00:10, 28.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.62G/3.93G [02:09<00:11, 28.1MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.63G/3.93G [02:09<00:11, 27.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.63G/3.93G [02:09<00:10, 28.0MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.63G/3.93G [02:09<00:10, 28.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.64G/3.93G [02:09<00:10, 27.5MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.64G/3.93G [02:09<00:10, 28.0MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.64G/3.93G [02:09<00:10, 28.7MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.65G/3.93G [02:09<00:10, 28.1MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.65G/3.93G [02:09<00:10, 27.5MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.65G/3.93G [02:10<00:10, 27.8MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.65G/3.93G [02:10<00:09, 28.8MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.66G/3.93G [02:10<00:10, 27.6MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.66G/3.93G [02:10<00:09, 28.1MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.66G/3.93G [02:10<00:09, 28.4MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.67G/3.93G [02:10<00:09, 28.0MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.67G/3.93G [02:10<00:09, 27.4MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.67G/3.93G [02:10<00:09, 28.5MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.67G/3.93G [02:10<00:09, 28.6MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.68G/3.93G [02:11<00:09, 27.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.68G/3.93G [02:11<00:08, 28.2MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.68G/3.93G [02:11<00:08, 28.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.69G/3.93G [02:11<00:08, 28.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.69G/3.93G [02:11<00:08, 27.7MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.69G/3.93G [02:11<00:08, 28.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.70G/3.93G [02:11<00:08, 27.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.70G/3.93G [02:11<00:08, 27.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.70G/3.93G [02:11<00:08, 28.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.70G/3.93G [02:11<00:08, 27.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.71G/3.93G [02:12<00:08, 28.2MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.71G/3.93G [02:12<00:07, 28.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.71G/3.93G [02:12<00:07, 28.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.72G/3.93G [02:12<00:08, 27.3MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.72G/3.93G [02:12<00:07, 27.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.72G/3.93G [02:12<00:07, 28.4MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.72G/3.93G [02:12<00:07, 28.1MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.73G/3.93G [02:12<00:07, 28.0MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.73G/3.93G [02:12<00:07, 27.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.73G/3.93G [02:12<00:07, 28.4MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.74G/3.93G [02:13<00:07, 27.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.74G/3.93G [02:13<00:06, 28.5MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.74G/3.93G [02:13<00:06, 27.7MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.74G/3.93G [02:13<00:06, 27.7MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.75G/3.93G [02:13<00:06, 28.4MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.75G/3.93G [02:13<00:06, 27.7MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.75G/3.93G [02:13<00:06, 27.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.76G/3.93G [02:13<00:06, 28.8MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.76G/3.93G [02:13<00:06, 28.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.76G/3.93G [02:14<00:06, 27.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.76G/3.93G [02:14<00:06, 27.6MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.77G/3.93G [02:14<00:05, 28.6MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.77G/3.93G [02:14<00:05, 28.0MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.77G/3.93G [02:14<00:05, 28.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.78G/3.93G [02:14<00:05, 28.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.78G/3.93G [02:14<00:05, 28.4MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.78G/3.93G [02:14<00:05, 28.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.79G/3.93G [02:14<00:05, 28.1MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.79G/3.93G [02:14<00:05, 27.5MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.79G/3.93G [02:15<00:05, 27.5MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.79G/3.93G [02:15<00:04, 28.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.80G/3.93G [02:15<00:05, 27.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.80G/3.93G [02:15<00:04, 27.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.80G/3.93G [02:15<00:05, 25.7MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.81G/3.93G [02:15<00:04, 29.6MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.81G/3.93G [02:15<00:04, 29.3MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.81G/3.93G [02:15<00:04, 28.3MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.82G/3.93G [02:15<00:04, 28.8MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.82G/3.93G [02:16<00:04, 28.6MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.82G/3.93G [02:16<00:03, 28.4MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.82G/3.93G [02:16<00:03, 28.6MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.83G/3.93G [02:16<00:03, 28.2MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.83G/3.93G [02:16<00:03, 27.5MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.83G/3.93G [02:16<00:03, 27.5MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.84G/3.93G [02:16<00:03, 28.6MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.84G/3.93G [02:16<00:03, 27.7MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.84G/3.93G [02:16<00:03, 28.1MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.84G/3.93G [02:16<00:03, 28.9MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.85G/3.93G [02:17<00:03, 28.4MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.85G/3.93G [02:17<00:03, 27.6MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.85G/3.93G [02:17<00:02, 27.6MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.86G/3.93G [02:17<00:02, 28.7MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.86G/3.93G [02:17<00:02, 27.4MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.86G/3.93G [02:17<00:02, 28.1MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.87G/3.93G [02:17<00:02, 28.6MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.87G/3.93G [02:17<00:02, 28.7MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.87G/3.93G [02:17<00:02, 28.4MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.87G/3.93G [02:18<00:02, 27.6MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.88G/3.93G [02:18<00:02, 28.8MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.88G/3.93G [02:18<00:02, 27.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.88G/3.93G [02:18<00:01, 28.2MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.89G/3.93G [02:18<00:01, 28.5MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.89G/3.93G [02:18<00:01, 28.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.89G/3.93G [02:18<00:01, 28.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.89G/3.93G [02:18<00:01, 27.7MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.90G/3.93G [02:18<00:01, 28.8MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.90G/3.93G [02:18<00:01, 27.8MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.90G/3.93G [02:19<00:01, 27.9MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.91G/3.93G [02:19<00:00, 28.3MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.91G/3.93G [02:19<00:00, 28.2MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.91G/3.93G [02:19<00:00, 28.7MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.92G/3.93G [02:19<00:00, 28.2MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.92G/3.93G [02:19<00:00, 28.0MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.92G/3.93G [02:19<00:00, 27.8MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.92G/3.93G [02:19<00:00, 27.9MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.93G/3.93G [02:19<00:00, 27.6MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.93G/3.93G [02:19<00:00, 27.9MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.93G/3.93G [02:20<00:00, 28.4MiB/s]

  0%|          | 0.00/3.74G [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.93G/3.93G [02:21<00:00, 27.9MiB/s]


  0%|          | 80.9k/3.74G [00:00<2:21:44, 440kiB/s][A

  0%|          | 261k/3.74G [00:00<1:22:35, 755kiB/s] [A

  0%|          | 622k/3.74G [00:00<47:46, 1.31MiB/s] [A

  0%|          | 1.34M/3.74G [00:00<26:41, 2.34MiB/s][A

  0%|          | 2.77M/3.74G [00:00<14:32, 4.29MiB/s][A

  0%|          | 5.64M/3.74G [00:01<07:39, 8.12MiB/s][A

  0%|          | 10.9M/3.74G [00:01<04:12, 14.8MiB/s][A

  0%|          | 16.1M/3.74G [00:01<03:15, 19.1MiB/s][A

  1%|          | 21.3M/3.74G [00:01<02:49, 22.0MiB/s][A

  1%|          | 26.5M/3.74G [00:01<02:35, 23.9MiB/s][A

  1%|          | 31.7M/3.74G [00:02<02:26, 25.3MiB/s][A

  1%|          | 36.9M/3.74G [00:02<02:21, 26.1MiB/s][A

  1%|          | 42.2M/3.74G [00:02<02:17, 26.8MiB/s][A

  1%|â–         | 47.4M/3.74G [00:02<02:14, 27.4MiB/s][A

  1%|â–         | 52.6M/3.74G [00:02<02:13, 27.6MiB/s][A

  2%|â–         | 57.8M/3.74G [00:02<02:12, 27.8MiB/s][A

  2%|â–         | 63.0M/3.74G [00:03<02:12, 27.8MiB/s][A

  2%|â–         | 68.1M/3.74G [00:03<02:11, 28.0MiB/s][A

  2%|â–         | 73.4M/3.74G [00:03<02:10, 28.1MiB/s][A

  2%|â–         | 78.6M/3.74G [00:03<02:09, 28.2MiB/s][A

  2%|â–         | 83.8M/3.74G [00:03<02:10, 28.0MiB/s][A

  2%|â–         | 89.0M/3.74G [00:04<02:08, 28.4MiB/s][A

  3%|â–Ž         | 94.3M/3.74G [00:04<02:09, 28.2MiB/s][A

  3%|â–Ž         | 99.5M/3.74G [00:04<02:08, 28.3MiB/s][A

  3%|â–Ž         | 105M/3.74G [00:04<02:08, 28.2MiB/s] [A

  3%|â–Ž         | 110M/3.74G [00:04<02:08, 28.4MiB/s][A

  3%|â–Ž         | 115M/3.74G [00:04<02:08, 28.3MiB/s][A

  3%|â–Ž         | 120M/3.74G [00:05<02:08, 28.2MiB/s][A

  3%|â–Ž         | 125M/3.74G [00:05<02:08, 28.1MiB/s][A

  3%|â–Ž         | 131M/3.74G [00:05<02:08, 28.1MiB/s][A

  4%|â–Ž         | 136M/3.74G [00:05<02:08, 28.0MiB/s][A

  4%|â–         | 141M/3.74G [00:05<02:08, 28.0MiB/s][A

  4%|â–         | 146M/3.74G [00:06<02:08, 28.1MiB/s][A

  4%|â–         | 151M/3.74G [00:06<02:07, 28.1MiB/s][A

  4%|â–         | 156M/3.74G [00:06<02:07, 28.2MiB/s][A

  4%|â–         | 162M/3.74G [00:06<02:07, 28.1MiB/s][A

  4%|â–         | 167M/3.74G [00:06<02:06, 28.2MiB/s][A

  5%|â–         | 172M/3.74G [00:06<02:06, 28.2MiB/s][A

  5%|â–         | 177M/3.74G [00:07<02:06, 28.1MiB/s][A

  5%|â–         | 182M/3.74G [00:07<02:06, 28.1MiB/s][A

  5%|â–Œ         | 187M/3.74G [00:07<02:06, 28.1MiB/s][A

  5%|â–Œ         | 193M/3.74G [00:07<02:06, 28.1MiB/s][A

  5%|â–Œ         | 198M/3.74G [00:07<02:06, 28.1MiB/s][A

  5%|â–Œ         | 203M/3.74G [00:08<02:05, 28.2MiB/s][A

  6%|â–Œ         | 208M/3.74G [00:08<02:05, 28.2MiB/s][A

  6%|â–Œ         | 213M/3.74G [00:08<02:05, 28.1MiB/s][A

  6%|â–Œ         | 218M/3.74G [00:08<02:05, 28.0MiB/s][A

  6%|â–Œ         | 224M/3.74G [00:08<02:05, 28.0MiB/s][A

  6%|â–Œ         | 229M/3.74G [00:09<02:04, 28.1MiB/s][A

  6%|â–‹         | 234M/3.74G [00:09<02:04, 28.1MiB/s][A

  6%|â–‹         | 239M/3.74G [00:09<02:04, 28.1MiB/s][A

  7%|â–‹         | 244M/3.74G [00:09<02:04, 28.1MiB/s][A

  7%|â–‹         | 250M/3.74G [00:09<02:03, 28.2MiB/s][A

  7%|â–‹         | 255M/3.74G [00:09<02:04, 28.1MiB/s][A

  7%|â–‹         | 260M/3.74G [00:10<02:04, 28.0MiB/s][A

  7%|â–‹         | 265M/3.74G [00:10<02:04, 28.0MiB/s][A

  7%|â–‹         | 270M/3.74G [00:10<02:03, 28.1MiB/s][A

  7%|â–‹         | 275M/3.74G [00:10<02:03, 28.1MiB/s][A

  8%|â–Š         | 281M/3.74G [00:10<02:04, 27.7MiB/s][A

  8%|â–Š         | 283M/3.74G [00:11<02:16, 25.4MiB/s][A

  8%|â–Š         | 291M/3.74G [00:11<01:41, 34.0MiB/s][A

  8%|â–Š         | 294M/3.74G [00:11<01:50, 31.3MiB/s][A

  8%|â–Š         | 298M/3.74G [00:11<02:04, 27.7MiB/s][A

  8%|â–Š         | 301M/3.74G [00:11<02:08, 26.9MiB/s][A

  8%|â–Š         | 306M/3.74G [00:11<01:51, 30.9MiB/s][A

  8%|â–Š         | 310M/3.74G [00:11<01:55, 29.6MiB/s][A

  8%|â–Š         | 313M/3.74G [00:11<02:12, 26.0MiB/s][A

  8%|â–Š         | 317M/3.74G [00:12<02:08, 26.6MiB/s][A

  9%|â–Š         | 322M/3.74G [00:12<01:46, 32.1MiB/s][A

  9%|â–Š         | 326M/3.74G [00:12<01:57, 29.2MiB/s][A

  9%|â–‰         | 329M/3.74G [00:12<02:11, 26.0MiB/s][A

  9%|â–‰         | 333M/3.74G [00:12<02:09, 26.4MiB/s][A

  9%|â–‰         | 338M/3.74G [00:12<01:45, 32.1MiB/s][A

  9%|â–‰         | 341M/3.74G [00:12<01:57, 29.0MiB/s][A

  9%|â–‰         | 344M/3.74G [00:13<02:11, 25.9MiB/s][A

  9%|â–‰         | 348M/3.74G [00:13<02:09, 26.2MiB/s][A

  9%|â–‰         | 353M/3.74G [00:13<01:46, 31.7MiB/s][A

 10%|â–‰         | 357M/3.74G [00:13<01:58, 28.7MiB/s][A

 10%|â–‰         | 360M/3.74G [00:13<02:12, 25.6MiB/s][A

 10%|â–‰         | 364M/3.74G [00:13<02:07, 26.5MiB/s][A

 10%|â–‰         | 369M/3.74G [00:13<01:46, 31.7MiB/s][A

 10%|â–‰         | 372M/3.74G [00:14<01:57, 28.6MiB/s][A

 10%|â–ˆ         | 375M/3.74G [00:14<02:11, 25.5MiB/s][A

 10%|â–ˆ         | 379M/3.74G [00:14<02:06, 26.6MiB/s][A

 10%|â–ˆ         | 384M/3.74G [00:14<01:46, 31.5MiB/s][A

 10%|â–ˆ         | 387M/3.74G [00:14<01:57, 28.4MiB/s][A

 10%|â–ˆ         | 390M/3.74G [00:14<02:11, 25.4MiB/s][A

 11%|â–ˆ         | 395M/3.74G [00:14<02:04, 26.8MiB/s][A

 11%|â–ˆ         | 399M/3.74G [00:15<01:45, 31.6MiB/s][A

 11%|â–ˆ         | 403M/3.74G [00:15<01:57, 28.5MiB/s][A

 11%|â–ˆ         | 406M/3.74G [00:15<02:11, 25.4MiB/s][A

 11%|â–ˆ         | 410M/3.74G [00:15<02:03, 27.0MiB/s][A

 11%|â–ˆ         | 415M/3.74G [00:15<01:45, 31.4MiB/s][A

 11%|â–ˆ         | 418M/3.74G [00:15<01:56, 28.4MiB/s][A

 11%|â–ˆâ–        | 421M/3.74G [00:15<02:09, 25.7MiB/s][A

 11%|â–ˆâ–        | 426M/3.74G [00:16<02:02, 27.0MiB/s][A

 12%|â–ˆâ–        | 431M/3.74G [00:16<01:44, 31.7MiB/s][A

 12%|â–ˆâ–        | 434M/3.74G [00:16<01:55, 28.6MiB/s][A

 12%|â–ˆâ–        | 437M/3.74G [00:16<02:09, 25.4MiB/s][A

 12%|â–ˆâ–        | 441M/3.74G [00:16<02:02, 26.9MiB/s][A

 12%|â–ˆâ–        | 446M/3.74G [00:16<01:44, 31.5MiB/s][A

 12%|â–ˆâ–        | 449M/3.74G [00:16<01:55, 28.4MiB/s][A

 12%|â–ˆâ–        | 452M/3.74G [00:16<02:07, 25.9MiB/s][A

 12%|â–ˆâ–        | 457M/3.74G [00:17<02:01, 27.0MiB/s][A

 12%|â–ˆâ–        | 462M/3.74G [00:17<01:43, 31.6MiB/s][A

 12%|â–ˆâ–        | 465M/3.74G [00:17<01:55, 28.5MiB/s][A

 13%|â–ˆâ–Ž        | 468M/3.74G [00:17<02:06, 25.9MiB/s][A

 13%|â–ˆâ–Ž        | 472M/3.74G [00:17<02:00, 27.0MiB/s][A

 13%|â–ˆâ–Ž        | 477M/3.74G [00:17<01:44, 31.3MiB/s][A

 13%|â–ˆâ–Ž        | 480M/3.74G [00:17<01:55, 28.2MiB/s][A

 13%|â–ˆâ–Ž        | 483M/3.74G [00:18<02:06, 25.8MiB/s][A

 13%|â–ˆâ–Ž        | 488M/3.74G [00:18<01:59, 27.2MiB/s][A

 13%|â–ˆâ–Ž        | 493M/3.74G [00:18<01:43, 31.4MiB/s][A

 13%|â–ˆâ–Ž        | 496M/3.74G [00:18<01:55, 28.2MiB/s][A

 13%|â–ˆâ–Ž        | 499M/3.74G [00:18<02:05, 25.8MiB/s][A

 13%|â–ˆâ–Ž        | 504M/3.74G [00:18<01:58, 27.3MiB/s][A

 14%|â–ˆâ–Ž        | 508M/3.74G [00:18<01:42, 31.5MiB/s][A

 14%|â–ˆâ–Ž        | 511M/3.74G [00:19<01:54, 28.2MiB/s][A

 14%|â–ˆâ–Ž        | 514M/3.74G [00:19<02:05, 25.7MiB/s][A

 14%|â–ˆâ–        | 519M/3.74G [00:19<01:57, 27.4MiB/s][A

 14%|â–ˆâ–        | 524M/3.74G [00:19<01:42, 31.5MiB/s][A

 14%|â–ˆâ–        | 527M/3.74G [00:19<01:54, 28.1MiB/s][A

 14%|â–ˆâ–        | 530M/3.74G [00:19<02:05, 25.6MiB/s][A

 14%|â–ˆâ–        | 535M/3.74G [00:19<01:57, 27.3MiB/s][A

 14%|â–ˆâ–        | 539M/3.74G [00:19<01:42, 31.3MiB/s][A

 14%|â–ˆâ–        | 542M/3.74G [00:20<01:54, 27.9MiB/s][A

 15%|â–ˆâ–        | 545M/3.74G [00:20<02:04, 25.6MiB/s][A

 15%|â–ˆâ–        | 550M/3.74G [00:20<01:58, 26.9MiB/s][A

 15%|â–ˆâ–        | 554M/3.74G [00:20<01:56, 27.4MiB/s][A

 15%|â–ˆâ–        | 556M/3.74G [00:20<02:10, 24.4MiB/s][A

 15%|â–ˆâ–        | 561M/3.74G [00:20<01:51, 28.6MiB/s][A

 15%|â–ˆâ–Œ        | 566M/3.74G [00:20<01:47, 29.4MiB/s][A

 15%|â–ˆâ–Œ        | 570M/3.74G [00:21<01:37, 32.5MiB/s][A

 15%|â–ˆâ–Œ        | 574M/3.74G [00:21<01:50, 28.7MiB/s][A

 15%|â–ˆâ–Œ        | 577M/3.74G [00:21<02:01, 26.1MiB/s][A

 16%|â–ˆâ–Œ        | 581M/3.74G [00:21<01:52, 28.1MiB/s][A

 16%|â–ˆâ–Œ        | 585M/3.74G [00:21<01:45, 30.1MiB/s][A

 16%|â–ˆâ–Œ        | 588M/3.74G [00:21<01:57, 26.8MiB/s][A

 16%|â–ˆâ–Œ        | 592M/3.74G [00:21<01:52, 28.1MiB/s][A

 16%|â–ˆâ–Œ        | 596M/3.74G [00:22<01:40, 31.3MiB/s][A

 16%|â–ˆâ–Œ        | 599M/3.74G [00:22<01:54, 27.6MiB/s][A

 16%|â–ˆâ–Œ        | 602M/3.74G [00:22<01:54, 27.3MiB/s][A

 16%|â–ˆâ–Œ        | 606M/3.74G [00:22<01:42, 30.5MiB/s][A

 16%|â–ˆâ–‹        | 609M/3.74G [00:22<01:57, 26.8MiB/s][A

 16%|â–ˆâ–‹        | 612M/3.74G [00:22<01:54, 27.2MiB/s][A

 16%|â–ˆâ–‹        | 616M/3.74G [00:22<01:42, 30.4MiB/s][A

 17%|â–ˆâ–‹        | 620M/3.74G [00:22<01:56, 26.7MiB/s][A

 17%|â–ˆâ–‹        | 623M/3.74G [00:23<01:53, 27.4MiB/s][A

 17%|â–ˆâ–‹        | 627M/3.74G [00:23<01:42, 30.4MiB/s][A

 17%|â–ˆâ–‹        | 630M/3.74G [00:23<01:57, 26.5MiB/s][A

 17%|â–ˆâ–‹        | 633M/3.74G [00:23<01:53, 27.4MiB/s][A

 17%|â–ˆâ–‹        | 637M/3.74G [00:23<01:41, 30.6MiB/s][A

 17%|â–ˆâ–‹        | 640M/3.74G [00:23<01:56, 26.6MiB/s][A

 17%|â–ˆâ–‹        | 643M/3.74G [00:23<01:52, 27.4MiB/s][A

 17%|â–ˆâ–‹        | 647M/3.74G [00:23<01:41, 30.4MiB/s][A

 17%|â–ˆâ–‹        | 651M/3.74G [00:24<01:56, 26.5MiB/s][A

 17%|â–ˆâ–‹        | 654M/3.74G [00:24<01:51, 27.6MiB/s][A

 18%|â–ˆâ–Š        | 658M/3.74G [00:24<01:41, 30.4MiB/s][A

 18%|â–ˆâ–Š        | 661M/3.74G [00:24<01:56, 26.4MiB/s][A

 18%|â–ˆâ–Š        | 664M/3.74G [00:24<01:50, 27.8MiB/s][A

 18%|â–ˆâ–Š        | 668M/3.74G [00:24<01:41, 30.3MiB/s][A

 18%|â–ˆâ–Š        | 671M/3.74G [00:24<01:56, 26.3MiB/s][A

 18%|â–ˆâ–Š        | 675M/3.74G [00:24<01:49, 28.0MiB/s][A

 18%|â–ˆâ–Š        | 678M/3.74G [00:24<01:41, 30.3MiB/s][A

 18%|â–ˆâ–Š        | 682M/3.74G [00:25<01:56, 26.3MiB/s][A

 18%|â–ˆâ–Š        | 685M/3.74G [00:25<01:49, 28.0MiB/s][A

 18%|â–ˆâ–Š        | 689M/3.74G [00:25<01:40, 30.3MiB/s][A

 18%|â–ˆâ–Š        | 692M/3.74G [00:25<01:55, 26.3MiB/s][A

 19%|â–ˆâ–Š        | 695M/3.74G [00:25<01:48, 28.0MiB/s][A

 19%|â–ˆâ–Š        | 699M/3.74G [00:25<01:40, 30.2MiB/s][A

 19%|â–ˆâ–‰        | 702M/3.74G [00:25<01:56, 26.2MiB/s][A

 19%|â–ˆâ–‰        | 706M/3.74G [00:25<01:48, 28.1MiB/s][A

 19%|â–ˆâ–‰        | 709M/3.74G [00:26<01:39, 30.4MiB/s][A

 19%|â–ˆâ–‰        | 713M/3.74G [00:26<01:55, 26.2MiB/s][A

 19%|â–ˆâ–‰        | 716M/3.74G [00:26<01:48, 28.0MiB/s][A

 19%|â–ˆâ–‰        | 720M/3.74G [00:26<01:40, 30.2MiB/s][A

 19%|â–ˆâ–‰        | 723M/3.74G [00:26<01:55, 26.1MiB/s][A

 19%|â–ˆâ–‰        | 727M/3.74G [00:26<01:47, 28.2MiB/s][A

 20%|â–ˆâ–‰        | 730M/3.74G [00:26<01:39, 30.4MiB/s][A

 20%|â–ˆâ–‰        | 733M/3.74G [00:26<01:54, 26.2MiB/s][A

 20%|â–ˆâ–‰        | 737M/3.74G [00:27<01:46, 28.2MiB/s][A

 20%|â–ˆâ–‰        | 740M/3.74G [00:27<01:39, 30.1MiB/s][A

 20%|â–ˆâ–‰        | 744M/3.74G [00:27<01:55, 26.0MiB/s][A

 20%|â–ˆâ–‰        | 747M/3.74G [00:27<01:45, 28.4MiB/s][A

 20%|â–ˆâ–ˆ        | 751M/3.74G [00:27<01:39, 30.2MiB/s][A

 20%|â–ˆâ–ˆ        | 754M/3.74G [00:27<01:54, 26.0MiB/s][A

 20%|â–ˆâ–ˆ        | 758M/3.74G [00:27<01:45, 28.3MiB/s][A

 20%|â–ˆâ–ˆ        | 761M/3.74G [00:27<01:39, 30.0MiB/s][A

 20%|â–ˆâ–ˆ        | 764M/3.74G [00:28<01:54, 25.9MiB/s][A

 21%|â–ˆâ–ˆ        | 768M/3.74G [00:28<01:45, 28.2MiB/s][A

 21%|â–ˆâ–ˆ        | 772M/3.74G [00:28<01:38, 30.2MiB/s][A

 21%|â–ˆâ–ˆ        | 775M/3.74G [00:28<01:53, 26.2MiB/s][A

 21%|â–ˆâ–ˆ        | 778M/3.74G [00:28<01:45, 28.2MiB/s][A

 21%|â–ˆâ–ˆ        | 782M/3.74G [00:28<01:37, 30.2MiB/s][A

 21%|â–ˆâ–ˆ        | 785M/3.74G [00:28<01:53, 26.0MiB/s][A

 21%|â–ˆâ–ˆ        | 789M/3.74G [00:28<01:45, 28.0MiB/s][A

 21%|â–ˆâ–ˆ        | 792M/3.74G [00:29<01:36, 30.4MiB/s][A

 21%|â–ˆâ–ˆâ–       | 795M/3.74G [00:29<01:52, 26.3MiB/s][A

 21%|â–ˆâ–ˆâ–       | 799M/3.74G [00:29<01:45, 27.8MiB/s][A

 21%|â–ˆâ–ˆâ–       | 803M/3.74G [00:29<01:36, 30.5MiB/s][A

 22%|â–ˆâ–ˆâ–       | 806M/3.74G [00:29<01:51, 26.3MiB/s][A

 22%|â–ˆâ–ˆâ–       | 809M/3.74G [00:29<01:45, 27.8MiB/s][A

 22%|â–ˆâ–ˆâ–       | 813M/3.74G [00:29<01:36, 30.2MiB/s][A

 22%|â–ˆâ–ˆâ–       | 816M/3.74G [00:29<01:52, 26.1MiB/s][A

 22%|â–ˆâ–ˆâ–       | 819M/3.74G [00:30<01:45, 27.7MiB/s][A

 22%|â–ˆâ–ˆâ–       | 823M/3.74G [00:30<01:36, 30.3MiB/s][A

 22%|â–ˆâ–ˆâ–       | 826M/3.74G [00:30<01:51, 26.2MiB/s][A

 22%|â–ˆâ–ˆâ–       | 830M/3.74G [00:30<01:45, 27.7MiB/s][A

 22%|â–ˆâ–ˆâ–       | 834M/3.74G [00:30<01:35, 30.4MiB/s][A

 22%|â–ˆâ–ˆâ–       | 837M/3.74G [00:30<01:50, 26.3MiB/s][A

 22%|â–ˆâ–ˆâ–       | 840M/3.74G [00:30<01:44, 27.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 844M/3.74G [00:30<01:35, 30.3MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 847M/3.74G [00:31<01:54, 25.4MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 851M/3.74G [00:31<01:44, 27.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 855M/3.74G [00:31<01:33, 31.0MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 858M/3.74G [00:31<01:45, 27.3MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 861M/3.74G [00:31<01:45, 27.2MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 865M/3.74G [00:31<01:33, 30.7MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 868M/3.74G [00:31<01:46, 27.0MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 871M/3.74G [00:31<01:44, 27.3MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 875M/3.74G [00:31<01:35, 29.9MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 878M/3.74G [00:32<01:45, 27.2MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 881M/3.74G [00:32<01:45, 27.2MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 885M/3.74G [00:32<01:36, 29.6MiB/s][A

 24%|â–ˆâ–ˆâ–Ž       | 888M/3.74G [00:32<01:44, 27.4MiB/s][A

 24%|â–ˆâ–ˆâ–       | 892M/3.74G [00:32<01:44, 27.2MiB/s][A

 24%|â–ˆâ–ˆâ–       | 895M/3.74G [00:32<01:35, 29.8MiB/s][A

 24%|â–ˆâ–ˆâ–       | 899M/3.74G [00:32<01:43, 27.5MiB/s][A

 24%|â–ˆâ–ˆâ–       | 902M/3.74G [00:32<01:41, 28.1MiB/s][A

 24%|â–ˆâ–ˆâ–       | 905M/3.74G [00:33<01:41, 27.9MiB/s][A

 24%|â–ˆâ–ˆâ–       | 908M/3.74G [00:33<01:45, 26.9MiB/s][A

 24%|â–ˆâ–ˆâ–       | 912M/3.74G [00:33<01:30, 31.3MiB/s][A

 24%|â–ˆâ–ˆâ–       | 915M/3.74G [00:33<01:43, 27.3MiB/s][A

 25%|â–ˆâ–ˆâ–       | 918M/3.74G [00:33<01:46, 26.5MiB/s][A

 25%|â–ˆâ–ˆâ–       | 923M/3.74G [00:33<01:30, 31.1MiB/s][A

 25%|â–ˆâ–ˆâ–       | 926M/3.74G [00:33<01:42, 27.5MiB/s][A

 25%|â–ˆâ–ˆâ–       | 929M/3.74G [00:33<01:47, 26.3MiB/s][A

 25%|â–ˆâ–ˆâ–       | 933M/3.74G [00:34<01:38, 28.4MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 936M/3.74G [00:34<01:40, 27.9MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 939M/3.74G [00:34<01:44, 26.9MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 943M/3.74G [00:34<01:29, 31.3MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 947M/3.74G [00:34<01:41, 27.6MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 949M/3.74G [00:34<01:48, 25.8MiB/s][A

 25%|â–ˆâ–ˆâ–Œ       | 954M/3.74G [00:34<01:37, 28.6MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 957M/3.74G [00:34<01:39, 27.9MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 960M/3.74G [00:35<01:43, 27.0MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 964M/3.74G [00:35<01:28, 31.5MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 967M/3.74G [00:35<01:40, 27.7MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 970M/3.74G [00:35<01:43, 26.7MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 975M/3.74G [00:35<01:37, 28.5MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 977M/3.74G [00:35<01:39, 27.9MiB/s][A

 26%|â–ˆâ–ˆâ–Œ       | 980M/3.74G [00:35<01:42, 26.9MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 985M/3.74G [00:35<01:28, 31.2MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 988M/3.74G [00:36<01:40, 27.4MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 991M/3.74G [00:36<01:43, 26.6MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 995M/3.74G [00:36<01:30, 30.3MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 998M/3.74G [00:36<01:40, 27.2MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.00G/3.74G [00:36<01:40, 27.3MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.00G/3.74G [00:36<01:35, 28.7MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:36<01:41, 26.9MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:36<01:34, 28.9MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.01G/3.74G [00:36<01:37, 27.9MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:41, 26.8MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:27, 31.1MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.02G/3.74G [00:37<01:39, 27.4MiB/s][A

 27%|â–ˆâ–ˆâ–‹       | 1.03G/3.74G [00:37<01:42, 26.5MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.03G/3.74G [00:37<01:28, 30.7MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.03G/3.74G [00:37<01:39, 27.3MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.04G/3.74G [00:37<01:42, 26.5MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.04G/3.74G [00:37<01:28, 30.4MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.04G/3.74G [00:38<01:39, 27.1MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:39, 27.1MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:33, 28.9MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.05G/3.74G [00:38<01:38, 27.3MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:38<01:32, 28.9MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:38<01:35, 28.0MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 1.06G/3.74G [00:38<01:40, 26.6MiB/s][A

 29%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:38<01:25, 31.4MiB/s][A

 29%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:38<01:36, 27.8MiB/s][A

 29%|â–ˆâ–ˆâ–Š       | 1.07G/3.74G [00:39<01:41, 26.4MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:32, 28.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:35, 27.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.08G/3.74G [00:39<01:39, 26.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:39<01:26, 30.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:39<01:37, 27.2MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.09G/3.74G [00:39<01:37, 27.2MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:39<01:33, 28.4MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:40<01:38, 26.8MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.10G/3.74G [00:40<01:31, 28.9MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:40<01:34, 27.9MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:40<01:35, 27.4MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.11G/3.74G [00:40<01:32, 28.6MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.12G/3.74G [00:40<01:37, 27.0MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.12G/3.74G [00:40<01:30, 29.0MiB/s][A

 30%|â–ˆâ–ˆâ–‰       | 1.12G/3.74G [00:40<01:33, 27.9MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:40<01:37, 27.0MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:41<01:27, 29.9MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.13G/3.74G [00:41<01:36, 27.0MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:41<01:33, 27.9MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:41<01:31, 28.6MiB/s][A

 30%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:41<01:38, 26.3MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.14G/3.74G [00:41<01:35, 27.3MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:41<01:32, 28.1MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:41<01:29, 29.0MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.15G/3.74G [00:41<01:30, 28.6MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:34, 27.5MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:23, 30.8MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.16G/3.74G [00:42<01:35, 27.1MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 1.17G/3.74G [00:42<01:34, 27.2MiB/s][A

 31%|â–ˆâ–ˆâ–ˆâ–      | 1.17G/3.74G [00:42<01:29, 28.9MiB/s][A

 31%|â–ˆâ–ˆâ–ˆâ–      | 1.17G/3.74G [00:42<01:35, 26.9MiB/s][A

 31%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:42<01:26, 29.5MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:42<01:31, 28.1MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.74G [00:42<01:34, 27.2MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:22, 30.9MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:33, 27.2MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.74G [00:43<01:35, 26.7MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:43<01:28, 28.9MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:43<01:34, 26.9MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.74G [00:43<01:28, 28.6MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:43<01:30, 28.0MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:43<01:32, 27.2MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:43<01:22, 30.6MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 1.21G/3.74G [00:44<01:33, 26.9MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:44<01:32, 27.3MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:44<01:28, 28.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.22G/3.74G [00:44<01:33, 26.8MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:44<01:25, 29.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:44<01:29, 27.9MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.23G/3.74G [00:44<01:31, 27.5MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:44<01:25, 29.2MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:45<01:32, 26.9MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.24G/3.74G [00:45<01:27, 28.6MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.25G/3.74G [00:45<01:29, 27.9MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.25G/3.74G [00:45<01:30, 27.4MiB/s][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.25G/3.74G [00:45<01:25, 29.1MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:45<01:32, 27.0MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:45<01:26, 28.7MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.26G/3.74G [00:45<01:28, 28.0MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.26G/3.74G [00:45<01:29, 27.6MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:45<01:24, 29.1MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:46<01:31, 27.0MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.27G/3.74G [00:46<01:25, 28.9MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:46<01:27, 28.1MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:46<01:29, 27.5MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.28G/3.74G [00:46<01:22, 29.9MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:46<01:33, 26.4MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:46<01:27, 27.9MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.29G/3.74G [00:46<01:25, 28.8MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:30, 27.0MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:22, 29.6MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.30G/3.74G [00:47<01:27, 27.8MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 1.31G/3.74G [00:47<01:29, 27.4MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.31G/3.74G [00:47<01:22, 29.5MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.31G/3.74G [00:47<01:30, 26.9MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:47<01:25, 28.4MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:47<01:26, 28.2MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.32G/3.74G [00:47<01:27, 27.6MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:20, 30.0MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:31, 26.3MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:26, 27.9MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.33G/3.74G [00:48<01:24, 28.5MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.34G/3.74G [00:48<01:28, 27.1MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.34G/3.74G [00:48<01:18, 30.5MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:48<01:25, 28.1MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:48<01:29, 26.8MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.35G/3.74G [00:48<01:19, 30.1MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.36G/3.74G [00:49<01:26, 27.7MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.36G/3.74G [00:49<01:28, 27.0MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.36G/3.74G [00:49<01:16, 31.3MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:49<01:27, 27.3MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:49<01:28, 26.9MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.37G/3.74G [00:49<01:17, 30.6MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:49<01:28, 26.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:49<01:28, 26.8MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.38G/3.74G [00:50<01:20, 29.4MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:50<01:30, 26.2MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:50<01:24, 28.0MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:50<01:23, 28.1MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.39G/3.74G [00:50<01:28, 26.6MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.40G/3.74G [00:50<01:15, 30.9MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.40G/3.74G [00:50<01:24, 27.8MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:50<01:29, 26.2MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:51<01:17, 30.0MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.41G/3.74G [00:51<01:23, 28.0MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:51<01:28, 26.3MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:51<01:17, 30.0MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.42G/3.74G [00:51<01:23, 27.9MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:51<01:28, 26.3MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:51<01:19, 29.0MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.43G/3.74G [00:51<01:28, 26.2MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:24, 27.3MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:23, 27.5MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.44G/3.74G [00:52<01:20, 28.4MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.45G/3.74G [00:52<01:16, 30.1MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.45G/3.74G [00:52<01:20, 28.5MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.45G/3.74G [00:52<01:22, 27.7MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:52<01:14, 30.7MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:52<01:22, 27.6MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.46G/3.74G [00:52<01:22, 27.7MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:52<01:16, 29.7MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:53<01:26, 26.2MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:53<01:20, 28.3MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.47G/3.74G [00:53<01:20, 28.1MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:53<01:23, 27.2MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:53<01:13, 30.6MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.48G/3.74G [00:53<01:22, 27.3MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:53<01:21, 27.6MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:53<01:14, 30.4MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.49G/3.74G [00:54<01:25, 26.4MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:54<01:20, 28.0MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:54<01:19, 28.0MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.50G/3.74G [00:54<01:22, 27.1MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:54<01:14, 29.9MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:54<01:22, 27.2MiB/s][A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.51G/3.74G [00:54<01:20, 27.7MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:54<01:11, 31.3MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:23, 26.5MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.52G/3.74G [00:55<01:21, 27.3MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:55<01:10, 31.2MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:55<01:22, 26.7MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/3.74G [00:55<01:21, 27.1MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.54G/3.74G [00:55<01:10, 31.1MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.54G/3.74G [00:55<01:22, 26.6MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.54G/3.74G [00:55<01:21, 27.1MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.74G [00:55<01:11, 30.8MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.74G [00:56<01:22, 26.4MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:56<01:20, 27.2MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:56<01:11, 30.6MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.74G [00:56<01:23, 26.2MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:56<01:20, 27.0MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:56<01:11, 30.4MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.57G/3.74G [00:56<01:22, 26.3MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:56<01:19, 27.1MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:57<01:14, 28.9MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.58G/3.74G [00:57<01:22, 26.1MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.59G/3.74G [00:57<01:16, 28.2MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.59G/3.74G [00:57<01:19, 27.1MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.59G/3.74G [00:57<01:18, 27.4MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:57<01:08, 31.1MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:57<01:20, 26.6MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:57<01:18, 27.2MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.60G/3.74G [00:57<01:12, 29.5MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:58<01:20, 26.5MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:58<01:16, 28.0MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.61G/3.74G [00:58<01:18, 27.2MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:58<01:16, 27.6MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:58<01:09, 30.6MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.62G/3.74G [00:58<01:20, 26.3MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:58<01:16, 27.7MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:58<01:13, 28.6MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.63G/3.74G [00:59<01:19, 26.7MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.64G/3.74G [00:59<01:13, 28.6MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.74G [00:59<01:18, 26.8MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.64G/3.74G [00:59<01:15, 27.8MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [00:59<01:11, 29.4MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [00:59<01:18, 26.7MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.65G/3.74G [00:59<01:14, 27.9MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [00:59<01:17, 26.9MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [00:59<01:14, 28.0MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.66G/3.74G [01:00<01:08, 30.5MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:00<01:19, 26.2MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:00<01:14, 27.8MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:00<01:12, 28.5MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.67G/3.74G [01:00<01:16, 26.9MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.68G/3.74G [01:00<01:13, 28.2MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.68G/3.74G [01:00<01:16, 26.9MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.68G/3.74G [01:00<01:13, 28.0MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:00<01:11, 28.6MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:01<01:14, 27.5MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.69G/3.74G [01:01<01:10, 29.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:01<01:17, 26.6MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:01<01:13, 27.9MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.70G/3.74G [01:01<01:09, 29.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:01<01:14, 27.2MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:01<01:14, 27.3MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.71G/3.74G [01:01<01:15, 26.8MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:01<01:10, 28.6MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:02<01:11, 28.2MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:02<01:22, 24.5MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.72G/3.74G [01:02<01:09, 28.9MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.73G/3.74G [01:02<01:27, 23.1MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.73G/3.74G [01:02<01:07, 29.8MiB/s][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:02<01:09, 28.8MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:02<01:07, 29.7MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.74G/3.74G [01:02<01:11, 28.0MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:03<01:09, 28.8MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:03<01:05, 30.4MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.75G/3.74G [01:03<01:13, 27.1MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:03<01:10, 28.0MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:03<01:12, 27.4MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.76G/3.74G [01:03<01:10, 27.9MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:03<01:07, 29.1MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:03<01:13, 27.0MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:03<01:10, 27.9MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.77G/3.74G [01:04<01:12, 27.3MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.78G/3.74G [01:04<01:10, 28.0MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.78G/3.74G [01:04<01:05, 30.0MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.78G/3.74G [01:04<01:13, 26.8MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:04<01:09, 28.0MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:04<01:11, 27.1MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.79G/3.74G [01:04<01:09, 28.1MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:04<01:08, 28.6MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:05<01:12, 26.7MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.80G/3.74G [01:05<01:09, 28.0MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:05<01:11, 27.2MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:05<01:09, 27.9MiB/s][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:05<01:04, 29.8MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.81G/3.74G [01:05<01:12, 26.7MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:05<01:08, 28.1MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:05<01:10, 27.1MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.82G/3.74G [01:05<01:09, 27.7MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:05<01:04, 29.5MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:06<01:11, 26.6MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.83G/3.74G [01:06<01:07, 28.3MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:06<01:09, 27.3MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:06<01:08, 27.8MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.84G/3.74G [01:06<01:05, 28.8MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:06<01:10, 26.9MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:06<01:06, 28.4MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:06<01:09, 27.3MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.85G/3.74G [01:06<01:07, 28.1MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:07<01:04, 29.4MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:07<01:11, 26.4MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.86G/3.74G [01:07<01:06, 28.1MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.87G/3.74G [01:07<01:09, 27.2MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.87G/3.74G [01:07<01:06, 28.3MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.87G/3.74G [01:07<01:03, 29.4MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:07<01:09, 26.7MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:07<01:06, 28.1MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.88G/3.74G [01:07<01:08, 27.2MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:08<01:04, 28.6MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:08<01:05, 28.4MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:08<01:06, 28.0MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.89G/3.74G [01:08<01:06, 27.7MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:08<01:09, 26.6MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:08<01:05, 28.2MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.90G/3.74G [01:08<01:07, 27.3MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:08<01:04, 28.6MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:08<01:03, 28.9MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.91G/3.74G [01:09<01:05, 27.7MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.92G/3.74G [01:09<01:05, 27.8MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:09<01:08, 26.7MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:09<01:03, 28.5MiB/s][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.92G/3.74G [01:09<01:06, 27.4MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:09<01:03, 28.6MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:09<01:02, 29.1MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.93G/3.74G [01:09<01:06, 27.0MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:09<01:04, 28.1MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:10<01:07, 26.7MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.94G/3.74G [01:10<01:04, 28.1MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:10<01:04, 27.8MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:10<01:03, 28.4MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:10<01:05, 27.3MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.95G/3.74G [01:10<01:03, 28.0MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:10<01:03, 28.0MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:10<01:05, 27.1MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.96G/3.74G [01:10<01:02, 28.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:10<01:04, 27.6MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:11<01:00, 29.3MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.97G/3.74G [01:11<01:03, 27.9MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:11<01:03, 27.9MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:11<01:03, 27.9MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:11<01:04, 27.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.98G/3.74G [01:11<01:02, 28.3MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:11<01:03, 27.6MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:11<01:00, 29.1MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.99G/3.74G [01:11<01:03, 27.4MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:12<01:02, 28.1MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:12<01:01, 28.2MiB/s][A

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:12<01:03, 27.2MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.00G/3.74G [01:12<01:02, 27.8MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.01G/3.74G [01:12<01:03, 27.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.01G/3.74G [01:12<01:01, 28.2MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.01G/3.74G [01:12<01:03, 27.0MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:12<01:11, 24.3MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:12<00:58, 29.5MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.02G/3.74G [01:13<01:02, 27.4MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:13<01:00, 28.5MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:13<01:00, 28.5MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.03G/3.74G [01:13<01:03, 27.1MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:13<01:00, 28.3MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:13<01:03, 26.8MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.04G/3.74G [01:13<00:59, 28.5MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:13<01:01, 27.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:13<01:01, 27.5MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:14<01:01, 27.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.05G/3.74G [01:14<01:02, 27.2MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.06G/3.74G [01:14<00:59, 28.4MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.06G/3.74G [01:14<01:03, 26.7MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.06G/3.74G [01:14<00:58, 28.5MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:14<01:00, 27.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:14<01:00, 27.6MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:14<01:01, 27.3MiB/s][A

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.07G/3.74G [01:14<01:01, 27.0MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:14<00:58, 28.5MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:15<01:02, 26.6MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.08G/3.74G [01:15<00:59, 27.8MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:15<01:00, 27.4MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:15<00:59, 27.9MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:15<01:00, 27.2MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.09G/3.74G [01:15<01:00, 27.1MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:15<00:57, 28.8MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:15<01:01, 26.7MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.10G/3.74G [01:15<00:58, 28.0MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:16<00:59, 27.5MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:16<00:58, 27.8MiB/s][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.11G/3.74G [01:16<00:59, 27.5MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:16<00:59, 27.5MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:16<00:58, 27.7MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:16<01:00, 26.8MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.12G/3.74G [01:16<00:57, 28.0MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:16<01:00, 26.5MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:16<00:57, 28.2MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.13G/3.74G [01:17<00:57, 27.9MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:17<00:57, 27.9MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:17<00:57, 27.6MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:17<00:58, 27.3MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.14G/3.74G [01:17<00:56, 28.3MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.15G/3.74G [01:17<00:59, 27.0MiB/s][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.15G/3.74G [01:17<00:56, 28.2MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.15G/3.74G [01:17<00:58, 27.0MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:17<00:57, 27.6MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:17<00:57, 27.3MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.16G/3.74G [01:18<00:57, 27.5MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:18<00:56, 27.8MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:18<00:58, 26.7MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:18<00:55, 28.1MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.17G/3.74G [01:18<00:58, 26.9MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:18<00:56, 27.9MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:18<00:56, 27.8MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.18G/3.74G [01:18<00:56, 27.7MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:18<00:56, 27.5MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:19<00:56, 27.3MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:19<00:55, 28.2MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.19G/3.74G [01:19<00:57, 26.7MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.20G/3.74G [01:19<00:54, 28.2MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.20G/3.74G [01:19<00:57, 26.9MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.20G/3.74G [01:19<00:55, 27.8MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:19<01:16, 20.0MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.21G/3.74G [01:19<00:50, 30.5MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:20<00:52, 28.9MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:20<00:53, 28.4MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.22G/3.74G [01:20<00:51, 29.5MiB/s][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:20<00:54, 27.6MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:20<00:53, 28.4MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:20<00:54, 27.6MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.23G/3.74G [01:20<00:55, 27.3MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:20<00:52, 28.6MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:20<00:56, 26.5MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.24G/3.74G [01:21<00:53, 28.1MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:21<00:54, 27.2MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:21<00:53, 28.1MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.25G/3.74G [01:21<00:53, 27.7MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:21<00:54, 27.1MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:21<00:52, 28.3MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.26G/3.74G [01:21<00:55, 26.7MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:21<00:52, 28.2MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:21<00:53, 27.3MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:22<00:53, 27.7MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.27G/3.74G [01:22<00:53, 27.7MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:22<00:54, 26.9MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:22<00:51, 28.6MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.28G/3.74G [01:22<00:54, 26.9MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.29G/3.74G [01:22<00:51, 28.1MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.29G/3.74G [01:22<00:53, 27.0MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.29G/3.74G [01:22<00:52, 27.7MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.29G/3.74G [01:22<00:52, 27.7MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:22<00:53, 27.0MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:23<00:59, 24.3MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.30G/3.74G [01:23<00:51, 28.2MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:23<00:49, 28.8MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:23<00:50, 28.2MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.31G/3.74G [01:23<00:51, 27.6MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:23<00:48, 29.2MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:23<00:51, 27.4MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:23<00:50, 28.2MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.32G/3.74G [01:23<00:51, 27.4MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:24<00:51, 27.5MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:24<00:51, 27.3MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.33G/3.74G [01:24<00:51, 27.2MiB/s][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.34G/3.74G [01:24<00:48, 28.7MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.34G/3.74G [01:24<00:52, 26.5MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.34G/3.74G [01:24<00:50, 27.8MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:24<00:51, 27.0MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:24<00:48, 28.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:24<00:50, 27.5MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.35G/3.74G [01:25<00:51, 26.7MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:25<00:48, 28.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:25<00:51, 27.0MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.36G/3.74G [01:25<00:49, 27.8MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:25<00:50, 27.4MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:25<00:49, 28.0MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:25<00:49, 27.5MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.37G/3.74G [01:25<00:51, 26.8MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:25<00:47, 28.5MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:26<00:50, 27.0MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.38G/3.74G [01:26<00:48, 28.0MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:26<00:50, 26.9MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:26<00:49, 27.4MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.39G/3.74G [01:26<00:46, 28.8MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:26<00:50, 26.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:26<00:47, 28.4MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.40G/3.74G [01:26<00:50, 26.7MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:26<00:49, 27.2MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:27<00:46, 28.8MiB/s][A

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.41G/3.74G [01:27<00:49, 26.7MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:27<00:46, 28.3MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:27<00:49, 26.7MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:27<00:47, 27.6MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.42G/3.74G [01:27<00:45, 28.7MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.74G [01:27<00:49, 26.6MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.43G/3.74G [01:27<00:46, 28.5MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.43G/3.74G [01:27<00:48, 26.8MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:28<00:47, 27.7MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:28<00:46, 28.1MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.44G/3.74G [01:28<00:48, 26.8MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:28<00:46, 27.9MiB/s][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:28<00:48, 26.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:28<00:45, 28.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.45G/3.74G [01:28<00:47, 27.2MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:28<00:46, 27.7MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:28<00:44, 28.5MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.46G/3.74G [01:29<00:47, 26.7MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:29<00:44, 28.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:29<00:48, 26.4MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.47G/3.74G [01:29<00:45, 27.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.48G/3.74G [01:29<00:45, 27.7MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.48G/3.74G [01:29<00:45, 27.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.48G/3.74G [01:29<00:43, 28.8MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.48G/3.74G [01:29<00:47, 26.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:29<00:44, 28.1MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:30<00:46, 26.9MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.49G/3.74G [01:30<00:44, 27.8MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:30<00:44, 28.2MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:30<00:47, 26.3MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.50G/3.74G [01:30<00:43, 28.6MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:30<00:46, 26.4MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:30<00:44, 27.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:30<00:44, 27.8MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.51G/3.74G [01:30<00:44, 27.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:30<00:42, 28.7MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:31<00:46, 26.5MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.52G/3.74G [01:31<00:43, 28.1MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:31<00:45, 26.9MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:31<00:43, 27.7MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.53G/3.74G [01:31<00:43, 27.9MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:31<00:45, 26.4MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:31<00:44, 27.0MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:31<00:44, 27.1MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.54G/3.74G [01:31<00:41, 28.7MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:32<00:44, 27.0MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:32<00:41, 28.4MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.55G/3.74G [01:32<00:41, 28.5MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:32<00:44, 26.6MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:32<00:41, 28.7MiB/s][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.56G/3.74G [01:32<00:44, 26.5MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.57G/3.74G [01:32<00:42, 27.9MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.57G/3.74G [01:32<00:41, 28.0MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.57G/3.74G [01:32<00:42, 27.3MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.57G/3.74G [01:33<00:41, 28.1MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:33<00:43, 26.6MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:33<00:40, 28.5MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.58G/3.74G [01:33<00:43, 26.3MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:33<00:45, 25.4MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:33<00:48, 23.6MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.59G/3.74G [01:33<00:40, 28.6MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:33<00:38, 29.7MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:33<00:39, 29.2MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.60G/3.74G [01:34<00:41, 27.3MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:34<00:38, 29.4MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:34<00:41, 27.0MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.61G/3.74G [01:34<00:40, 28.2MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.62G/3.74G [01:34<00:39, 28.3MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.62G/3.74G [01:34<00:41, 27.0MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.62G/3.74G [01:34<00:38, 29.1MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.62G/3.74G [01:34<00:42, 26.5MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:34<00:39, 28.1MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:35<00:39, 27.8MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.63G/3.74G [01:35<00:41, 26.5MiB/s][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:35<00:38, 28.8MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:35<00:41, 26.4MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.64G/3.74G [01:35<00:38, 28.3MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.65G/3.74G [01:35<00:53, 20.3MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.65G/3.74G [01:35<00:35, 30.6MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:36<00:37, 29.3MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:36<00:39, 27.7MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.66G/3.74G [01:36<00:37, 28.7MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:36<00:38, 27.9MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:36<00:38, 27.7MiB/s][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.67G/3.74G [01:36<00:38, 27.8MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:36<00:39, 27.0MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:36<00:36, 29.2MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.68G/3.74G [01:36<00:39, 26.9MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:37<00:38, 27.6MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:37<00:38, 27.5MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:37<00:38, 27.2MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.69G/3.74G [01:37<00:35, 29.1MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:37<00:39, 26.6MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:37<00:36, 28.4MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.70G/3.74G [01:37<00:38, 27.0MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.71G/3.74G [01:37<00:38, 27.1MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.71G/3.74G [01:37<00:35, 28.7MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.71G/3.74G [01:38<00:38, 26.6MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:38<00:35, 28.5MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:38<00:36, 27.7MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.72G/3.74G [01:38<00:38, 26.8MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:38<00:35, 28.4MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:38<00:38, 26.6MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:38<00:34, 28.9MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.73G/3.74G [01:38<00:36, 27.4MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:38<00:37, 26.6MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:39<00:35, 28.3MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.74G/3.74G [01:39<00:37, 26.7MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:39<00:34, 28.5MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:39<00:36, 27.4MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.75G/3.74G [01:39<00:35, 27.5MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.76G/3.74G [01:39<00:36, 27.0MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.76G/3.74G [01:39<00:36, 26.8MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.76G/3.74G [01:39<00:34, 28.8MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.76G/3.74G [01:39<00:36, 26.9MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:40<00:33, 29.3MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:40<00:36, 26.8MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.77G/3.74G [01:40<00:35, 26.9MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:40<00:34, 28.3MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:40<00:36, 26.6MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.78G/3.74G [01:40<00:33, 28.9MiB/s][A

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:40<00:34, 27.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:40<00:35, 27.2MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:40<00:34, 27.3MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.79G/3.74G [01:41<00:35, 27.0MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:41<00:32, 28.9MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:41<00:35, 26.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.80G/3.74G [01:41<00:32, 28.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:41<00:34, 27.1MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:41<00:33, 27.5MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.81G/3.74G [01:41<00:32, 28.2MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:41<00:35, 26.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:41<00:32, 28.4MiB/s][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.82G/3.74G [01:42<00:33, 27.3MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:42<00:32, 27.8MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:42<00:33, 27.0MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:42<00:33, 27.3MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.83G/3.74G [01:42<00:31, 28.5MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:42<00:34, 26.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:42<00:31, 28.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.84G/3.74G [01:42<00:32, 27.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:42<00:33, 27.1MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:43<00:32, 27.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.85G/3.74G [01:43<00:32, 27.6MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.85G/3.74G [01:43<00:31, 28.5MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:43<00:33, 26.2MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:43<00:31, 28.3MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.86G/3.74G [01:43<00:32, 27.0MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:43<00:32, 27.3MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:43<00:31, 28.0MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.87G/3.74G [01:43<00:36, 23.9MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:44<00:30, 28.1MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:44<00:30, 28.4MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.88G/3.74G [01:44<00:30, 28.6MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:44<00:29, 28.9MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:44<00:32, 26.5MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:44<00:29, 28.6MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.89G/3.74G [01:44<00:31, 27.0MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.90G/3.74G [01:44<00:30, 27.9MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.90G/3.74G [01:44<00:29, 28.3MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.90G/3.74G [01:44<00:30, 27.5MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:45<00:30, 27.7MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:45<00:31, 26.4MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.91G/3.74G [01:45<00:29, 27.9MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:45<00:30, 27.1MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:45<00:29, 27.8MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:45<00:29, 28.1MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.92G/3.74G [01:45<00:29, 27.9MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:45<00:29, 27.4MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:45<00:30, 26.3MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.93G/3.74G [01:46<00:28, 27.9MiB/s][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:46<00:29, 27.0MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:46<00:28, 28.0MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:46<00:28, 28.2MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.94G/3.74G [01:46<00:28, 27.8MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.95G/3.74G [01:46<00:28, 27.5MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.95G/3.74G [01:46<00:28, 27.6MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.95G/3.74G [01:46<00:28, 28.1MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.96G/3.74G [01:46<00:29, 26.7MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.96G/3.74G [01:47<00:28, 27.2MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.96G/3.74G [01:47<00:28, 27.2MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:47<00:28, 27.6MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:47<00:27, 28.2MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:47<00:27, 28.0MiB/s][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.97G/3.74G [01:47<00:27, 27.5MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:47<00:28, 26.8MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:47<00:26, 28.5MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.98G/3.74G [01:47<00:28, 26.6MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:47<00:27, 27.9MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:48<00:26, 28.0MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.99G/3.74G [01:48<00:26, 28.1MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.99G/3.74G [01:48<00:27, 27.3MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:48<00:27, 26.9MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:48<00:26, 28.3MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.00G/3.74G [01:48<00:27, 26.4MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:48<00:26, 27.8MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:48<00:26, 27.9MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.01G/3.74G [01:48<00:25, 28.2MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:49<00:26, 27.3MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:49<00:26, 27.1MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:49<00:25, 28.3MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.02G/3.74G [01:49<00:27, 26.3MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:49<00:25, 27.7MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:49<00:25, 28.1MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.03G/3.74G [01:49<00:24, 28.5MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.04G/3.74G [01:49<00:25, 27.3MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3.04G/3.74G [01:49<00:25, 27.1MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.04G/3.74G [01:50<00:24, 28.1MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.04G/3.74G [01:50<00:26, 26.2MiB/s][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:50<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:50<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.05G/3.74G [01:50<00:24, 28.2MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:50<00:24, 27.4MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:50<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:50<00:24, 27.8MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.06G/3.74G [01:50<00:25, 26.4MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:50<00:24, 27.1MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:51<00:25, 26.7MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.07G/3.74G [01:51<00:23, 28.4MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:51<00:23, 28.2MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:51<00:23, 28.1MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.08G/3.74G [01:51<00:23, 27.7MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.09G/3.74G [01:51<00:24, 27.2MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:51<00:23, 27.9MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:51<00:25, 25.9MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.09G/3.74G [01:51<00:23, 27.8MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:52<00:23, 27.9MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:52<00:22, 28.1MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.10G/3.74G [01:52<00:23, 27.3MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:52<00:22, 28.2MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:52<00:22, 27.9MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:52<00:23, 26.7MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.11G/3.74G [01:52<00:23, 27.1MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:52<00:23, 26.6MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:52<00:21, 28.3MiB/s][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.12G/3.74G [01:52<00:21, 28.2MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:53<00:21, 28.3MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:53<00:22, 27.7MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3.13G/3.74G [01:53<00:22, 27.3MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.13G/3.74G [01:53<00:21, 27.6MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:53<00:28, 21.6MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.14G/3.74G [01:53<00:29, 20.1MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:53<00:18, 32.3MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:53<00:19, 30.0MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.15G/3.74G [01:54<00:20, 29.1MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:54<00:19, 29.3MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:54<00:21, 26.5MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.16G/3.74G [01:54<00:21, 26.6MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:54<00:22, 25.6MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:54<00:19, 30.1MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.17G/3.74G [01:54<00:18, 30.0MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.18G/3.74G [01:54<00:19, 28.8MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3.18G/3.74G [01:54<00:20, 27.7MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.18G/3.74G [01:55<00:20, 27.4MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.18G/3.74G [01:55<00:20, 27.0MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:55<00:19, 28.3MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:55<00:20, 27.0MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.19G/3.74G [01:55<00:19, 28.5MiB/s][A

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:55<00:19, 27.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:55<00:19, 27.8MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:55<00:20, 26.8MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.20G/3.74G [01:55<00:19, 26.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:56<00:19, 27.2MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:56<00:19, 27.5MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.21G/3.74G [01:56<00:19, 27.7MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:56<00:19, 27.0MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:56<00:18, 28.6MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.22G/3.74G [01:56<00:18, 27.8MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.23G/3.74G [01:56<00:18, 28.0MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.23G/3.74G [01:56<00:19, 26.9MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.23G/3.74G [01:56<00:18, 27.2MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.23G/3.74G [01:56<00:18, 27.4MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:57<00:18, 27.3MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:57<00:17, 27.9MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.24G/3.74G [01:57<00:18, 27.2MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:57<00:17, 28.8MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:57<00:17, 27.8MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:57<00:17, 27.7MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.25G/3.74G [01:57<00:18, 27.1MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:57<00:17, 27.0MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:57<00:17, 27.7MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.26G/3.74G [01:58<00:17, 27.6MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:58<00:16, 28.1MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:58<00:17, 27.3MiB/s][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.27G/3.74G [01:58<00:16, 28.0MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.27G/3.74G [01:58<00:17, 27.5MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:58<00:16, 27.7MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:58<00:17, 26.6MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.28G/3.74G [01:58<00:16, 27.2MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [01:58<00:16, 27.7MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [01:58<00:16, 27.8MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [01:59<00:16, 27.9MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.29G/3.74G [01:59<00:16, 27.3MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [01:59<00:15, 27.9MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [01:59<00:16, 27.3MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.30G/3.74G [01:59<00:15, 27.7MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [01:59<00:16, 26.6MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [01:59<00:15, 27.3MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [01:59<00:15, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.31G/3.74G [01:59<00:15, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.32G/3.74G [02:00<00:15, 27.9MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.32G/3.74G [02:00<00:15, 27.2MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.32G/3.74G [02:00<00:14, 28.0MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:00<00:15, 27.4MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:00<00:14, 28.0MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:00<00:15, 26.9MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.33G/3.74G [02:00<00:14, 27.4MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:00<00:14, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:00<00:14, 27.6MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.34G/3.74G [02:00<00:14, 27.7MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:01<00:14, 27.2MiB/s][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:01<00:13, 28.4MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:01<00:14, 27.1MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.35G/3.74G [02:01<00:14, 27.2MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:01<00:14, 27.1MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:01<00:13, 27.3MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.36G/3.74G [02:01<00:13, 27.6MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.37G/3.74G [02:01<00:13, 27.7MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.37G/3.74G [02:01<00:13, 27.9MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.37G/3.74G [02:01<00:13, 27.2MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.37G/3.74G [02:02<00:12, 28.5MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:02<00:13, 27.2MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:02<00:13, 27.5MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.38G/3.74G [02:02<00:13, 27.1MiB/s][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:02<00:13, 27.3MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:02<00:12, 27.9MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.39G/3.74G [02:02<00:12, 27.1MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:02<00:11, 29.1MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:02<00:12, 27.2MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:03<00:12, 27.3MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.40G/3.74G [02:03<00:12, 26.9MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:03<00:12, 27.6MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:03<00:12, 27.5MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.41G/3.74G [02:03<00:12, 27.0MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:03<00:11, 28.6MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:03<00:11, 27.4MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:03<00:11, 27.9MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.42G/3.74G [02:03<00:11, 26.6MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:04<00:11, 27.5MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:04<00:11, 27.4MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.43G/3.74G [02:04<00:11, 27.7MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:04<00:10, 27.9MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:04<00:11, 27.2MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:04<00:10, 29.2MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.44G/3.74G [02:04<00:10, 27.0MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:04<00:10, 27.3MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:04<00:10, 26.7MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.45G/3.74G [02:04<00:10, 27.7MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.46G/3.74G [02:05<00:10, 28.1MiB/s][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.46G/3.74G [02:05<00:10, 26.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.46G/3.74G [02:05<00:09, 28.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:05<00:10, 26.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:05<00:09, 27.7MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:05<00:09, 27.8MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.47G/3.74G [02:05<00:09, 26.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:05<00:09, 29.0MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:05<00:09, 27.4MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.48G/3.74G [02:06<00:09, 27.3MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:06<00:09, 26.8MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:06<00:09, 27.6MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.49G/3.74G [02:06<00:09, 27.6MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:06<00:09, 26.8MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:06<00:08, 28.6MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:06<00:08, 27.2MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.50G/3.74G [02:06<00:08, 28.4MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.51G/3.74G [02:06<00:08, 26.2MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.51G/3.74G [02:07<00:08, 27.5MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.51G/3.74G [02:07<00:08, 28.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:07<00:08, 26.4MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:07<00:07, 28.7MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.52G/3.74G [02:07<00:08, 26.6MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:07<00:07, 27.6MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:07<00:07, 28.0MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.53G/3.74G [02:07<00:07, 26.3MiB/s][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:07<00:07, 28.7MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:08<00:07, 27.2MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:08<00:07, 27.7MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.54G/3.74G [02:08<00:07, 27.7MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:08<00:07, 26.4MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:08<00:06, 29.5MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.55G/3.74G [02:08<00:07, 26.8MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:08<00:06, 27.9MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:08<00:06, 27.5MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.56G/3.74G [02:08<00:06, 26.3MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:09<00:05, 29.3MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:09<00:06, 27.4MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:09<00:06, 27.5MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.57G/3.74G [02:09<00:06, 26.7MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:09<00:06, 26.5MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:09<00:05, 28.3MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.58G/3.74G [02:09<00:05, 27.1MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:09<00:05, 28.4MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:09<00:05, 27.5MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.59G/3.74G [02:10<00:05, 27.7MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.60G/3.74G [02:10<00:05, 27.3MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.60G/3.74G [02:10<00:05, 26.7MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.60G/3.74G [02:10<00:04, 28.1MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.60G/3.74G [02:10<00:05, 26.8MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:10<00:04, 28.6MiB/s][A

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:10<00:04, 27.7MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.61G/3.74G [02:10<00:04, 27.8MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:10<00:04, 27.4MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:10<00:04, 26.7MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:11<00:04, 28.2MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.62G/3.74G [02:11<00:04, 26.8MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:11<00:03, 28.6MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:11<00:03, 27.7MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.63G/3.74G [02:11<00:03, 27.6MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:11<00:03, 27.3MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:11<00:03, 27.5MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.64G/3.74G [02:11<00:03, 28.2MiB/s][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.65G/3.74G [02:11<00:03, 26.0MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:12<00:03, 28.4MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:12<00:03, 27.5MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.65G/3.74G [02:12<00:03, 27.7MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:12<00:03, 27.3MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:12<00:03, 26.7MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.66G/3.74G [02:12<00:02, 28.0MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:12<00:02, 26.6MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:12<00:02, 27.8MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.67G/3.74G [02:12<00:02, 27.8MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:13<00:02, 27.8MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:13<00:02, 27.7MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:13<00:02, 27.7MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.68G/3.74G [02:13<00:02, 28.0MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.69G/3.74G [02:13<00:02, 26.0MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.69G/3.74G [02:13<00:01, 28.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.69G/3.74G [02:13<00:01, 27.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:13<00:01, 27.8MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:13<00:01, 27.4MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:13<00:01, 27.0MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.70G/3.74G [02:14<00:01, 28.3MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:14<00:01, 26.7MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:14<00:01, 27.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.71G/3.74G [02:14<00:01, 27.6MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:14<00:00, 27.7MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:14<00:00, 27.5MiB/s][A

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.72G/3.74G [02:14<00:00, 27.9MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:14<00:00, 27.8MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:14<00:00, 26.9MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:15<00:00, 25.5MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.73G/3.74G [02:15<00:00, 28.0MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.74G/3.74G [02:15<00:00, 28.0MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.74G/3.74G [02:15<00:00, 27.9MiB/s][A
  0%|          | 0.00/29.0 [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.74G/3.74G [02:15<00:00, 27.5MiB/s]


  0%|          | 0.00/6.11k [00:00<?, ?iB/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 9.00/29.0 [00:00<00:01, 10.8iB/s]

  0%|          | 0.00/1.14G [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.11k/6.11k [00:00<00:00, 7.42kiB/s]

  0%|          | 2.19M/1.14G [00:00<00:54, 20.8MiB/s]
  0%|          | 4.34M/1.14G [00:00<00:54, 21.0MiB/s]
  1%|          | 7.69M/1.14G [00:00<00:54, 20.5MiB/s]
  1%|          | 12.8M/1.14G [00:00<00:47, 23.7MiB/s]
  2%|â–         | 18.0M/1.14G [00:00<00:44, 25.4MiB/s]
  2%|â–         | 23.2M/1.14G [00:00<00:42, 26.3MiB/s]
  3%|â–Ž         | 28.4M/1.14G [00:01<00:41, 26.9MiB/s]
  3%|â–Ž         | 33.6M/1.14G [00:01<00:40, 27.1MiB/s]
  3%|â–Ž         | 38.7M/1.14G [00:01<00:40, 27.3MiB/s]
  4%|â–         | 44.0M/1.14G [00:01<00:39, 27.5MiB/s]
  4%|â–         | 49.2M/1.14G [00:01<00:39, 27.6MiB/s]
  5%|â–         | 54.4M/1.14G [00:02<00:39, 27.6MiB/s]
  5%|â–Œ         | 59.6M/1.14G [00:02<00:38, 27.8MiB/s]
  6%|â–Œ         | 64.8M/1.14G [00:02<00:38, 27.8MiB/s]
  6%|â–Œ         | 70.0M/1.14G [00:02<00:38, 27.8MiB/s]
  7%|â–‹         | 75.2M/1.14G [00:02<00:38, 27.9MiB/s]
  7%|â–‹         | 80.4M/1.14G [00:02<00:38, 27.7MiB/s]
  8%|â–Š         | 85.6M/1.14G [00:03<00:37, 27.9MiB/s]
  8%|â–Š         | 90.8M/1.14G [00:03<00:37, 27.8MiB/s]
  8%|â–Š         | 96.0M/1.14G [00:03<00:37, 27.9MiB/s]
  9%|â–‰         | 101M/1.14G [00:03<00:37, 27.7MiB/s] 
  9%|â–‰         | 106M/1.14G [00:03<00:36, 27.9MiB/s]
 10%|â–‰         | 112M/1.14G [00:04<00:37, 27.4MiB/s]
 10%|â–ˆ         | 117M/1.14G [00:04<00:36, 28.1MiB/s]
 11%|â–ˆ         | 122M/1.14G [00:04<00:36, 28.0MiB/s]
 11%|â–ˆ         | 127M/1.14G [00:04<00:36, 27.9MiB/s]
 12%|â–ˆâ–        | 132M/1.14G [00:04<00:35, 28.0MiB/s]
 12%|â–ˆâ–        | 138M/1.14G [00:05<00:35, 28.0MiB/s]
 13%|â–ˆâ–Ž        | 143M/1.14G [00:05<00:35, 28.0MiB/s]
 13%|â–ˆâ–Ž        | 148M/1.14G [00:05<00:35, 27.8MiB/s]
 13%|â–ˆâ–Ž        | 153M/1.14G [00:05<00:35, 28.0MiB/s]
 14%|â–ˆâ–        | 158M/1.14G [00:05<00:35, 27.8MiB/s]
 14%|â–ˆâ–        | 164M/1.14G [00:05<00:34, 27.9MiB/s]
 15%|â–ˆâ–        | 169M/1.14G [00:06<00:34, 27.8MiB/s]
 15%|â–ˆâ–Œ        | 174M/1.14G [00:06<00:34, 27.8MiB/s]
 16%|â–ˆâ–Œ        | 179M/1.14G [00:06<00:34, 27.8MiB/s]
 16%|â–ˆâ–Œ        | 184M/1.14G [00:06<00:29, 32.3MiB/s]
 17%|â–ˆâ–‹        | 188M/1.14G [00:06<00:32, 28.9MiB/s]
 17%|â–ˆâ–‹        | 191M/1.14G [00:06<00:35, 26.8MiB/s]
 17%|â–ˆâ–‹        | 195M/1.14G [00:07<00:35, 26.6MiB/s]
 18%|â–ˆâ–Š        | 200M/1.14G [00:07<00:34, 27.0MiB/s]
 18%|â–ˆâ–Š        | 205M/1.14G [00:07<00:34, 27.3MiB/s]
 19%|â–ˆâ–Š        | 211M/1.14G [00:07<00:33, 27.3MiB/s]
 19%|â–ˆâ–‰        | 216M/1.14G [00:07<00:33, 27.7MiB/s]
 19%|â–ˆâ–‰        | 221M/1.14G [00:08<00:32, 27.8MiB/s]
 20%|â–ˆâ–‰        | 226M/1.14G [00:08<00:32, 27.8MiB/s]
 20%|â–ˆâ–ˆ        | 231M/1.14G [00:08<00:32, 27.8MiB/s]
 21%|â–ˆâ–ˆ        | 237M/1.14G [00:08<00:32, 27.8MiB/s]
 21%|â–ˆâ–ˆâ–       | 242M/1.14G [00:08<00:32, 27.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 247M/1.14G [00:08<00:27, 32.3MiB/s]
 22%|â–ˆâ–ˆâ–       | 251M/1.14G [00:09<00:31, 28.5MiB/s]
 22%|â–ˆâ–ˆâ–       | 254M/1.14G [00:09<00:33, 26.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 257M/1.14G [00:09<00:32, 26.8MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 263M/1.14G [00:09<00:27, 32.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 266M/1.14G [00:09<00:31, 27.9MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 269M/1.14G [00:09<00:33, 25.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 273M/1.14G [00:09<00:32, 26.3MiB/s]
 24%|â–ˆâ–ˆâ–       | 278M/1.14G [00:09<00:26, 32.0MiB/s]
 25%|â–ˆâ–ˆâ–       | 282M/1.14G [00:10<00:31, 27.0MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 285M/1.14G [00:10<00:34, 25.0MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 288M/1.14G [00:10<00:31, 26.6MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 293M/1.14G [00:10<00:26, 32.0MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 297M/1.14G [00:10<00:30, 27.7MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 300M/1.14G [00:10<00:32, 25.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 304M/1.14G [00:11<00:31, 26.6MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 309M/1.14G [00:11<00:26, 31.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 312M/1.14G [00:11<00:30, 27.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 315M/1.14G [00:11<00:32, 25.4MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 319M/1.14G [00:11<00:30, 26.4MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 324M/1.14G [00:11<00:25, 31.7MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 328M/1.14G [00:11<00:29, 27.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 331M/1.14G [00:11<00:31, 25.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 335M/1.14G [00:12<00:30, 26.5MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 340M/1.14G [00:12<00:25, 31.4MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 343M/1.14G [00:12<00:29, 27.3MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 346M/1.14G [00:12<00:30, 25.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 351M/1.14G [00:12<00:29, 26.6MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 355M/1.14G [00:12<00:24, 31.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 359M/1.14G [00:12<00:28, 27.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 362M/1.14G [00:13<00:29, 26.0MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 366M/1.14G [00:13<00:28, 26.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 371M/1.14G [00:13<00:24, 31.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 374M/1.14G [00:13<00:28, 27.2MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 377M/1.14G [00:13<00:29, 25.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 382M/1.14G [00:13<00:28, 26.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 386M/1.14G [00:13<00:24, 31.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 390M/1.14G [00:14<00:27, 27.2MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 393M/1.14G [00:14<00:28, 26.0MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 397M/1.14G [00:14<00:27, 26.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 402M/1.14G [00:14<00:24, 30.6MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 405M/1.14G [00:14<00:27, 27.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 408M/1.14G [00:14<00:27, 26.4MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 412M/1.14G [00:14<00:23, 30.8MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 415M/1.14G [00:15<00:26, 26.7MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 418M/1.14G [00:15<00:27, 25.9MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 423M/1.14G [00:15<00:26, 26.7MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 427M/1.14G [00:15<00:23, 30.5MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 431M/1.14G [00:15<00:26, 27.1MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 434M/1.14G [00:15<00:26, 26.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 438M/1.14G [00:15<00:22, 30.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 441M/1.14G [00:15<00:26, 26.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 444M/1.14G [00:16<00:26, 25.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 449M/1.14G [00:16<00:23, 29.0MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 452M/1.14G [00:16<00:24, 27.7MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 455M/1.14G [00:16<00:26, 26.1MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 459M/1.14G [00:16<00:23, 29.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 462M/1.14G [00:16<00:24, 27.6MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 465M/1.14G [00:16<00:25, 26.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 470M/1.14G [00:16<00:22, 29.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 473M/1.14G [00:17<00:23, 27.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 475M/1.14G [00:17<00:25, 26.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 480M/1.14G [00:17<00:22, 29.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 483M/1.14G [00:17<00:23, 27.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 486M/1.14G [00:17<00:24, 26.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 490M/1.14G [00:17<00:22, 29.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 493M/1.14G [00:17<00:23, 27.6MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 496M/1.14G [00:17<00:24, 26.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 501M/1.14G [00:18<00:21, 29.2MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 504M/1.14G [00:18<00:22, 27.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 506M/1.14G [00:18<00:23, 26.4MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 511M/1.14G [00:18<00:21, 29.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 514M/1.14G [00:18<00:22, 27.4MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 517M/1.14G [00:18<00:23, 26.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 521M/1.14G [00:18<00:21, 29.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 524M/1.14G [00:18<00:22, 27.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 527M/1.14G [00:19<00:22, 26.5MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 532M/1.14G [00:19<00:20, 29.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 535M/1.14G [00:19<00:21, 27.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 537M/1.14G [00:19<00:22, 26.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 542M/1.14G [00:19<00:20, 29.4MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 545M/1.14G [00:19<00:21, 27.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 548M/1.14G [00:19<00:22, 26.4MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 553M/1.14G [00:19<00:20, 29.1MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 555M/1.14G [00:20<00:21, 27.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 558M/1.14G [00:20<00:21, 26.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 563M/1.14G [00:20<00:17, 31.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 566M/1.14G [00:20<00:21, 26.6MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 569M/1.14G [00:20<00:21, 26.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 572M/1.14G [00:20<00:19, 28.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 575M/1.14G [00:20<00:20, 26.8MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 579M/1.14G [00:20<00:20, 27.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 582M/1.14G [00:21<00:19, 28.6MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 585M/1.14G [00:21<00:21, 25.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 589M/1.14G [00:21<00:18, 29.6MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 592M/1.14G [00:21<00:19, 27.8MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 595M/1.14G [00:21<00:20, 26.5MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 599M/1.14G [00:21<00:18, 29.0MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 602M/1.14G [00:21<00:19, 27.2MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 605M/1.14G [00:21<00:19, 27.2MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 609M/1.14G [00:21<00:17, 30.7MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 612M/1.14G [00:22<00:19, 26.6MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 615M/1.14G [00:22<00:19, 26.7MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 618M/1.14G [00:22<00:18, 28.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 621M/1.14G [00:22<00:19, 26.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 625M/1.14G [00:22<00:17, 28.8MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 628M/1.14G [00:22<00:18, 27.0MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 631M/1.14G [00:22<00:18, 27.1MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 635M/1.14G [00:22<00:16, 30.6MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 638M/1.14G [00:23<00:18, 26.6MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 641M/1.14G [00:23<00:18, 26.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 644M/1.14G [00:23<00:17, 28.2MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 647M/1.14G [00:23<00:17, 27.3MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 651M/1.14G [00:23<00:16, 28.6MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 654M/1.14G [00:23<00:17, 27.2MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 656M/1.14G [00:23<00:17, 27.2MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 659M/1.14G [00:23<00:16, 28.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 662M/1.14G [00:23<00:17, 27.3MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 666M/1.14G [00:24<00:16, 28.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 669M/1.14G [00:24<00:17, 27.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 672M/1.14G [00:24<00:17, 27.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 675M/1.14G [00:24<00:16, 27.9MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 678M/1.14G [00:24<00:16, 27.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 682M/1.14G [00:24<00:15, 28.7MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 685M/1.14G [00:24<00:16, 27.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 687M/1.14G [00:24<00:16, 27.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 690M/1.14G [00:24<00:16, 27.4MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 693M/1.14G [00:25<00:15, 28.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 696M/1.14G [00:25<00:15, 28.1MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 699M/1.14G [00:25<00:16, 27.3MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 702M/1.14G [00:25<00:14, 29.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 705M/1.14G [00:25<00:16, 26.9MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 708M/1.14G [00:25<00:15, 27.1MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 711M/1.14G [00:25<00:15, 27.7MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 714M/1.14G [00:25<00:15, 27.6MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 717M/1.14G [00:25<00:14, 29.7MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 720M/1.14G [00:26<00:15, 26.7MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 723M/1.14G [00:26<00:15, 27.3MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 726M/1.14G [00:26<00:14, 27.7MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 729M/1.14G [00:26<00:14, 27.7MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 732M/1.14G [00:26<00:14, 28.0MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 735M/1.14G [00:26<00:14, 27.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 739M/1.14G [00:26<00:13, 29.3MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 742M/1.14G [00:26<00:14, 27.0MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 744M/1.14G [00:26<00:14, 27.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 747M/1.14G [00:27<00:14, 27.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 750M/1.14G [00:27<00:14, 27.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 754M/1.14G [00:27<00:12, 29.5MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 757M/1.14G [00:27<00:14, 26.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 760M/1.14G [00:27<00:13, 26.9MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 763M/1.14G [00:27<00:13, 27.8MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 765M/1.14G [00:27<00:13, 27.8MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 768M/1.14G [00:27<00:13, 27.9MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 771M/1.14G [00:27<00:13, 27.8MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 775M/1.14G [00:27<00:11, 30.3MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 778M/1.14G [00:28<00:13, 26.5MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 780M/1.14G [00:28<00:13, 26.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 784M/1.14G [00:28<00:12, 27.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 786M/1.14G [00:28<00:12, 27.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 790M/1.14G [00:28<00:11, 29.4MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 793M/1.14G [00:28<00:12, 27.1MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 796M/1.14G [00:28<00:12, 27.4MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 799M/1.14G [00:28<00:12, 27.4MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 802M/1.14G [00:28<00:12, 27.6MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 805M/1.14G [00:29<00:12, 27.6MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 807M/1.14G [00:29<00:12, 27.3MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 811M/1.14G [00:29<00:11, 29.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 814M/1.14G [00:29<00:12, 26.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 817M/1.14G [00:29<00:11, 27.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 820M/1.14G [00:29<00:11, 27.6MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 823M/1.14G [00:29<00:11, 27.4MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 827M/1.14G [00:29<00:10, 29.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 830M/1.14G [00:29<00:11, 26.6MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 833M/1.14G [00:30<00:10, 27.7MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 836M/1.14G [00:30<00:10, 27.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 838M/1.14G [00:30<00:10, 27.1MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 842M/1.14G [00:30<00:09, 29.6MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 845M/1.14G [00:30<00:10, 26.8MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 848M/1.14G [00:30<00:10, 27.5MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 851M/1.14G [00:30<00:10, 27.6MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 854M/1.14G [00:30<00:10, 27.6MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 857M/1.14G [00:30<00:10, 27.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 859M/1.14G [00:31<00:10, 26.9MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 863M/1.14G [00:31<00:09, 29.6MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 866M/1.14G [00:31<00:09, 27.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 869M/1.14G [00:31<00:09, 27.7MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 872M/1.14G [00:31<00:09, 27.6MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 875M/1.14G [00:31<00:09, 27.1MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 878M/1.14G [00:31<00:08, 29.4MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 881M/1.14G [00:31<00:09, 26.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 884M/1.14G [00:31<00:09, 27.6MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 887M/1.14G [00:32<00:09, 27.5MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 890M/1.14G [00:32<00:08, 27.6MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 893M/1.14G [00:32<00:08, 29.0MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 896M/1.14G [00:32<00:08, 27.4MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 899M/1.14G [00:32<00:08, 27.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 902M/1.14G [00:32<00:08, 27.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 905M/1.14G [00:32<00:08, 27.1MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 908M/1.14G [00:32<00:08, 27.7MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 911M/1.14G [00:32<00:08, 27.9MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 914M/1.14G [00:33<00:07, 29.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 917M/1.14G [00:33<00:08, 27.4MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 920M/1.14G [00:33<00:07, 27.3MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 923M/1.14G [00:33<00:07, 27.2MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 926M/1.14G [00:33<00:07, 26.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 929M/1.14G [00:33<00:07, 28.7MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 932M/1.14G [00:33<00:07, 28.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 935M/1.14G [00:33<00:06, 29.6MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 938M/1.14G [00:33<00:07, 26.8MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 941M/1.14G [00:34<00:07, 26.9MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 944M/1.14G [00:34<00:07, 27.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 947M/1.14G [00:34<00:06, 27.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 950M/1.14G [00:34<00:06, 28.7MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 953M/1.14G [00:34<00:06, 27.9MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 956M/1.14G [00:34<00:06, 28.9MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 959M/1.14G [00:34<00:06, 26.8MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 962M/1.14G [00:34<00:06, 26.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 965M/1.14G [00:34<00:06, 27.2MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 968M/1.14G [00:34<00:06, 27.8MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 971M/1.14G [00:35<00:05, 28.8MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 974M/1.14G [00:35<00:05, 27.9MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 977M/1.14G [00:35<00:05, 29.1MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 980M/1.14G [00:35<00:05, 27.1MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 983M/1.14G [00:35<00:05, 26.6MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 985M/1.14G [00:35<00:05, 27.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 988M/1.14G [00:35<00:05, 27.6MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 991M/1.14G [00:35<00:05, 28.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 994M/1.14G [00:35<00:05, 27.7MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 997M/1.14G [00:36<00:04, 29.1MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.00G/1.14G [00:36<00:05, 26.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.00G/1.14G [00:36<00:05, 26.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.01G/1.14G [00:36<00:04, 27.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.01G/1.14G [00:36<00:04, 27.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.01G/1.14G [00:36<00:04, 28.5MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.01G/1.14G [00:36<00:04, 27.6MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.02G/1.14G [00:36<00:04, 29.3MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.02G/1.14G [00:36<00:04, 23.2MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.03G/1.14G [00:37<00:04, 27.3MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.03G/1.14G [00:37<00:03, 27.6MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.03G/1.14G [00:37<00:04, 24.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.04G/1.14G [00:37<00:03, 29.2MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.04G/1.14G [00:37<00:03, 28.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.04G/1.14G [00:37<00:03, 25.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.05G/1.14G [00:37<00:03, 29.4MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.05G/1.14G [00:37<00:03, 28.3MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.05G/1.14G [00:38<00:03, 25.3MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:02, 29.4MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:02, 29.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.06G/1.14G [00:38<00:02, 25.3MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 29.5MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 28.5MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.07G/1.14G [00:38<00:02, 25.4MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.08G/1.14G [00:38<00:01, 29.6MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.08G/1.14G [00:39<00:01, 29.1MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.08G/1.14G [00:39<00:02, 25.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.09G/1.14G [00:39<00:01, 29.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.09G/1.14G [00:39<00:01, 28.9MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.09G/1.14G [00:39<00:01, 25.2MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:39<00:01, 29.3MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:39<00:01, 29.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.10G/1.14G [00:39<00:01, 25.3MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.11G/1.14G [00:40<00:00, 29.2MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.11G/1.14G [00:40<00:00, 28.8MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.11G/1.14G [00:40<00:00, 25.2MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.12G/1.14G [00:40<00:00, 29.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.12G/1.14G [00:40<00:00, 28.7MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 25.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 29.4MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.13G/1.14G [00:40<00:00, 28.9MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.14G/1.14G [00:41<00:00, 25.3MiB/s]

  0%|          | 0.00/104M [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.14G/1.14G [00:41<00:00, 27.1MiB/s]


  8%|â–Š         | 8.52M/104M [00:00<00:01, 80.3MiB/s][A

 21%|â–ˆâ–ˆ        | 21.4M/104M [00:00<00:00, 108MiB/s] [A

 32%|â–ˆâ–ˆâ–ˆâ–      | 33.2M/104M [00:00<00:00, 112MiB/s][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44.9M/104M [00:00<00:00, 114MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56.6M/104M [00:00<00:00, 115MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68.4M/104M [00:00<00:00, 116MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 80.1M/104M [00:00<00:00, 116MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91.9M/104M [00:00<00:00, 117MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104M/104M [00:00<00:00, 117MiB/s] [A/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > Model's license - MIT
 > Check https://choosealicense.com/licenses/mit/ for more info.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104M/104M [00:04<00:00, 22.8MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", config_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", config_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 65, in __init__
    self.config = load_config(config_path) if config_path else None
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 94, in load_config
    raise TypeError(f" [!] Unknown config file type {ext}")
TypeError:  [!] Unknown config file type 
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", config_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 65, in __init__
    self.config = load_config(config_path) if config_path else None
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 94, in load_config
    raise TypeError(f" [!] Unknown config file type {ext}")
TypeError:  [!] Unknown config file type 
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark",  gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 88, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--bark/config.json'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark",  gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 88, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--bark/config.json'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark",  gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 88, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--bark/config.json'
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", model_path="/home/n0x/.local/tts/tts_models--multilingual--multi-dataset--bark",  gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 88, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--bark/config.json'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 119, in load_model
    _download(config.REMOTE_MODEL_PATHS[model_type]["path"], ckpt_path, config.CACHE_DIR)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 49, in _download
    os.makedirs(CACHE_DIR, exist_ok=True)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 1 more time]
  File "/usr/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/root/.local'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 161, in _load_tts_from_dir
    config = load_config(os.path.join(model_dir, "config.json"))
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/config/__init__.py", line 88, in load_config
    with fsspec.open(config_path, "r", encoding="utf-8") as f:
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/core.py", line 105, in __enter__
    f = self.fs.open(self.path, mode=mode)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/spec.py", line 1303, in open
    f = self._open(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 195, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 359, in __init__
    self._open()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 364, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/root/.local/share/tts/tts_models--multilingual--multi-dataset--bark/config.json'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Downloading: "https://dl.fbaipublicfiles.com/encodec/v0/encodec_24khz-d7cc33bc.th" to /root/.cache/torch/hub/checkpoints/encodec_24khz-d7cc33bc.th
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/88.9M [00:00<?, ?B/s]
 10%|â–‰         | 8.75M/88.9M [00:00<00:00, 90.7MB/s]
 23%|â–ˆâ–ˆâ–Ž       | 20.0M/88.9M [00:00<00:00, 106MB/s] 
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 31.2M/88.9M [00:00<00:00, 111MB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 42.5M/88.9M [00:00<00:00, 114MB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 53.8M/88.9M [00:00<00:00, 115MB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 65.0M/88.9M [00:00<00:00, 116MB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 76.2M/88.9M [00:00<00:00, 116MB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 87.5M/88.9M [00:00<00:00, 117MB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88.9M/88.9M [00:00<00:00, 114MB/s]

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 72.0MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 66.4MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 71.4MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 70.5MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 65.4MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 60.0MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 38.0MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 15.6MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 59.0MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 19.9MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 63.4MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 72.0MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark",  gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 23.2MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 73.6MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 73.5MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
WARNING:TTS.tts.layers.bark.load_model:found outdated text model, removing...
 > tts_models/multilingual/multi-dataset/bark is already downloaded.
 > Using model: bark

  0%|          | 0.00/19.0k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0k/19.0k [00:00<00:00, 69.6MiB/s]
/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=device)
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", 
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 74, in __init__
    self.load_tts_model_by_name(model_name, gpu)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/api.py", line 177, in load_tts_model_by_name
    self.synthesizer = Synthesizer(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 109, in __init__
    self._load_tts_from_dir(model_dir, use_cuda)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/utils/synthesizer.py", line 164, in _load_tts_from_dir
    self.tts_model.load_checkpoint(config, checkpoint_dir=model_dir, eval=True)
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 281, in load_checkpoint
    self.load_bark_models()
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/models/bark.py", line 50, in load_bark_models
    self.semantic_model, self.config = load_model(
  File "/home/n0x/vocal-fun-ai-node/TTS/TTS/tts/layers/bark/load_model.py", line 121, in load_model
    checkpoint = torch.load(ckpt_path, map_location=device)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1384, in load
    return _legacy_load(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/serialization.py", line 1628, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, '<'.
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

  0%|          | 0.00/5.35G [00:00<?, ?iB/s]
  0%|          | 8.42M/5.35G [00:00<01:07, 79.4MiB/s]
  0%|          | 20.3M/5.35G [00:00<00:52, 102MiB/s] 
  1%|          | 32.0M/5.35G [00:00<00:48, 109MiB/s]
  1%|          | 43.5M/5.35G [00:00<00:47, 111MiB/s]
  1%|          | 54.6M/5.35G [00:00<00:47, 111MiB/s]
  1%|          | 66.0M/5.35G [00:00<00:47, 112MiB/s]
  1%|â–         | 77.2M/5.35G [00:00<00:50, 104MiB/s]
  2%|â–         | 90.2M/5.35G [00:00<00:47, 112MiB/s]
  2%|â–         | 102M/5.35G [00:00<00:45, 115MiB/s] 
  2%|â–         | 114M/5.35G [00:01<00:45, 115MiB/s]
  2%|â–         | 126M/5.35G [00:01<00:50, 104MiB/s]
  3%|â–Ž         | 138M/5.35G [00:01<00:47, 109MiB/s]
  3%|â–Ž         | 151M/5.35G [00:01<00:45, 115MiB/s]
  3%|â–Ž         | 162M/5.35G [00:01<00:45, 115MiB/s]
  3%|â–Ž         | 174M/5.35G [00:01<00:47, 109MiB/s]
  3%|â–Ž         | 185M/5.35G [00:01<00:47, 109MiB/s]
  4%|â–Ž         | 196M/5.35G [00:01<00:48, 107MiB/s]
  4%|â–         | 210M/5.35G [00:01<00:44, 117MiB/s]
  4%|â–         | 223M/5.35G [00:01<00:43, 119MiB/s]
  4%|â–         | 235M/5.35G [00:02<00:43, 118MiB/s]
  5%|â–         | 247M/5.35G [00:02<00:43, 118MiB/s]
  5%|â–         | 258M/5.35G [00:02<00:43, 118MiB/s]
  5%|â–Œ         | 270M/5.35G [00:02<00:44, 114MiB/s]
  5%|â–Œ         | 283M/5.35G [00:02<00:42, 119MiB/s]
  6%|â–Œ         | 295M/5.35G [00:02<00:42, 118MiB/s]
  6%|â–Œ         | 307M/5.35G [00:02<00:43, 117MiB/s]
  6%|â–Œ         | 319M/5.35G [00:02<00:43, 116MiB/s]
  6%|â–Œ         | 330M/5.35G [00:02<00:43, 115MiB/s]
  6%|â–‹         | 342M/5.35G [00:03<00:43, 115MiB/s]
  7%|â–‹         | 354M/5.35G [00:03<00:43, 116MiB/s]
  7%|â–‹         | 365M/5.35G [00:03<00:42, 116MiB/s]
  7%|â–‹         | 377M/5.35G [00:03<00:42, 117MiB/s]
  7%|â–‹         | 389M/5.35G [00:03<00:42, 117MiB/s]
  7%|â–‹         | 400M/5.35G [00:03<00:42, 117MiB/s]
  8%|â–Š         | 412M/5.35G [00:03<00:42, 117MiB/s]
  8%|â–Š         | 424M/5.35G [00:03<00:42, 117MiB/s]
  8%|â–Š         | 436M/5.35G [00:03<00:42, 117MiB/s]
  8%|â–Š         | 447M/5.35G [00:03<00:41, 117MiB/s]
  9%|â–Š         | 459M/5.35G [00:04<00:41, 117MiB/s]
  9%|â–‰         | 471M/5.35G [00:04<00:41, 117MiB/s]
  9%|â–‰         | 482M/5.35G [00:04<00:41, 117MiB/s]
  9%|â–‰         | 494M/5.35G [00:04<00:41, 117MiB/s]
  9%|â–‰         | 506M/5.35G [00:04<00:41, 117MiB/s]
 10%|â–‰         | 518M/5.35G [00:04<00:41, 117MiB/s]
 10%|â–‰         | 529M/5.35G [00:04<00:41, 117MiB/s]
 10%|â–ˆ         | 541M/5.35G [00:04<00:41, 117MiB/s]
 10%|â–ˆ         | 553M/5.35G [00:04<00:40, 117MiB/s]
 11%|â–ˆ         | 565M/5.35G [00:04<00:40, 117MiB/s]
 11%|â–ˆ         | 576M/5.35G [00:05<00:40, 117MiB/s]
 11%|â–ˆ         | 588M/5.35G [00:05<00:40, 117MiB/s]
 11%|â–ˆ         | 600M/5.35G [00:05<00:40, 117MiB/s]
 11%|â–ˆâ–        | 611M/5.35G [00:05<00:40, 117MiB/s]
 12%|â–ˆâ–        | 623M/5.35G [00:05<00:40, 117MiB/s]
 12%|â–ˆâ–        | 635M/5.35G [00:05<00:40, 117MiB/s]
 12%|â–ˆâ–        | 647M/5.35G [00:05<00:40, 117MiB/s]
 12%|â–ˆâ–        | 658M/5.35G [00:05<00:40, 117MiB/s]
 13%|â–ˆâ–Ž        | 670M/5.35G [00:05<00:39, 117MiB/s]
 13%|â–ˆâ–Ž        | 682M/5.35G [00:05<00:39, 117MiB/s]
 13%|â–ˆâ–Ž        | 693M/5.35G [00:06<00:39, 117MiB/s]
 13%|â–ˆâ–Ž        | 705M/5.35G [00:06<00:39, 117MiB/s]
 13%|â–ˆâ–Ž        | 717M/5.35G [00:06<00:39, 117MiB/s]
 14%|â–ˆâ–Ž        | 729M/5.35G [00:06<00:39, 117MiB/s]
 14%|â–ˆâ–        | 740M/5.35G [00:06<00:39, 117MiB/s]
 14%|â–ˆâ–        | 752M/5.35G [00:06<00:39, 117MiB/s]
 14%|â–ˆâ–        | 764M/5.35G [00:06<00:39, 117MiB/s]
 14%|â–ˆâ–        | 776M/5.35G [00:06<00:39, 117MiB/s]
 15%|â–ˆâ–        | 787M/5.35G [00:06<00:38, 117MiB/s]
 15%|â–ˆâ–        | 799M/5.35G [00:06<00:38, 117MiB/s]
 15%|â–ˆâ–Œ        | 811M/5.35G [00:07<00:38, 117MiB/s]
 15%|â–ˆâ–Œ        | 822M/5.35G [00:07<00:39, 116MiB/s]
 16%|â–ˆâ–Œ        | 834M/5.35G [00:07<00:39, 115MiB/s]
 16%|â–ˆâ–Œ        | 846M/5.35G [00:07<00:39, 115MiB/s]
 16%|â–ˆâ–Œ        | 857M/5.35G [00:07<00:38, 116MiB/s]
 16%|â–ˆâ–Œ        | 869M/5.35G [00:07<00:38, 116MiB/s]
 16%|â–ˆâ–‹        | 881M/5.35G [00:07<00:38, 117MiB/s]
 17%|â–ˆâ–‹        | 893M/5.35G [00:07<00:38, 117MiB/s]
 17%|â–ˆâ–‹        | 904M/5.35G [00:07<00:38, 117MiB/s]
 17%|â–ˆâ–‹        | 916M/5.35G [00:07<00:37, 117MiB/s]
 17%|â–ˆâ–‹        | 928M/5.35G [00:08<00:37, 117MiB/s]
 18%|â–ˆâ–Š        | 940M/5.35G [00:08<00:37, 117MiB/s]
 18%|â–ˆâ–Š        | 951M/5.35G [00:08<00:37, 117MiB/s]
 18%|â–ˆâ–Š        | 963M/5.35G [00:08<00:37, 117MiB/s]
 18%|â–ˆâ–Š        | 975M/5.35G [00:08<00:37, 117MiB/s]
 18%|â–ˆâ–Š        | 987M/5.35G [00:08<00:37, 117MiB/s]
 19%|â–ˆâ–Š        | 998M/5.35G [00:08<00:37, 117MiB/s]
 19%|â–ˆâ–‰        | 1.01G/5.35G [00:08<00:37, 116MiB/s]
 19%|â–ˆâ–‰        | 1.02G/5.35G [00:08<00:36, 117MiB/s]
 19%|â–ˆâ–‰        | 1.03G/5.35G [00:08<00:36, 118MiB/s]
 20%|â–ˆâ–‰        | 1.05G/5.35G [00:09<00:36, 118MiB/s]
 20%|â–ˆâ–‰        | 1.06G/5.35G [00:09<00:36, 117MiB/s]
 20%|â–ˆâ–‰        | 1.07G/5.35G [00:09<00:36, 117MiB/s]
 20%|â–ˆâ–ˆ        | 1.08G/5.35G [00:09<00:36, 117MiB/s]
 20%|â–ˆâ–ˆ        | 1.09G/5.35G [00:09<00:36, 117MiB/s]
 21%|â–ˆâ–ˆ        | 1.10G/5.35G [00:09<00:36, 117MiB/s]
 21%|â–ˆâ–ˆ        | 1.12G/5.35G [00:09<00:36, 117MiB/s]
 21%|â–ˆâ–ˆ        | 1.13G/5.35G [00:09<00:36, 117MiB/s]
 21%|â–ˆâ–ˆâ–       | 1.14G/5.35G [00:09<00:36, 117MiB/s]
 22%|â–ˆâ–ˆâ–       | 1.15G/5.35G [00:09<00:35, 117MiB/s]
 22%|â–ˆâ–ˆâ–       | 1.16G/5.35G [00:10<00:58, 71.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 1.17G/5.35G [00:10<00:51, 80.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 1.19G/5.35G [00:10<00:46, 88.9MiB/s]
 22%|â–ˆâ–ˆâ–       | 1.20G/5.35G [00:10<00:43, 95.8MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 1.21G/5.35G [00:10<00:40, 101MiB/s] 
 23%|â–ˆâ–ˆâ–Ž       | 1.22G/5.35G [00:10<00:39, 106MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 1.23G/5.35G [00:10<00:37, 109MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 1.24G/5.35G [00:10<00:40, 100MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 1.26G/5.35G [00:11<00:37, 111MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 1.27G/5.35G [00:11<00:36, 113MiB/s]
 24%|â–ˆâ–ˆâ–       | 1.28G/5.35G [00:11<00:35, 114MiB/s]
 24%|â–ˆâ–ˆâ–       | 1.29G/5.35G [00:11<00:35, 114MiB/s]
 24%|â–ˆâ–ˆâ–       | 1.30G/5.35G [00:11<00:35, 115MiB/s]
 25%|â–ˆâ–ˆâ–       | 1.32G/5.35G [00:11<00:34, 116MiB/s]
 25%|â–ˆâ–ˆâ–       | 1.33G/5.35G [00:11<00:34, 116MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 1.34G/5.35G [00:11<00:34, 117MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 1.35G/5.35G [00:11<00:34, 117MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 1.36G/5.35G [00:11<00:34, 117MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.38G/5.35G [00:12<00:34, 116MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.39G/5.35G [00:12<00:34, 115MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 1.40G/5.35G [00:12<00:34, 115MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 1.41G/5.35G [00:12<00:34, 116MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.42G/5.35G [00:12<00:33, 116MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.43G/5.35G [00:12<00:33, 116MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.45G/5.35G [00:12<00:33, 117MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.46G/5.35G [00:12<00:33, 117MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 1.47G/5.35G [00:12<00:33, 117MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.48G/5.35G [00:13<00:33, 117MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.49G/5.35G [00:13<00:33, 117MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.50G/5.35G [00:13<00:32, 117MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 1.52G/5.35G [00:13<00:32, 117MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.53G/5.35G [00:13<00:32, 117MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 1.54G/5.35G [00:13<00:32, 117MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.55G/5.35G [00:13<00:32, 117MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.56G/5.35G [00:13<00:32, 116MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 1.57G/5.35G [00:13<00:32, 116MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.59G/5.35G [00:13<00:32, 116MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 1.60G/5.35G [00:14<00:32, 117MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.61G/5.35G [00:14<00:32, 117MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.62G/5.35G [00:14<00:31, 117MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 1.63G/5.35G [00:14<00:31, 117MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.64G/5.35G [00:14<00:31, 117MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.66G/5.35G [00:14<00:31, 117MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 1.67G/5.35G [00:14<00:31, 117MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 1.68G/5.35G [00:14<00:31, 117MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.69G/5.35G [00:14<00:31, 116MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.70G/5.35G [00:14<00:31, 117MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.71G/5.35G [00:15<00:31, 117MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.73G/5.35G [00:15<00:31, 117MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 1.74G/5.35G [00:15<00:30, 117MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.75G/5.35G [00:15<00:30, 117MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.76G/5.35G [00:15<00:30, 117MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.77G/5.35G [00:15<00:30, 117MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.78G/5.35G [00:15<00:30, 117MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.80G/5.35G [00:15<00:30, 117MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.81G/5.35G [00:15<00:30, 117MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.82G/5.35G [00:15<00:30, 117MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.83G/5.35G [00:16<00:30, 117MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 1.84G/5.35G [00:16<00:30, 117MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.85G/5.35G [00:16<00:29, 117MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 1.87G/5.35G [00:16<00:29, 116MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.88G/5.35G [00:16<00:29, 117MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.89G/5.35G [00:16<00:29, 117MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.90G/5.35G [00:16<00:29, 117MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.91G/5.35G [00:16<00:29, 117MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.93G/5.35G [00:16<00:29, 117MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.94G/5.35G [00:16<00:29, 117MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.95G/5.35G [00:17<00:29, 115MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.96G/5.35G [00:17<00:29, 115MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.97G/5.35G [00:17<00:29, 115MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.98G/5.35G [00:17<00:29, 115MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2.00G/5.35G [00:17<00:28, 116MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2.01G/5.35G [00:17<00:28, 117MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2.02G/5.35G [00:17<00:28, 117MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2.03G/5.35G [00:17<00:28, 117MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2.04G/5.35G [00:17<00:28, 117MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2.05G/5.35G [00:17<00:28, 117MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2.07G/5.35G [00:18<00:28, 116MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2.08G/5.35G [00:18<00:28, 117MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2.09G/5.35G [00:18<00:27, 117MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2.10G/5.35G [00:18<00:27, 117MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2.11G/5.35G [00:18<00:27, 117MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2.12G/5.35G [00:18<00:27, 117MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2.14G/5.35G [00:18<00:27, 117MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.15G/5.35G [00:18<00:27, 117MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.16G/5.35G [00:18<00:27, 116MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.17G/5.35G [00:18<00:27, 114MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.18G/5.35G [00:19<00:27, 117MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.20G/5.35G [00:19<00:26, 117MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.21G/5.35G [00:19<00:26, 117MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.22G/5.35G [00:19<00:26, 117MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.23G/5.35G [00:19<00:27, 113MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.24G/5.35G [00:19<00:26, 117MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.25G/5.35G [00:19<00:26, 117MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.27G/5.35G [00:19<00:26, 117MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.28G/5.35G [00:19<00:26, 117MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.29G/5.35G [00:19<00:26, 117MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.30G/5.35G [00:20<00:26, 117MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.31G/5.35G [00:20<00:26, 117MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.33G/5.35G [00:20<00:25, 117MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2.34G/5.35G [00:20<00:25, 117MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.35G/5.35G [00:20<00:26, 114MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.36G/5.35G [00:20<00:25, 118MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.37G/5.35G [00:20<00:25, 117MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.38G/5.35G [00:20<00:26, 113MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.40G/5.35G [00:20<00:24, 118MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.41G/5.35G [00:20<00:24, 118MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.42G/5.35G [00:21<00:40, 72.7MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.43G/5.35G [00:21<00:35, 81.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.44G/5.35G [00:21<00:32, 89.8MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.46G/5.35G [00:21<00:30, 96.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.47G/5.35G [00:21<00:28, 101MiB/s] 
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.48G/5.35G [00:21<00:27, 104MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.49G/5.35G [00:21<00:26, 109MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.50G/5.35G [00:21<00:26, 109MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.51G/5.35G [00:22<00:25, 110MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.53G/5.35G [00:22<00:25, 112MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.54G/5.35G [00:22<00:24, 113MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.55G/5.35G [00:22<00:24, 114MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.56G/5.35G [00:22<00:24, 114MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.57G/5.35G [00:22<00:24, 116MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.58G/5.35G [00:22<00:23, 116MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.60G/5.35G [00:22<00:23, 116MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.61G/5.35G [00:22<00:23, 116MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.62G/5.35G [00:22<00:23, 116MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.63G/5.35G [00:23<00:23, 117MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.64G/5.35G [00:23<00:28, 94.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.66G/5.35G [00:23<00:24, 108MiB/s] 
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.67G/5.35G [00:23<00:24, 110MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.68G/5.35G [00:23<00:23, 112MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.69G/5.35G [00:23<00:23, 113MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.70G/5.35G [00:23<00:23, 114MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.72G/5.35G [00:23<00:22, 115MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.73G/5.35G [00:23<00:22, 115MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.74G/5.35G [00:24<00:22, 116MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.75G/5.35G [00:24<00:22, 116MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.76G/5.35G [00:24<00:22, 116MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.77G/5.35G [00:24<00:22, 117MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.79G/5.35G [00:24<00:22, 112MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.80G/5.35G [00:24<00:21, 118MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.81G/5.35G [00:24<00:21, 117MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.82G/5.35G [00:24<00:21, 117MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.83G/5.35G [00:24<00:21, 117MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.85G/5.35G [00:24<00:21, 117MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.86G/5.35G [00:25<00:21, 117MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.87G/5.35G [00:25<00:21, 117MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.88G/5.35G [00:25<00:21, 117MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.89G/5.35G [00:25<00:21, 117MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.90G/5.35G [00:25<00:20, 117MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.92G/5.35G [00:25<00:20, 117MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.93G/5.35G [00:25<00:20, 117MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.94G/5.35G [00:25<00:20, 117MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.95G/5.35G [00:25<00:20, 117MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.96G/5.35G [00:25<00:20, 117MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.97G/5.35G [00:26<00:20, 117MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.99G/5.35G [00:26<00:20, 117MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3.00G/5.35G [00:26<00:20, 117MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3.01G/5.35G [00:26<00:20, 117MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.02G/5.35G [00:26<00:19, 117MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.03G/5.35G [00:26<00:19, 117MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.04G/5.35G [00:26<00:19, 117MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.06G/5.35G [00:26<00:19, 117MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.07G/5.35G [00:26<00:19, 115MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.08G/5.35G [00:26<00:20, 114MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.09G/5.35G [00:27<00:19, 114MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.10G/5.35G [00:27<00:19, 115MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.11G/5.35G [00:27<00:19, 116MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.13G/5.35G [00:27<00:19, 116MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3.14G/5.35G [00:27<00:19, 116MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.15G/5.35G [00:27<00:18, 116MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.16G/5.35G [00:27<00:18, 116MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.17G/5.35G [00:27<00:18, 117MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.18G/5.35G [00:27<00:18, 117MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.20G/5.35G [00:27<00:18, 116MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3.21G/5.35G [00:28<00:18, 116MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.22G/5.35G [00:28<00:18, 116MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.23G/5.35G [00:28<00:18, 117MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.24G/5.35G [00:28<00:18, 117MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.25G/5.35G [00:28<00:17, 117MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.27G/5.35G [00:28<00:17, 116MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.28G/5.35G [00:28<00:17, 117MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.29G/5.35G [00:28<00:17, 117MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.30G/5.35G [00:28<00:17, 117MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.31G/5.35G [00:28<00:17, 117MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.32G/5.35G [00:29<00:17, 117MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.34G/5.35G [00:29<00:17, 117MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.35G/5.35G [00:29<00:17, 117MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.36G/5.35G [00:29<00:17, 117MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.37G/5.35G [00:29<00:16, 117MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.38G/5.35G [00:29<00:16, 117MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.40G/5.35G [00:29<00:16, 117MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3.41G/5.35G [00:29<00:16, 117MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.42G/5.35G [00:29<00:16, 117MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.43G/5.35G [00:30<00:16, 117MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.44G/5.35G [00:30<00:16, 117MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.45G/5.35G [00:30<00:16, 117MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.47G/5.35G [00:30<00:16, 116MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.48G/5.35G [00:30<00:15, 118MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.49G/5.35G [00:30<00:15, 118MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.50G/5.35G [00:30<00:15, 117MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.51G/5.35G [00:30<00:15, 117MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.52G/5.35G [00:30<00:15, 117MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.54G/5.35G [00:30<00:15, 117MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.55G/5.35G [00:31<00:15, 117MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.56G/5.35G [00:31<00:15, 117MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.57G/5.35G [00:31<00:15, 117MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.58G/5.35G [00:31<00:15, 117MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.60G/5.35G [00:31<00:15, 117MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.61G/5.35G [00:31<00:14, 117MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.62G/5.35G [00:31<00:14, 117MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.63G/5.35G [00:31<00:14, 117MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.64G/5.35G [00:31<00:14, 115MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.65G/5.35G [00:31<00:14, 114MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.67G/5.35G [00:32<00:14, 115MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3.68G/5.35G [00:32<00:14, 115MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.69G/5.35G [00:32<00:14, 116MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.70G/5.35G [00:32<00:14, 116MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.71G/5.35G [00:32<00:14, 116MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.72G/5.35G [00:32<00:13, 117MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.74G/5.35G [00:32<00:13, 117MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3.75G/5.35G [00:32<00:13, 117MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.76G/5.35G [00:32<00:13, 117MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.77G/5.35G [00:32<00:13, 117MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.78G/5.35G [00:33<00:13, 117MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.79G/5.35G [00:33<00:13, 117MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.81G/5.35G [00:33<00:13, 117MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.82G/5.35G [00:33<00:21, 71.2MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.83G/5.35G [00:33<00:18, 80.7MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.84G/5.35G [00:33<00:16, 89.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.85G/5.35G [00:33<00:15, 96.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.86G/5.35G [00:33<00:14, 101MiB/s] 
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.88G/5.35G [00:34<00:13, 106MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.89G/5.35G [00:34<00:13, 109MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.90G/5.35G [00:34<00:13, 111MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.91G/5.35G [00:34<00:12, 113MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.92G/5.35G [00:34<00:12, 114MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.93G/5.35G [00:34<00:12, 115MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3.95G/5.35G [00:34<00:12, 116MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.96G/5.35G [00:34<00:12, 116MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.97G/5.35G [00:34<00:11, 117MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.98G/5.35G [00:34<00:11, 117MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.99G/5.35G [00:35<00:11, 117MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4.00G/5.35G [00:35<00:11, 117MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.02G/5.35G [00:35<00:11, 117MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.03G/5.35G [00:35<00:11, 117MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.04G/5.35G [00:35<00:11, 117MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.05G/5.35G [00:35<00:11, 117MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.06G/5.35G [00:35<00:11, 117MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4.08G/5.35G [00:35<00:10, 117MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.09G/5.35G [00:35<00:10, 117MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.10G/5.35G [00:35<00:10, 117MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.11G/5.35G [00:36<00:10, 117MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.12G/5.35G [00:36<00:10, 117MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.13G/5.35G [00:36<00:10, 117MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.15G/5.35G [00:36<00:10, 117MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4.16G/5.35G [00:36<00:10, 117MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4.17G/5.35G [00:36<00:10, 117MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4.18G/5.35G [00:36<00:10, 117MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4.19G/5.35G [00:36<00:09, 117MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4.20G/5.35G [00:36<00:09, 117MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.22G/5.35G [00:36<00:09, 117MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.23G/5.35G [00:37<00:09, 117MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.24G/5.35G [00:37<00:09, 115MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.25G/5.35G [00:37<00:09, 111MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.27G/5.35G [00:37<00:09, 120MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4.28G/5.35G [00:37<00:09, 119MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.29G/5.35G [00:37<00:09, 118MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.30G/5.35G [00:37<00:08, 118MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.31G/5.35G [00:37<00:08, 118MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.32G/5.35G [00:37<00:08, 118MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.34G/5.35G [00:37<00:08, 118MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.35G/5.35G [00:38<00:08, 117MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.36G/5.35G [00:38<00:08, 117MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.37G/5.35G [00:38<00:08, 117MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.38G/5.35G [00:38<00:08, 117MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.40G/5.35G [00:38<00:14, 64.7MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.41G/5.35G [00:38<00:13, 72.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.42G/5.35G [00:38<00:11, 84.5MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.43G/5.35G [00:39<00:10, 92.2MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.44G/5.35G [00:39<00:09, 98.4MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.45G/5.35G [00:39<00:08, 103MiB/s] 
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.47G/5.35G [00:39<00:08, 107MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4.48G/5.35G [00:39<00:07, 110MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.49G/5.35G [00:39<00:07, 112MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.50G/5.35G [00:39<00:07, 113MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.51G/5.35G [00:39<00:07, 115MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.52G/5.35G [00:39<00:07, 115MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.54G/5.35G [00:39<00:07, 116MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.55G/5.35G [00:40<00:06, 116MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.56G/5.35G [00:40<00:06, 117MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.57G/5.35G [00:40<00:06, 117MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.58G/5.35G [00:40<00:06, 117MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.59G/5.35G [00:40<00:06, 117MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.61G/5.35G [00:40<00:06, 117MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.62G/5.35G [00:40<00:06, 117MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.63G/5.35G [00:40<00:06, 117MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.64G/5.35G [00:40<00:06, 117MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.65G/5.35G [00:40<00:05, 117MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.66G/5.35G [00:41<00:05, 117MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.68G/5.35G [00:41<00:05, 117MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.69G/5.35G [00:41<00:05, 117MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.70G/5.35G [00:41<00:05, 117MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.71G/5.35G [00:41<00:05, 117MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.72G/5.35G [00:41<00:05, 117MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.73G/5.35G [00:41<00:05, 117MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.75G/5.35G [00:41<00:05, 117MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.76G/5.35G [00:41<00:05, 117MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.77G/5.35G [00:41<00:04, 117MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.78G/5.35G [00:42<00:04, 117MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.79G/5.35G [00:42<00:04, 117MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.81G/5.35G [00:42<00:04, 117MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.82G/5.35G [00:42<00:04, 117MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.83G/5.35G [00:42<00:04, 117MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.84G/5.35G [00:42<00:04, 117MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.85G/5.35G [00:42<00:04, 117MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.86G/5.35G [00:42<00:04, 117MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.88G/5.35G [00:42<00:04, 117MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.89G/5.35G [00:42<00:03, 117MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.90G/5.35G [00:43<00:03, 117MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.91G/5.35G [00:43<00:03, 117MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.92G/5.35G [00:43<00:03, 117MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.93G/5.35G [00:43<00:03, 117MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.95G/5.35G [00:43<00:03, 116MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4.96G/5.35G [00:43<00:03, 117MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4.97G/5.35G [00:43<00:03, 116MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4.98G/5.35G [00:43<00:03, 115MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4.99G/5.35G [00:43<00:03, 118MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5.01G/5.35G [00:43<00:02, 117MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5.02G/5.35G [00:44<00:02, 116MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5.03G/5.35G [00:44<00:02, 116MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5.04G/5.35G [00:44<00:02, 116MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5.05G/5.35G [00:44<00:02, 118MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5.06G/5.35G [00:44<00:02, 118MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5.08G/5.35G [00:44<00:02, 119MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.09G/5.35G [00:44<00:02, 118MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.10G/5.35G [00:44<00:02, 118MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.11G/5.35G [00:44<00:02, 118MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.12G/5.35G [00:44<00:01, 118MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.14G/5.35G [00:45<00:01, 118MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5.15G/5.35G [00:45<00:01, 117MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5.16G/5.35G [00:45<00:01, 117MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5.17G/5.35G [00:45<00:01, 114MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5.18G/5.35G [00:45<00:01, 118MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5.20G/5.35G [00:45<00:01, 118MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5.21G/5.35G [00:45<00:01, 118MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.22G/5.35G [00:45<00:01, 118MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.23G/5.35G [00:45<00:01, 118MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.24G/5.35G [00:45<00:00, 117MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.25G/5.35G [00:46<00:00, 115MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.27G/5.35G [00:46<00:00, 118MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5.28G/5.35G [00:46<00:00, 116MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.29G/5.35G [00:46<00:00, 116MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.30G/5.35G [00:46<00:00, 117MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.32G/5.35G [00:46<00:00, 119MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.33G/5.35G [00:46<00:00, 117MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.34G/5.35G [00:46<00:00, 119MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5.35G/5.35G [00:46<00:00, 118MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35G/5.35G [00:46<00:00, 114MiB/s]
INFO:     Started server process [99477]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/layers/bark/hubert/tokenizer.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(path, map_location=map_location))

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:00<01:03,  1.57it/s]
  2%|â–         | 2/100 [00:00<00:31,  3.08it/s]
  4%|â–         | 4/100 [00:00<00:16,  5.74it/s]
  6%|â–Œ         | 6/100 [00:01<00:12,  7.42it/s]
  8%|â–Š         | 8/100 [00:01<00:10,  8.81it/s]
 10%|â–ˆ         | 10/100 [00:01<00:09,  9.72it/s]
 12%|â–ˆâ–        | 12/100 [00:01<00:08,  9.78it/s]
 14%|â–ˆâ–        | 14/100 [00:01<00:08, 10.11it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:02<00:08, 10.24it/s]
 18%|â–ˆâ–Š        | 18/100 [00:02<00:07, 10.51it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:02<00:07, 10.71it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:02<00:07, 10.56it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:02<00:07, 10.34it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:02<00:07,  9.99it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:03<00:07,  9.24it/s]
 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:03<00:08,  8.86it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:03<00:08,  8.58it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:03<00:08,  8.30it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:03<00:07,  8.81it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:03<00:07,  8.96it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:04<00:06,  9.95it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:04<00:05, 10.55it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:04<00:05, 10.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 121.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 21.78it/s] 

  0%|          | 0/16 [00:00<?, ?it/s]
  6%|â–‹         | 1/16 [00:00<00:10,  1.47it/s]
 12%|â–ˆâ–Ž        | 2/16 [00:01<00:09,  1.53it/s]
 19%|â–ˆâ–‰        | 3/16 [00:02<00:09,  1.44it/s]
 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:02<00:08,  1.45it/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:03<00:07,  1.47it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:04<00:06,  1.47it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:04<00:06,  1.46it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:05<00:05,  1.46it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:06<00:04,  1.41it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:06<00:04,  1.38it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:07<00:03,  1.30it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:08<00:03,  1.20it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:09<00:02,  1.23it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:10<00:01,  1.18it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:11<00:00,  1.31it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:11<00:00,  1.48it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:11<00:00,  1.38it/s]
INFO:     127.0.0.1:41382 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:06, 15.75it/s]
  4%|â–         | 4/100 [00:00<00:06, 15.99it/s]
  6%|â–Œ         | 6/100 [00:00<00:06, 15.23it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 15.45it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 15.74it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 15.40it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 15.74it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:01<00:05, 15.62it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:05, 15.80it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:05, 15.89it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 15.69it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:01<00:04, 15.86it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:01<00:04, 16.02it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:01<00:04, 15.74it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:01<00:04, 15.86it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:02<00:04, 15.97it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:04, 15.67it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:04, 15.90it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:02<00:03, 16.16it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:02<00:03, 15.82it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:02<00:03, 15.91it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 37.17it/s]

  0%|          | 0/17 [00:00<?, ?it/s]
  6%|â–Œ         | 1/17 [00:00<00:07,  2.03it/s]
 12%|â–ˆâ–        | 2/17 [00:00<00:07,  2.05it/s]
 18%|â–ˆâ–Š        | 3/17 [00:01<00:06,  2.07it/s]
 24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:01<00:06,  2.06it/s]
 29%|â–ˆâ–ˆâ–‰       | 5/17 [00:02<00:05,  2.06it/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:02<00:05,  2.07it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:03<00:04,  2.07it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:03<00:04,  2.08it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:04<00:03,  2.08it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:04<00:03,  2.08it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:05<00:02,  2.07it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:05<00:02,  2.07it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:06<00:01,  2.07it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:06<00:01,  2.08it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:07<00:00,  2.08it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:07<00:00,  2.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.18it/s]
INFO:     127.0.0.1:41382 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:00<00:09,  9.93it/s]
  2%|â–         | 2/100 [00:00<00:11,  8.69it/s]
  4%|â–         | 4/100 [00:00<00:08, 11.24it/s]
  6%|â–Œ         | 6/100 [00:00<00:08, 11.25it/s]
  8%|â–Š         | 8/100 [00:00<00:07, 12.12it/s]
 10%|â–ˆ         | 10/100 [00:00<00:07, 11.99it/s]
 12%|â–ˆâ–        | 12/100 [00:01<00:07, 12.23it/s]
 14%|â–ˆâ–        | 14/100 [00:01<00:07, 11.64it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:01<00:07, 11.48it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:06, 12.14it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:06, 11.99it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:06, 12.25it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:02<00:06, 12.05it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:02<00:06, 12.16it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:02<00:06, 11.68it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:02<00:05, 12.27it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:02<00:05, 12.02it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:05, 12.03it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:03<00:05, 11.89it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:03<00:05, 11.69it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:03<00:05, 11.86it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:03<00:05, 11.36it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:03<00:04, 11.50it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:04<00:05,  9.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 96.05it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 24.04it/s]

  0%|          | 0/18 [00:00<?, ?it/s]
  6%|â–Œ         | 1/18 [00:00<00:11,  1.45it/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [109349]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:01<01:51,  1.13s/it]
  3%|â–Ž         | 3/100 [00:01<00:33,  2.94it/s]
  5%|â–Œ         | 5/100 [00:01<00:18,  5.13it/s]
  7%|â–‹         | 7/100 [00:01<00:12,  7.29it/s]
  9%|â–‰         | 9/100 [00:01<00:09,  9.22it/s]
 11%|â–ˆ         | 11/100 [00:01<00:08, 11.03it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:01<00:07, 12.23it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:01<00:06, 13.53it/s]
 17%|â–ˆâ–‹        | 17/100 [00:02<00:05, 14.52it/s]
 19%|â–ˆâ–‰        | 19/100 [00:02<00:05, 15.02it/s]
 21%|â–ˆâ–ˆ        | 21/100 [00:02<00:05, 15.66it/s]
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:02<00:04, 16.15it/s]
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:02<00:04, 16.17it/s]
 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:02<00:04, 16.50it/s]
 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:02<00:04, 16.77it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:02<00:04, 16.53it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:03<00:04, 16.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 32.02it/s]

  0%|          | 0/14 [00:00<?, ?it/s]
  7%|â–‹         | 1/14 [00:00<00:06,  2.08it/s]
 14%|â–ˆâ–        | 2/14 [00:00<00:05,  2.15it/s]
 21%|â–ˆâ–ˆâ–       | 3/14 [00:01<00:05,  2.17it/s]
 29%|â–ˆâ–ˆâ–Š       | 4/14 [00:01<00:04,  2.14it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:02<00:04,  2.15it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 6/14 [00:02<00:03,  2.17it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:03<00:03,  2.18it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:03<00:02,  2.18it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:04<00:02,  2.19it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:04<00:01,  2.20it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:05<00:01,  2.20it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:05<00:00,  2.20it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 13/14 [00:05<00:00,  2.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.34it/s]
INFO:     127.0.0.1:34596 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34596 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:00<00:10,  9.84it/s]
  3%|â–Ž         | 3/100 [00:00<00:06, 13.97it/s]
  5%|â–Œ         | 5/100 [00:00<00:06, 15.66it/s]
  7%|â–‹         | 7/100 [00:00<00:05, 16.43it/s]
  9%|â–‰         | 9/100 [00:00<00:05, 16.52it/s]
 11%|â–ˆ         | 11/100 [00:00<00:05, 16.75it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:00<00:05, 16.41it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:00<00:05, 16.72it/s]
 17%|â–ˆâ–‹        | 17/100 [00:01<00:04, 16.95it/s]
 19%|â–ˆâ–‰        | 19/100 [00:01<00:04, 16.76it/s]
 21%|â–ˆâ–ˆ        | 21/100 [00:01<00:04, 16.97it/s]
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:01<00:04, 17.07it/s]
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:01<00:04, 16.87it/s]
 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:01<00:04, 16.99it/s]
 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:01<00:04, 17.13it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:01<00:04, 16.89it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:01<00:03, 17.03it/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:02<00:03, 17.08it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 45.93it/s]

  0%|          | 0/14 [00:00<?, ?it/s]
  7%|â–‹         | 1/14 [00:00<00:05,  2.21it/s]
 14%|â–ˆâ–        | 2/14 [00:00<00:05,  2.22it/s]
 21%|â–ˆâ–ˆâ–       | 3/14 [00:01<00:04,  2.22it/s]
 29%|â–ˆâ–ˆâ–Š       | 4/14 [00:01<00:04,  2.21it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:02<00:04,  2.18it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 6/14 [00:02<00:03,  2.19it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:03<00:03,  2.19it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:03<00:02,  2.19it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:04<00:02,  2.20it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:04<00:01,  2.20it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:04<00:01,  2.20it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:05<00:00,  2.20it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 13/14 [00:05<00:00,  2.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.24it/s]
INFO:     127.0.0.1:54654 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54654 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [109349]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > You must confirm the following:
 | > "I have purchased a commercial license from Coqui: licensing@coqui.ai"
 | > "Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml" - [y/n]
 | | > 
  0%|          | 0.00/1.87G [00:00<?, ?iB/s]
  0%|          | 4.65M/1.87G [00:00<00:40, 46.5MiB/s]
  0%|          | 9.31M/1.87G [00:00<00:41, 44.6MiB/s]
  1%|          | 13.8M/1.87G [00:00<00:42, 43.7MiB/s]
  1%|          | 18.2M/1.87G [00:00<00:42, 43.5MiB/s]
  1%|          | 22.7M/1.87G [00:00<00:42, 43.6MiB/s]
  1%|â–         | 27.1M/1.87G [00:00<00:42, 43.7MiB/s]
  2%|â–         | 31.6M/1.87G [00:00<00:42, 43.4MiB/s]
  2%|â–         | 35.9M/1.87G [00:00<00:42, 43.4MiB/s]
  2%|â–         | 40.3M/1.87G [00:00<00:42, 43.2MiB/s]
  2%|â–         | 44.7M/1.87G [00:01<00:42, 43.2MiB/s]
  3%|â–Ž         | 49.2M/1.87G [00:01<00:41, 43.4MiB/s]
  3%|â–Ž         | 53.6M/1.87G [00:01<00:41, 43.2MiB/s]
  3%|â–Ž         | 58.0M/1.87G [00:01<00:41, 43.5MiB/s]
  3%|â–Ž         | 62.4M/1.87G [00:01<00:41, 43.1MiB/s]
  4%|â–Ž         | 66.7M/1.87G [00:01<00:42, 42.9MiB/s]
  4%|â–         | 71.0M/1.87G [00:01<00:42, 42.8MiB/s]
  4%|â–         | 75.4M/1.87G [00:01<00:42, 42.5MiB/s]
  4%|â–         | 79.8M/1.87G [00:01<00:41, 42.7MiB/s]
  5%|â–         | 84.3M/1.87G [00:01<00:41, 42.8MiB/s]
  5%|â–         | 88.7M/1.87G [00:02<00:41, 42.9MiB/s]
  5%|â–         | 93.2M/1.87G [00:02<00:41, 43.0MiB/s]
  5%|â–Œ         | 97.6M/1.87G [00:02<00:41, 43.1MiB/s]
  5%|â–Œ         | 102M/1.87G [00:02<00:40, 43.2MiB/s] 
  6%|â–Œ         | 107M/1.87G [00:02<00:40, 43.3MiB/s]
  6%|â–Œ         | 111M/1.87G [00:02<00:40, 43.2MiB/s]
  6%|â–Œ         | 115M/1.87G [00:02<00:40, 43.5MiB/s]
  6%|â–‹         | 120M/1.87G [00:02<00:40, 43.3MiB/s]
  7%|â–‹         | 124M/1.87G [00:02<00:40, 43.2MiB/s]
  7%|â–‹         | 128M/1.87G [00:02<00:40, 42.9MiB/s]
  7%|â–‹         | 133M/1.87G [00:03<00:40, 42.7MiB/s]
  7%|â–‹         | 137M/1.87G [00:03<00:40, 43.1MiB/s]
  8%|â–Š         | 142M/1.87G [00:03<00:39, 43.3MiB/s]
  8%|â–Š         | 146M/1.87G [00:03<00:39, 43.2MiB/s]
  8%|â–Š         | 150M/1.87G [00:03<00:39, 43.1MiB/s]
  8%|â–Š         | 155M/1.87G [00:03<00:39, 43.2MiB/s]
  9%|â–Š         | 159M/1.87G [00:03<00:39, 43.2MiB/s]
  9%|â–‰         | 164M/1.87G [00:03<00:39, 43.3MiB/s]
  9%|â–‰         | 168M/1.87G [00:03<00:39, 43.4MiB/s]
  9%|â–‰         | 172M/1.87G [00:03<00:39, 43.2MiB/s]
  9%|â–‰         | 177M/1.87G [00:04<00:39, 43.3MiB/s]
 10%|â–‰         | 181M/1.87G [00:04<00:39, 43.2MiB/s]
 10%|â–‰         | 186M/1.87G [00:04<00:38, 43.2MiB/s]
 10%|â–ˆ         | 190M/1.87G [00:04<00:38, 43.3MiB/s]
 10%|â–ˆ         | 194M/1.87G [00:04<00:38, 43.0MiB/s]
 11%|â–ˆ         | 199M/1.87G [00:04<00:38, 42.9MiB/s]
 11%|â–ˆ         | 203M/1.87G [00:04<00:38, 43.3MiB/s]
 11%|â–ˆ         | 208M/1.87G [00:04<00:38, 43.1MiB/s]
 11%|â–ˆâ–        | 212M/1.87G [00:04<00:38, 43.0MiB/s]
 12%|â–ˆâ–        | 216M/1.87G [00:05<00:38, 43.4MiB/s]
 12%|â–ˆâ–        | 221M/1.87G [00:05<00:38, 43.2MiB/s]
 12%|â–ˆâ–        | 225M/1.87G [00:05<00:38, 43.0MiB/s]
 12%|â–ˆâ–        | 229M/1.87G [00:05<00:37, 43.3MiB/s]
 13%|â–ˆâ–Ž        | 234M/1.87G [00:05<00:37, 43.1MiB/s]
 13%|â–ˆâ–Ž        | 238M/1.87G [00:05<00:37, 43.2MiB/s]
 13%|â–ˆâ–Ž        | 243M/1.87G [00:05<00:37, 43.4MiB/s]
 13%|â–ˆâ–Ž        | 247M/1.87G [00:05<00:37, 43.0MiB/s]
 13%|â–ˆâ–Ž        | 251M/1.87G [00:05<00:37, 42.7MiB/s]
 14%|â–ˆâ–Ž        | 256M/1.87G [00:05<00:37, 43.2MiB/s]
 14%|â–ˆâ–        | 260M/1.87G [00:06<00:37, 43.0MiB/s]
 14%|â–ˆâ–        | 264M/1.87G [00:06<00:37, 42.8MiB/s]
 14%|â–ˆâ–        | 269M/1.87G [00:06<00:37, 43.0MiB/s]
 15%|â–ˆâ–        | 273M/1.87G [00:06<00:36, 43.2MiB/s]
 15%|â–ˆâ–        | 278M/1.87G [00:06<00:36, 43.1MiB/s]
 15%|â–ˆâ–Œ        | 282M/1.87G [00:06<00:36, 43.2MiB/s]
 15%|â–ˆâ–Œ        | 287M/1.87G [00:06<00:36, 43.5MiB/s]
 16%|â–ˆâ–Œ        | 291M/1.87G [00:06<00:36, 43.0MiB/s]
 16%|â–ˆâ–Œ        | 295M/1.87G [00:06<00:36, 42.8MiB/s]
 16%|â–ˆâ–Œ        | 300M/1.87G [00:06<00:36, 43.1MiB/s]
 16%|â–ˆâ–‹        | 304M/1.87G [00:07<00:36, 43.0MiB/s]
 17%|â–ˆâ–‹        | 308M/1.87G [00:07<00:36, 43.1MiB/s]
 17%|â–ˆâ–‹        | 313M/1.87G [00:07<00:36, 43.1MiB/s]
 17%|â–ˆâ–‹        | 317M/1.87G [00:07<00:36, 42.8MiB/s]
 17%|â–ˆâ–‹        | 322M/1.87G [00:07<00:36, 42.9MiB/s]
 17%|â–ˆâ–‹        | 326M/1.87G [00:07<00:35, 43.0MiB/s]
 18%|â–ˆâ–Š        | 330M/1.87G [00:07<00:35, 43.1MiB/s]
 18%|â–ˆâ–Š        | 335M/1.87G [00:07<00:35, 43.0MiB/s]
 18%|â–ˆâ–Š        | 339M/1.87G [00:07<00:35, 43.1MiB/s]
 18%|â–ˆâ–Š        | 344M/1.87G [00:07<00:35, 43.2MiB/s]
 19%|â–ˆâ–Š        | 348M/1.87G [00:08<00:35, 43.3MiB/s]
 19%|â–ˆâ–‰        | 353M/1.87G [00:08<00:35, 43.2MiB/s]
 19%|â–ˆâ–‰        | 357M/1.87G [00:08<00:34, 43.4MiB/s]
 19%|â–ˆâ–‰        | 361M/1.87G [00:08<00:35, 43.0MiB/s]
 20%|â–ˆâ–‰        | 366M/1.87G [00:08<00:34, 43.2MiB/s]
 20%|â–ˆâ–‰        | 370M/1.87G [00:08<00:34, 43.3MiB/s]
 20%|â–ˆâ–ˆ        | 375M/1.87G [00:08<00:34, 43.3MiB/s]
 20%|â–ˆâ–ˆ        | 379M/1.87G [00:08<00:34, 42.7MiB/s]
 21%|â–ˆâ–ˆ        | 383M/1.87G [00:08<00:34, 43.0MiB/s]
 21%|â–ˆâ–ˆ        | 388M/1.87G [00:08<00:34, 43.2MiB/s]
 21%|â–ˆâ–ˆ        | 392M/1.87G [00:09<00:33, 43.4MiB/s]
 21%|â–ˆâ–ˆ        | 397M/1.87G [00:09<00:33, 43.4MiB/s]
 21%|â–ˆâ–ˆâ–       | 401M/1.87G [00:09<00:34, 43.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 405M/1.87G [00:09<00:34, 42.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 410M/1.87G [00:09<00:33, 43.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 414M/1.87G [00:09<00:33, 43.2MiB/s]
 22%|â–ˆâ–ˆâ–       | 419M/1.87G [00:09<00:33, 43.2MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 423M/1.87G [00:09<00:33, 43.2MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 428M/1.87G [00:09<00:33, 43.4MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 432M/1.87G [00:10<00:33, 43.2MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 436M/1.87G [00:10<00:33, 43.1MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 441M/1.87G [00:10<00:33, 43.2MiB/s]
 24%|â–ˆâ–ˆâ–       | 445M/1.87G [00:10<00:32, 43.5MiB/s]
 24%|â–ˆâ–ˆâ–       | 450M/1.87G [00:10<00:32, 43.4MiB/s]
 24%|â–ˆâ–ˆâ–       | 454M/1.87G [00:10<00:32, 43.3MiB/s]
 25%|â–ˆâ–ˆâ–       | 458M/1.87G [00:10<00:32, 43.4MiB/s]
 25%|â–ˆâ–ˆâ–       | 463M/1.87G [00:10<00:32, 43.2MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 467M/1.87G [00:10<00:49, 28.5MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 471M/1.87G [00:11<00:44, 31.6MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 476M/1.87G [00:11<00:40, 34.3MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 480M/1.87G [00:11<00:37, 36.6MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 485M/1.87G [00:11<00:36, 38.4MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 489M/1.87G [00:11<00:34, 39.7MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 494M/1.87G [00:11<00:33, 40.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 498M/1.87G [00:11<00:32, 41.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 502M/1.87G [00:11<00:32, 42.1MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 507M/1.87G [00:11<00:32, 42.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 511M/1.87G [00:12<00:31, 42.9MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 516M/1.87G [00:12<00:31, 42.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 520M/1.87G [00:12<00:31, 42.7MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 524M/1.87G [00:12<00:31, 42.9MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 529M/1.87G [00:12<00:31, 42.9MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 533M/1.87G [00:12<00:30, 43.1MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 538M/1.87G [00:12<00:30, 43.2MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 542M/1.87G [00:12<00:30, 43.2MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 547M/1.87G [00:12<00:30, 43.1MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 551M/1.87G [00:12<00:30, 43.2MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 555M/1.87G [00:13<00:30, 42.7MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 560M/1.87G [00:13<00:30, 43.1MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 564M/1.87G [00:13<00:30, 42.9MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 568M/1.87G [00:13<00:30, 42.9MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 573M/1.87G [00:13<00:30, 43.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 577M/1.87G [00:13<00:29, 43.3MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 582M/1.87G [00:13<00:29, 43.3MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 586M/1.87G [00:13<00:29, 43.2MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 591M/1.87G [00:13<00:29, 43.1MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 595M/1.87G [00:13<00:31, 40.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 600M/1.87G [00:14<00:29, 43.7MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 605M/1.87G [00:14<00:28, 43.6MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 609M/1.87G [00:14<00:28, 43.5MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 614M/1.87G [00:14<00:28, 43.5MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 618M/1.87G [00:14<00:28, 43.5MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 622M/1.87G [00:14<00:28, 43.6MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 627M/1.87G [00:14<00:28, 43.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 631M/1.87G [00:14<00:28, 42.9MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 636M/1.87G [00:14<00:28, 43.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 640M/1.87G [00:15<00:28, 43.3MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 644M/1.87G [00:15<00:28, 42.8MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 649M/1.87G [00:15<00:28, 42.9MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 653M/1.87G [00:15<00:28, 42.9MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 658M/1.87G [00:15<00:28, 43.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 662M/1.87G [00:15<00:27, 43.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 666M/1.87G [00:15<00:28, 42.9MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 671M/1.87G [00:15<00:27, 43.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 675M/1.87G [00:15<00:27, 43.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 680M/1.87G [00:15<00:27, 43.2MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 684M/1.87G [00:16<00:27, 43.4MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 688M/1.87G [00:16<00:27, 43.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 693M/1.87G [00:16<00:27, 43.2MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 697M/1.87G [00:16<00:27, 43.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 702M/1.87G [00:16<00:27, 43.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 706M/1.87G [00:16<00:26, 43.1MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 711M/1.87G [00:16<00:26, 43.2MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 715M/1.87G [00:16<00:26, 43.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 719M/1.87G [00:16<00:26, 43.2MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 724M/1.87G [00:16<00:26, 43.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 728M/1.87G [00:17<00:26, 43.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 733M/1.87G [00:17<00:26, 43.2MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 737M/1.87G [00:17<00:26, 43.3MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 742M/1.87G [00:17<00:25, 43.5MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 746M/1.87G [00:17<00:25, 43.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 750M/1.87G [00:17<00:25, 43.2MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 755M/1.87G [00:17<00:25, 43.1MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 759M/1.87G [00:17<00:25, 43.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 764M/1.87G [00:17<00:25, 43.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 768M/1.87G [00:17<00:25, 43.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 773M/1.87G [00:18<00:25, 43.0MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 777M/1.87G [00:18<00:25, 42.9MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 781M/1.87G [00:18<00:25, 42.9MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 786M/1.87G [00:18<00:25, 43.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 790M/1.87G [00:18<00:24, 43.4MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 795M/1.87G [00:18<00:24, 43.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 799M/1.87G [00:18<00:24, 43.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 803M/1.87G [00:18<00:24, 43.2MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 808M/1.87G [00:18<00:24, 43.5MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 812M/1.87G [00:18<00:24, 43.4MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 817M/1.87G [00:19<00:24, 43.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 821M/1.87G [00:19<00:24, 43.2MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 825M/1.87G [00:19<00:24, 43.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 830M/1.87G [00:19<00:24, 43.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 834M/1.87G [00:19<00:23, 43.1MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 839M/1.87G [00:19<00:23, 43.2MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 843M/1.87G [00:19<00:23, 43.3MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 848M/1.87G [00:19<00:23, 43.4MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 852M/1.87G [00:19<00:23, 43.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 856M/1.87G [00:20<00:23, 43.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 861M/1.87G [00:20<00:23, 42.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 865M/1.87G [00:20<00:23, 43.1MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 870M/1.87G [00:20<00:23, 43.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 874M/1.87G [00:20<00:23, 43.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 879M/1.87G [00:20<00:22, 43.2MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 883M/1.87G [00:20<00:22, 43.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 887M/1.87G [00:20<00:22, 43.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 892M/1.87G [00:20<00:22, 42.8MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 896M/1.87G [00:20<00:22, 42.9MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 901M/1.87G [00:21<00:22, 43.1MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 905M/1.87G [00:21<00:22, 43.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 909M/1.87G [00:21<00:22, 42.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 914M/1.87G [00:21<00:22, 42.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 918M/1.87G [00:21<00:21, 43.2MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 922M/1.87G [00:21<00:21, 43.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 927M/1.87G [00:21<00:21, 42.8MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 931M/1.87G [00:21<00:21, 43.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 936M/1.87G [00:21<00:21, 42.9MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 940M/1.87G [00:21<00:21, 42.6MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 944M/1.87G [00:22<00:21, 43.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 949M/1.87G [00:22<00:21, 42.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 953M/1.87G [00:22<00:21, 42.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 957M/1.87G [00:22<00:21, 42.8MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 962M/1.87G [00:22<00:21, 42.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 966M/1.87G [00:22<00:21, 42.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 971M/1.87G [00:22<00:20, 43.0MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 975M/1.87G [00:22<00:20, 43.1MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 980M/1.87G [00:22<00:20, 43.5MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 984M/1.87G [00:22<00:20, 43.3MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 988M/1.87G [00:23<00:20, 43.1MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 993M/1.87G [00:23<00:20, 43.2MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 997M/1.87G [00:23<00:20, 43.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.00G/1.87G [00:23<00:20, 43.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.01G/1.87G [00:23<00:19, 43.2MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.01G/1.87G [00:23<00:19, 43.3MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:23<00:19, 43.4MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:23<00:19, 43.0MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:23<00:19, 43.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.03G/1.87G [00:24<00:19, 43.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.03G/1.87G [00:24<00:19, 43.2MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.04G/1.87G [00:24<00:19, 43.1MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.04G/1.87G [00:24<00:19, 43.5MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.05G/1.87G [00:24<00:19, 43.1MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.05G/1.87G [00:24<00:19, 43.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.05G/1.87G [00:24<00:29, 27.3MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.06G/1.87G [00:24<00:19, 41.5MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.07G/1.87G [00:25<00:18, 42.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.07G/1.87G [00:25<00:18, 42.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.08G/1.87G [00:25<00:18, 42.6MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.08G/1.87G [00:25<00:18, 42.7MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.09G/1.87G [00:25<00:18, 42.8MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.09G/1.87G [00:25<00:18, 42.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.10G/1.87G [00:25<00:17, 43.0MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.10G/1.87G [00:25<00:17, 42.9MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:25<00:17, 42.7MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:25<00:17, 42.9MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:26<00:17, 43.0MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.12G/1.87G [00:26<00:17, 42.9MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.12G/1.87G [00:26<00:17, 43.0MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.13G/1.87G [00:26<00:17, 43.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.13G/1.87G [00:26<00:16, 43.4MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.14G/1.87G [00:26<00:16, 43.2MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.14G/1.87G [00:26<00:16, 42.9MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:26<00:16, 43.1MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:26<00:16, 43.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:27<00:16, 43.1MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.16G/1.87G [00:27<00:16, 43.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.16G/1.87G [00:27<00:16, 43.0MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.17G/1.87G [00:27<00:16, 43.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.17G/1.87G [00:27<00:16, 43.3MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:27<00:16, 42.9MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:27<00:15, 43.0MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:27<00:15, 43.4MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.19G/1.87G [00:27<00:15, 43.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.19G/1.87G [00:27<00:15, 43.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.20G/1.87G [00:28<00:15, 43.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.20G/1.87G [00:28<00:15, 43.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.21G/1.87G [00:28<00:15, 43.3MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.21G/1.87G [00:28<00:15, 43.5MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.22G/1.87G [00:28<00:15, 43.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.22G/1.87G [00:28<00:15, 43.0MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.22G/1.87G [00:28<00:14, 43.2MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.23G/1.87G [00:28<00:14, 43.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.23G/1.87G [00:28<00:14, 43.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.24G/1.87G [00:28<00:14, 43.3MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.24G/1.87G [00:29<00:14, 43.6MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:29<00:14, 43.2MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:29<00:14, 42.9MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.26G/1.87G [00:29<00:14, 43.1MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.26G/1.87G [00:29<00:14, 43.2MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.26G/1.87G [00:29<00:13, 43.2MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.27G/1.87G [00:29<00:13, 43.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.27G/1.87G [00:29<00:13, 43.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.28G/1.87G [00:29<00:13, 43.5MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.28G/1.87G [00:29<00:13, 43.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.29G/1.87G [00:30<00:13, 43.3MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.29G/1.87G [00:30<00:13, 43.3MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.29G/1.87G [00:30<00:13, 43.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.30G/1.87G [00:30<00:13, 43.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.30G/1.87G [00:30<00:13, 43.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.31G/1.87G [00:30<00:13, 43.1MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.31G/1.87G [00:30<00:12, 43.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:30<00:12, 43.3MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:30<00:12, 43.5MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.33G/1.87G [00:30<00:12, 43.5MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.33G/1.87G [00:31<00:12, 43.3MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.33G/1.87G [00:31<00:12, 43.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.34G/1.87G [00:31<00:12, 43.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.34G/1.87G [00:31<00:12, 43.5MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.35G/1.87G [00:31<00:12, 43.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.35G/1.87G [00:31<00:11, 43.0MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:31<00:11, 43.1MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:31<00:11, 43.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:31<00:11, 43.4MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.37G/1.87G [00:31<00:11, 43.5MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.37G/1.87G [00:32<00:11, 43.7MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.38G/1.87G [00:32<00:11, 43.3MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.38G/1.87G [00:32<00:11, 43.2MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:32<00:11, 42.8MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:32<00:11, 42.8MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.40G/1.87G [00:32<00:10, 43.3MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.40G/1.87G [00:32<00:10, 42.9MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.40G/1.87G [00:32<00:10, 42.8MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.41G/1.87G [00:32<00:10, 42.8MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.41G/1.87G [00:32<00:10, 42.6MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.42G/1.87G [00:33<00:10, 42.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.42G/1.87G [00:33<00:10, 42.9MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:33<00:10, 42.6MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:33<00:10, 42.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:33<00:10, 42.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.44G/1.87G [00:33<00:10, 42.6MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.44G/1.87G [00:33<00:09, 42.9MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.45G/1.87G [00:33<00:09, 43.0MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.45G/1.87G [00:33<00:09, 43.1MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:34<00:09, 42.0MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:34<00:09, 43.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.47G/1.87G [00:34<00:09, 43.5MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.47G/1.87G [00:34<00:09, 43.2MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.47G/1.87G [00:34<00:09, 43.4MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.48G/1.87G [00:34<00:08, 43.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.48G/1.87G [00:34<00:08, 43.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.49G/1.87G [00:34<00:08, 43.3MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.49G/1.87G [00:34<00:08, 43.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:34<00:08, 43.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:35<00:08, 43.2MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.51G/1.87G [00:35<00:08, 43.4MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.51G/1.87G [00:35<00:08, 43.6MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.51G/1.87G [00:35<00:08, 43.4MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.52G/1.87G [00:35<00:08, 43.4MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.52G/1.87G [00:35<00:07, 43.7MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:35<00:07, 43.6MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:35<00:07, 43.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.54G/1.87G [00:35<00:07, 43.5MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.54G/1.87G [00:35<00:07, 42.8MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.54G/1.87G [00:36<00:07, 42.8MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.55G/1.87G [00:36<00:07, 42.9MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.55G/1.87G [00:36<00:07, 43.0MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.56G/1.87G [00:36<00:07, 43.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.56G/1.87G [00:36<00:07, 43.4MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:36<00:06, 43.3MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:36<00:06, 42.9MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:36<00:06, 42.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:36<00:06, 42.7MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:36<00:06, 43.0MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.59G/1.87G [00:37<00:06, 42.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.59G/1.87G [00:37<00:06, 43.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:37<00:06, 43.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:37<00:06, 43.4MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.61G/1.87G [00:37<00:06, 43.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.61G/1.87G [00:37<00:05, 43.0MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.61G/1.87G [00:37<00:05, 42.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.62G/1.87G [00:37<00:05, 42.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.62G/1.87G [00:37<00:05, 42.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.63G/1.87G [00:37<00:05, 43.1MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.63G/1.87G [00:38<00:05, 42.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:38<00:05, 42.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:38<00:05, 42.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:38<00:05, 42.8MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.65G/1.87G [00:38<00:05, 43.1MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.65G/1.87G [00:38<00:04, 43.4MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.66G/1.87G [00:38<00:04, 43.1MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.66G/1.87G [00:38<00:04, 42.9MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.67G/1.87G [00:38<00:04, 43.1MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.67G/1.87G [00:38<00:04, 42.3MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.87G [00:39<00:04, 43.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.87G [00:39<00:04, 43.5MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.68G/1.87G [00:39<00:04, 41.7MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.69G/1.87G [00:39<00:04, 38.5MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.69G/1.87G [00:39<00:06, 25.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.70G/1.87G [00:39<00:04, 38.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:39<00:04, 39.5MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:40<00:03, 40.4MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:40<00:03, 41.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:40<00:03, 42.0MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:40<00:03, 42.3MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.73G/1.87G [00:40<00:03, 42.4MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.73G/1.87G [00:40<00:03, 42.2MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.74G/1.87G [00:40<00:03, 42.5MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.74G/1.87G [00:40<00:02, 42.6MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.75G/1.87G [00:40<00:02, 43.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.75G/1.87G [00:40<00:02, 42.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.75G/1.87G [00:41<00:02, 42.5MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.76G/1.87G [00:41<00:02, 42.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.76G/1.87G [00:41<00:02, 43.2MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.77G/1.87G [00:41<00:02, 43.1MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.77G/1.87G [00:41<00:02, 42.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.78G/1.87G [00:41<00:02, 43.2MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.78G/1.87G [00:41<00:02, 43.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:41<00:01, 43.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:41<00:01, 43.4MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:41<00:01, 43.0MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.80G/1.87G [00:42<00:01, 43.1MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.80G/1.87G [00:42<00:01, 43.1MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.81G/1.87G [00:42<00:01, 43.4MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.81G/1.87G [00:42<00:01, 43.3MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.82G/1.87G [00:42<00:01, 43.3MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.82G/1.87G [00:42<00:01, 43.5MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:42<00:00, 43.2MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:42<00:00, 42.9MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:42<00:00, 42.9MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.84G/1.87G [00:42<00:00, 42.9MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.84G/1.87G [00:43<00:00, 42.9MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.85G/1.87G [00:43<00:00, 43.0MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.85G/1.87G [00:43<00:00, 43.3MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:43<00:00, 42.9MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:43<00:00, 42.8MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:43<00:00, 43.0MiB/s]

  0%|          | 0.00/4.37k [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.87G/1.87G [00:44<00:00, 42.4MiB/s]

  0%|          | 0.00/361k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.37k/4.37k [00:00<00:00, 6.38kiB/s]

 18%|â–ˆâ–Š        | 66.6k/361k [00:00<00:00, 334kiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 199k/361k [00:00<00:00, 523kiB/s] 

  0%|          | 0.00/32.0 [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 361k/361k [00:01<00:00, 333kiB/s]

  0%|          | 0.00/7.75M [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.0/32.0 [00:00<00:00, 32.7iB/s]

 29%|â–ˆâ–ˆâ–‰       | 2.24M/7.75M [00:00<00:00, 22.2MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7.07M/7.75M [00:00<00:00, 37.2MiB/s]INFO:     Started server process [110094]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.75M/7.75M [00:13<00:00, 37.2MiB/s]INFO:     127.0.0.1:34316 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_to_file(text=text,
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [110094]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.75M/7.75M [00:32<00:00, 242kiB/s] 
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [110648]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:50306 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50306 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58908 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58908 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58924 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [110648]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [111073]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:59422 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59422 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34270 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44530 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48426 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41366 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40404 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59888 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57808 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57808 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [111073]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [112130]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:44318 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44318 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44318 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60602 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [112130]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")

  0%|          | 0.00/425M [00:00<?, ?iB/s]
  1%|          | 4.36M/425M [00:00<00:10, 41.0MiB/s]
  2%|â–         | 10.5M/425M [00:00<00:12, 32.8MiB/s]
  5%|â–         | 21.0M/425M [00:00<00:11, 36.6MiB/s]
  7%|â–‹         | 31.2M/425M [00:00<00:07, 52.3MiB/s]
  9%|â–‰         | 37.5M/425M [00:00<00:09, 39.8MiB/s]
 10%|â–‰         | 42.4M/425M [00:01<00:11, 33.1MiB/s]
 12%|â–ˆâ–        | 52.4M/425M [00:01<00:10, 35.0MiB/s]
 15%|â–ˆâ–        | 62.9M/425M [00:01<00:10, 36.0MiB/s]
 17%|â–ˆâ–‹        | 73.4M/425M [00:02<00:10, 33.8MiB/s]
 20%|â–ˆâ–‰        | 83.9M/425M [00:02<00:09, 36.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 94.4M/425M [00:02<00:08, 36.9MiB/s]
 25%|â–ˆâ–ˆâ–       | 105M/425M [00:02<00:08, 38.0MiB/s] 
 27%|â–ˆâ–ˆâ–‹       | 115M/425M [00:03<00:08, 36.1MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 119M/425M [00:07<00:53, 5.76MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 122M/425M [00:08<01:03, 4.79MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 124M/425M [00:09<01:05, 4.57MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 125M/425M [00:09<01:05, 4.56MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 126M/425M [00:10<01:32, 3.22MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 127M/425M [00:11<01:42, 2.91MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 128M/425M [00:11<01:39, 2.98MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 128M/425M [00:11<01:33, 3.19MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 129M/425M [00:11<01:23, 3.54MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 130M/425M [00:11<01:08, 4.30MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 131M/425M [00:11<00:51, 5.75MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 133M/425M [00:11<00:36, 7.93MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 135M/425M [00:11<00:29, 9.75MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 137M/425M [00:12<00:36, 7.80MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 147M/425M [00:12<00:15, 18.6MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 157M/425M [00:12<00:10, 25.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 168M/425M [00:12<00:08, 30.3MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178M/425M [00:13<00:07, 32.7MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/425M [00:13<00:06, 34.7MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 199M/425M [00:13<00:06, 35.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 208M/425M [00:13<00:05, 42.0MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 213M/425M [00:14<00:05, 37.3MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220M/425M [00:14<00:05, 36.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/425M [00:14<00:05, 37.3MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 241M/425M [00:14<00:04, 37.8MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 252M/425M [00:15<00:04, 38.1MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 261M/425M [00:15<00:03, 46.3MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 267M/425M [00:15<00:03, 39.9MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/425M [00:15<00:04, 35.7MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 283M/425M [00:15<00:03, 36.4MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 294M/425M [00:16<00:03, 37.3MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304M/425M [00:16<00:03, 38.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 308M/425M [00:17<00:05, 20.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 311M/425M [00:17<00:06, 18.7MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 313M/425M [00:17<00:06, 18.2MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 316M/425M [00:17<00:07, 15.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 325M/425M [00:18<00:04, 20.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 336M/425M [00:18<00:03, 26.1MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346M/425M [00:18<00:02, 28.9MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 349M/425M [00:18<00:03, 24.1MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 351M/425M [00:19<00:03, 21.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 354M/425M [00:19<00:03, 21.6MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 356M/425M [00:19<00:03, 19.2MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 358M/425M [00:19<00:04, 14.6MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 367M/425M [00:19<00:02, 20.9MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 377M/425M [00:20<00:01, 26.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 388M/425M [00:20<00:01, 29.7MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 391M/425M [00:20<00:01, 21.4MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 393M/425M [00:21<00:01, 19.1MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 395M/425M [00:21<00:01, 18.1MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 398M/425M [00:21<00:01, 18.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 400M/425M [00:21<00:01, 14.8MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 409M/425M [00:21<00:00, 22.1MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 419M/425M [00:22<00:00, 27.9MiB/s]INFO:     Started server process [112868]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:41776 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41776 - "POST /generate_audio HTTP/1.1" 200 OK

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425M/425M [00:40<00:00, 27.9MiB/s]trump, iâ€™m not going to shut up.
Character 'â€™' not found in the vocabulary. Discarding it.
iâ€™ve been a vocal user of twitter for a while now, and iâ€˜ve noticed that there are a lot of people who are very vocal on twitter.
Character 'â€˜' not found in the vocabulary. Discarding it.
INFO:     127.0.0.1:53214 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47170 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47170 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [112868]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425M/425M [03:21<00:00, 2.11MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [113881]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53590 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 280, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     127.0.0.1:53604 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 280, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     127.0.0.1:53608 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 280, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     127.0.0.1:53620 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 280, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [113881]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [114298]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:01<02:49,  1.71s/it]
  3%|â–Ž         | 3/100 [00:01<00:49,  1.98it/s]
  5%|â–Œ         | 5/100 [00:02<00:27,  3.47it/s]
  7%|â–‹         | 7/100 [00:02<00:18,  5.02it/s]
  9%|â–‰         | 9/100 [00:02<00:14,  6.42it/s]
 11%|â–ˆ         | 11/100 [00:02<00:11,  7.71it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:02<00:09,  8.89it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:02<00:08,  9.91it/s]
 17%|â–ˆâ–‹        | 17/100 [00:02<00:07, 10.63it/s]
 19%|â–ˆâ–‰        | 19/100 [00:03<00:07, 10.77it/s]
 21%|â–ˆâ–ˆ        | 21/100 [00:03<00:07, 11.17it/s]
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:03<00:06, 11.38it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 28.30it/s]

  0%|          | 0/9 [00:00<?, ?it/s]
 11%|â–ˆ         | 1/9 [00:00<00:05,  1.59it/s]
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:04,  1.73it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:03,  1.80it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:02<00:02,  1.88it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:02<00:02,  1.84it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:03<00:02,  1.31it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:05<00:01,  1.01it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:07<00:01,  1.19s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.29s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.05it/s]
INFO:     127.0.0.1:48930 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:00<00:16,  6.15it/s]
  2%|â–         | 2/100 [00:00<00:24,  4.06it/s]
  3%|â–Ž         | 3/100 [00:00<00:21,  4.60it/s]
  4%|â–         | 4/100 [00:00<00:17,  5.50it/s]
  5%|â–Œ         | 5/100 [00:00<00:14,  6.50it/s]
  6%|â–Œ         | 6/100 [00:01<00:13,  6.88it/s]
  8%|â–Š         | 8/100 [00:01<00:13,  6.99it/s]
  9%|â–‰         | 9/100 [00:01<00:12,  7.54it/s]
 11%|â–ˆ         | 11/100 [00:01<00:10,  8.32it/s]
 12%|â–ˆâ–        | 12/100 [00:01<00:11,  7.37it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:01<00:11,  7.40it/s]
 14%|â–ˆâ–        | 14/100 [00:02<00:11,  7.26it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:02<00:11,  7.55it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:02<00:10,  7.67it/s]
 17%|â–ˆâ–‹        | 17/100 [00:02<00:10,  7.77it/s]
 18%|â–ˆâ–Š        | 18/100 [00:02<00:10,  8.05it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:02<00:08,  9.13it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:02<00:08,  9.67it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:03<00:07, 10.14it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:03<00:06, 10.60it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:03<00:06, 10.76it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:03<00:06, 11.26it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:03<00:06, 11.32it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:03<00:05, 11.43it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:04<00:05, 11.68it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:04<00:05, 11.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 127.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 22.64it/s] 

  0%|          | 0/15 [00:00<?, ?it/s]
  7%|â–‹         | 1/15 [00:00<00:08,  1.58it/s]
 13%|â–ˆâ–Ž        | 2/15 [00:01<00:07,  1.67it/s]
 20%|â–ˆâ–ˆ        | 3/15 [00:01<00:06,  1.78it/s]
 27%|â–ˆâ–ˆâ–‹       | 4/15 [00:02<00:06,  1.80it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:02<00:05,  1.82it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:03<00:04,  1.82it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:03<00:04,  1.84it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:04<00:03,  1.82it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:05<00:03,  1.80it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:05<00:02,  1.81it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:06<00:02,  1.77it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:06<00:01,  1.77it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:07<00:01,  1.79it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:07<00:00,  1.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.80it/s]
INFO:     127.0.0.1:48930 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [114298]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/bark", gpu=True, half=True).to("cuda")
TypeError: TTS.__init__() got an unexpected keyword argument 'half'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [115264]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:01<01:45,  1.07s/it]
  3%|â–Ž         | 3/100 [00:01<00:31,  3.08it/s]
  5%|â–Œ         | 5/100 [00:01<00:17,  5.33it/s]
  7%|â–‹         | 7/100 [00:01<00:12,  7.55it/s]
  9%|â–‰         | 9/100 [00:01<00:09,  9.43it/s]
 11%|â–ˆ         | 11/100 [00:01<00:07, 11.20it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:01<00:07, 12.39it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:01<00:06, 13.63it/s]
 17%|â–ˆâ–‹        | 17/100 [00:02<00:05, 14.60it/s]
 19%|â–ˆâ–‰        | 19/100 [00:02<00:05, 15.08it/s]
 21%|â–ˆâ–ˆ        | 21/100 [00:02<00:05, 15.72it/s]
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:02<00:04, 16.20it/s]
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:02<00:04, 16.26it/s]
 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:02<00:04, 16.57it/s]
 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:02<00:04, 16.83it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:02<00:04, 16.69it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:02<00:03, 16.90it/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:03<00:04, 16.06it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 31.59it/s]

  0%|          | 0/14 [00:00<?, ?it/s]
  7%|â–‹         | 1/14 [00:00<00:06,  1.99it/s]
 14%|â–ˆâ–        | 2/14 [00:00<00:05,  2.10it/s]
 21%|â–ˆâ–ˆâ–       | 3/14 [00:01<00:05,  2.15it/s]
 29%|â–ˆâ–ˆâ–Š       | 4/14 [00:01<00:04,  2.17it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:02<00:04,  2.19it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 6/14 [00:02<00:03,  2.19it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:03<00:03,  2.20it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:03<00:02,  2.20it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:04<00:02,  2.20it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:04<00:01,  2.20it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:05<00:01,  2.20it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:05<00:00,  2.20it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 13/14 [00:05<00:00,  2.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.49it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.25it/s]
INFO:     127.0.0.1:59184 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:07, 12.59it/s]
  4%|â–         | 4/100 [00:00<00:06, 14.91it/s]
  6%|â–Œ         | 6/100 [00:00<00:06, 15.53it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.20it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 16.62it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.29it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.64it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.49it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.74it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:04, 16.92it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 16.71it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:01<00:04, 16.93it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:01<00:04, 17.05it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:01<00:04, 16.87it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:01<00:04, 17.03it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:01<00:03, 17.15it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:04, 16.32it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:03, 16.61it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:02<00:03, 16.85it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:02<00:03, 16.70it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:02<00:03, 16.83it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:02<00:03, 16.65it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:02<00:03, 16.83it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:02<00:03, 16.97it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 34.15it/s]

  0%|          | 0/19 [00:00<?, ?it/s]
  5%|â–Œ         | 1/19 [00:00<00:09,  1.89it/s]
 11%|â–ˆ         | 2/19 [00:01<00:08,  2.02it/s]
 16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.09it/s]
 21%|â–ˆâ–ˆ        | 4/19 [00:01<00:07,  2.14it/s]
 26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:06,  2.17it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:05,  2.18it/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:05,  2.19it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:05,  2.19it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:04<00:04,  2.18it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:04,  2.17it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:05<00:03,  2.17it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:03,  2.15it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:06<00:03,  1.95it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:06<00:02,  1.86it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:07<00:02,  1.94it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:07<00:01,  1.98it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:08<00:00,  2.02it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:08<00:00,  2.07it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:08<00:00,  2.43it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:08<00:00,  2.13it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 17.57it/s]
  4%|â–         | 4/100 [00:00<00:05, 17.24it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.71it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.98it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.13it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.65it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.86it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.64it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.81it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:04, 16.92it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 82.32it/s]

  0%|          | 0/8 [00:00<?, ?it/s]
 12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.13it/s]
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.15it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.15it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.15it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.14it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.14it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.14it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.22it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:06, 15.04it/s]
  4%|â–         | 4/100 [00:00<00:05, 16.13it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.02it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.07it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 16.37it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 15.84it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.16it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.06it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:05, 16.35it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:04, 16.56it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 16.40it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 70.84it/s]

  0%|          | 0/9 [00:00<?, ?it/s]
 11%|â–ˆ         | 1/9 [00:00<00:03,  2.11it/s]
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:03,  2.15it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:02,  2.16it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:01<00:02,  2.15it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:02<00:01,  2.16it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:02<00:01,  2.16it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:03<00:00,  2.17it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:03<00:00,  2.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.43it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.25it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 17.28it/s]
  4%|â–         | 4/100 [00:00<00:05, 17.32it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.79it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.99it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.12it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.60it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.80it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.60it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 226.47it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 84.48it/s] 

  0%|          | 0/8 [00:00<?, ?it/s]
 12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.16it/s]
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.17it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.19it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.19it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.19it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.19it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.33it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 16.57it/s]
  4%|â–         | 4/100 [00:00<00:05, 16.89it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.57it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.85it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.05it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.54it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.80it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.61it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.86it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 92.54it/s]

  0%|          | 0/7 [00:00<?, ?it/s]
 14%|â–ˆâ–        | 1/7 [00:00<00:02,  2.16it/s]
 29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:02,  2.18it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:01<00:01,  2.18it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:01<00:01,  2.18it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:02<00:00,  2.18it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:02<00:00,  2.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.34it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.25it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 17.14it/s]
  4%|â–         | 4/100 [00:00<00:05, 17.15it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.74it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.95it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.06it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.50it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.75it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.55it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.74it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:04, 16.90it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 16.64it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:01<00:04, 16.76it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:01<00:04, 16.91it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:01<00:04, 16.66it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:01<00:04, 16.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 54.53it/s]

  0%|          | 0/12 [00:00<?, ?it/s]
  8%|â–Š         | 1/12 [00:00<00:05,  2.14it/s]
 17%|â–ˆâ–‹        | 2/12 [00:00<00:04,  2.16it/s]
 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:01<00:04,  2.17it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:01<00:03,  2.17it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:02<00:03,  2.18it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:02<00:02,  2.19it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:03<00:02,  2.18it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:03<00:01,  2.18it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:04<00:01,  2.18it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:04<00:00,  2.18it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:05<00:00,  2.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:05<00:00,  2.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:05<00:00,  2.23it/s]

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:06, 15.94it/s]
  4%|â–         | 4/100 [00:00<00:05, 16.12it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.06it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.44it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 16.73it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.35it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.65it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 114.50it/s]

  0%|          | 0/6 [00:00<?, ?it/s]
 17%|â–ˆâ–‹        | 1/6 [00:00<00:02,  2.11it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:01,  2.13it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:01<00:01,  2.15it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:01<00:00,  2.17it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:02<00:00,  2.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.43it/s]
INFO:     127.0.0.1:55344 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [115264]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")

  0%|          | 0.00/347M [00:00<?, ?iB/s]
  1%|          | 3.47M/347M [00:00<00:09, 34.7MiB/s]
  3%|â–Ž         | 10.5M/347M [00:00<00:10, 32.9MiB/s]
  6%|â–Œ         | 19.8M/347M [00:00<00:06, 52.8MiB/s]
  7%|â–‹         | 25.8M/347M [00:00<00:07, 40.8MiB/s]
  9%|â–‰         | 31.5M/347M [00:00<00:09, 35.1MiB/s]
 11%|â–ˆ         | 39.0M/347M [00:00<00:07, 43.9MiB/s]
 13%|â–ˆâ–Ž        | 44.2M/347M [00:01<00:08, 37.2MiB/s]
 15%|â–ˆâ–Œ        | 52.4M/347M [00:01<00:07, 37.6MiB/s]
 18%|â–ˆâ–Š        | 62.9M/347M [00:01<00:07, 39.1MiB/s]
 21%|â–ˆâ–ˆ        | 73.4M/347M [00:01<00:06, 40.0MiB/s]
 24%|â–ˆâ–ˆâ–       | 83.9M/347M [00:02<00:06, 39.8MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 88.0M/347M [00:02<00:06, 38.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 94.4M/347M [00:02<00:06, 36.6MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 105M/347M [00:02<00:06, 37.7MiB/s] 
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 115M/347M [00:02<00:05, 38.7MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 126M/347M [00:03<00:05, 39.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 136M/347M [00:03<00:05, 38.9MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147M/347M [00:03<00:05, 39.0MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 157M/347M [00:04<00:04, 39.9MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 168M/347M [00:04<00:04, 39.3MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 178M/347M [00:04<00:04, 40.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 189M/347M [00:04<00:03, 40.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 199M/347M [00:05<00:03, 40.5MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210M/347M [00:05<00:03, 40.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 220M/347M [00:05<00:03, 40.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 231M/347M [00:05<00:02, 39.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 241M/347M [00:06<00:02, 39.3MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 252M/347M [00:06<00:02, 39.9MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 262M/347M [00:06<00:02, 40.6MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 273M/347M [00:06<00:01, 39.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 283M/347M [00:07<00:01, 39.3MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294M/347M [00:07<00:01, 39.0MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 304M/347M [00:07<00:01, 39.9MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 315M/347M [00:07<00:00, 40.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 325M/347M [00:08<00:00, 40.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 336M/347M [00:08<00:00, 40.1MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 346M/347M [00:08<00:00, 40.7MiB/s]

  0%|          | 0.00/190M [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347M/347M [00:11<00:00, 31.2MiB/s]


  0%|          | 594k/190M [00:00<00:31, 5.93MiB/s][A

  1%|          | 1.41M/190M [00:00<00:26, 7.17MiB/s][A

  1%|          | 2.31M/190M [00:00<00:23, 7.99MiB/s][A

  2%|â–         | 3.26M/190M [00:00<00:21, 8.54MiB/s][A

  2%|â–         | 4.32M/190M [00:00<00:19, 9.29MiB/s][A

  3%|â–Ž         | 5.43M/190M [00:00<00:18, 9.87MiB/s][A

  4%|â–Ž         | 6.66M/190M [00:00<00:17, 10.6MiB/s][A

  4%|â–         | 7.91M/190M [00:00<00:16, 11.2MiB/s][A

  5%|â–         | 9.24M/190M [00:00<00:15, 11.9MiB/s][A

  6%|â–Œ         | 10.5M/190M [00:01<00:22, 7.98MiB/s][A

  6%|â–‹         | 12.0M/190M [00:01<00:18, 9.49MiB/s][A

  7%|â–‹         | 13.5M/190M [00:01<00:16, 11.0MiB/s][A

  8%|â–Š         | 15.2M/190M [00:01<00:14, 12.4MiB/s][A

  9%|â–‰         | 16.9M/190M [00:01<00:12, 13.7MiB/s][A

 10%|â–‰         | 18.7M/190M [00:01<00:11, 14.7MiB/s][A

 11%|â–ˆ         | 20.5M/190M [00:01<00:10, 15.7MiB/s][A

 12%|â–ˆâ–        | 22.2M/190M [00:02<00:16, 10.5MiB/s][A

 13%|â–ˆâ–Ž        | 24.2M/190M [00:02<00:13, 12.7MiB/s][A

 14%|â–ˆâ–        | 26.3M/190M [00:02<00:11, 14.4MiB/s][A

 15%|â–ˆâ–        | 28.4M/190M [00:02<00:10, 16.0MiB/s][A

 16%|â–ˆâ–Œ        | 30.5M/190M [00:02<00:09, 17.5MiB/s][A

 17%|â–ˆâ–‹        | 32.5M/190M [00:02<00:12, 12.2MiB/s][A

 18%|â–ˆâ–Š        | 34.9M/190M [00:02<00:10, 14.7MiB/s][A

 20%|â–ˆâ–‰        | 37.3M/190M [00:02<00:09, 16.8MiB/s][A

 21%|â–ˆâ–ˆ        | 39.7M/190M [00:03<00:08, 18.6MiB/s][A

 22%|â–ˆâ–ˆâ–       | 41.9M/190M [00:03<00:11, 13.2MiB/s][A

 23%|â–ˆâ–ˆâ–Ž       | 44.6M/190M [00:03<00:09, 15.9MiB/s][A

 25%|â–ˆâ–ˆâ–       | 47.4M/190M [00:03<00:07, 18.5MiB/s][A

 26%|â–ˆâ–ˆâ–‹       | 50.1M/190M [00:03<00:06, 20.5MiB/s][A

 28%|â–ˆâ–ˆâ–Š       | 52.5M/190M [00:03<00:09, 14.8MiB/s][A

 29%|â–ˆâ–ˆâ–‰       | 55.4M/190M [00:03<00:07, 17.6MiB/s][A

 31%|â–ˆâ–ˆâ–ˆ       | 58.4M/190M [00:04<00:06, 20.5MiB/s][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 61.6M/190M [00:04<00:05, 23.0MiB/s][A

 34%|â–ˆâ–ˆâ–ˆâ–      | 64.2M/190M [00:04<00:08, 15.2MiB/s][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 66.3M/190M [00:04<00:07, 15.8MiB/s][A

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 68.3M/190M [00:04<00:07, 16.3MiB/s][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 70.3M/190M [00:04<00:07, 16.4MiB/s][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 72.3M/190M [00:04<00:06, 17.4MiB/s][A

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 74.2M/190M [00:05<00:09, 11.6MiB/s][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 77.4M/190M [00:05<00:07, 15.4MiB/s][A

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80.6M/190M [00:05<00:05, 19.1MiB/s][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83.9M/190M [00:05<00:04, 22.1MiB/s][A

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 86.5M/190M [00:05<00:06, 16.3MiB/s][A

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 89.8M/190M [00:05<00:05, 19.7MiB/s][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 93.2M/190M [00:06<00:04, 22.9MiB/s][A

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96.0M/190M [00:06<00:05, 17.1MiB/s][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 99.6M/190M [00:06<00:04, 20.7MiB/s][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103M/190M [00:06<00:03, 24.0MiB/s] [A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 106M/190M [00:06<00:04, 18.0MiB/s][A

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 110M/190M [00:06<00:03, 21.8MiB/s][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 114M/190M [00:06<00:03, 25.2MiB/s][A

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 117M/190M [00:07<00:03, 18.8MiB/s][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 120M/190M [00:07<00:03, 22.6MiB/s][A

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 125M/190M [00:07<00:02, 26.5MiB/s][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 128M/190M [00:07<00:03, 19.9MiB/s][A

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 132M/190M [00:07<00:02, 23.9MiB/s][A

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 136M/190M [00:07<00:01, 27.6MiB/s][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 139M/190M [00:08<00:02, 20.4MiB/s][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 144M/190M [00:08<00:01, 24.7MiB/s][A

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 147M/190M [00:08<00:02, 19.1MiB/s][A

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 151M/190M [00:08<00:01, 23.9MiB/s][A

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 156M/190M [00:08<00:01, 28.6MiB/s][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160M/190M [00:09<00:01, 20.0MiB/s][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 164M/190M [00:09<00:01, 24.5MiB/s][A

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 168M/190M [00:09<00:01, 19.8MiB/s][A

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 173M/190M [00:09<00:00, 24.9MiB/s][A

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 177M/190M [00:09<00:00, 29.2MiB/s][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 181M/190M [00:09<00:00, 22.4MiB/s][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 186M/190M [00:10<00:00, 27.3MiB/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 190M/190M [00:10<00:00, 21.4MiB/s][AINFO:     Started server process [116514]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)


/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [117295]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:43012 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")

  0%|          | 0.00/148M [00:00<?, ?iB/s]
  3%|â–Ž         | 4.75M/148M [00:00<00:03, 43.6MiB/s]
  7%|â–‹         | 10.5M/148M [00:00<00:04, 32.3MiB/s]
 14%|â–ˆâ–        | 21.0M/148M [00:00<00:03, 37.7MiB/s]
 21%|â–ˆâ–ˆâ–       | 31.5M/148M [00:00<00:02, 38.8MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 41.9M/148M [00:01<00:02, 39.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 52.1M/148M [00:01<00:01, 50.7MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 58.1M/148M [00:01<00:02, 41.7MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 63.1M/148M [00:01<00:02, 35.6MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 67.8M/148M [00:01<00:02, 37.5MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 72.0M/148M [00:01<00:01, 38.1MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 76.2M/148M [00:02<00:02, 27.4MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 83.9M/148M [00:02<00:02, 29.3MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94.4M/148M [00:02<00:01, 33.5MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 105M/148M [00:02<00:01, 35.6MiB/s] 
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 115M/148M [00:03<00:00, 35.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 126M/148M [00:03<00:00, 37.4MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 130M/148M [00:03<00:00, 33.4MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 133M/148M [00:04<00:00, 20.6MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 135M/148M [00:04<00:00, 19.3MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 138M/148M [00:04<00:00, 15.7MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 141M/148M [00:04<00:00, 15.4MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 145M/148M [00:04<00:00, 16.2MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 147M/148M [00:05<00:00, 13.4MiB/s]INFO:     Started server process [118749]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:47602 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:47612 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:47626 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:47636 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148M/148M [00:20<00:00, 13.4MiB/s]INFO:     127.0.0.1:47652 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48488 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48496 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48510 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48514 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48520 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48524 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48526 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48542 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:48544 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60460 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60464 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60478 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60480 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60492 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     127.0.0.1:60500 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [118749]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148M/148M [00:38<00:00, 3.84MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")

  0%|          | 0.00/146M [00:00<?, ?iB/s]
  0%|          | 261k/146M [00:00<00:57, 2.52MiB/s]
  0%|          | 523k/146M [00:00<00:56, 2.55MiB/s]
  1%|          | 785k/146M [00:00<00:56, 2.56MiB/s]
  1%|          | 1.06M/146M [00:00<00:54, 2.64MiB/s]
  1%|          | 1.60M/146M [00:00<00:40, 3.60MiB/s]
  2%|â–         | 2.23M/146M [00:00<00:31, 4.52MiB/s]
  2%|â–         | 2.93M/146M [00:00<00:26, 5.31MiB/s]
  3%|â–Ž         | 4.14M/146M [00:00<00:18, 7.46MiB/s]
  4%|â–         | 5.65M/146M [00:00<00:14, 9.82MiB/s]
  5%|â–Œ         | 7.58M/146M [00:01<00:10, 12.7MiB/s]
  6%|â–‹         | 9.42M/146M [00:01<00:09, 14.4MiB/s]
  7%|â–‹         | 10.9M/146M [00:01<00:14, 9.27MiB/s]
 10%|â–ˆ         | 14.7M/146M [00:01<00:10, 12.8MiB/s]
 13%|â–ˆâ–Ž        | 18.9M/146M [00:01<00:08, 15.5MiB/s]
 14%|â–ˆâ–        | 21.0M/146M [00:02<00:09, 12.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 31.5M/146M [00:02<00:05, 21.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 41.9M/146M [00:02<00:04, 25.6MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 44.3M/146M [00:02<00:04, 20.8MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 46.3M/146M [00:03<00:08, 12.2MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 47.8M/146M [00:03<00:08, 11.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 50.5M/146M [00:03<00:07, 13.0MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 52.2M/146M [00:03<00:07, 12.4MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 53.6M/146M [00:04<00:08, 10.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 57.8M/146M [00:04<00:05, 15.3MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 62.9M/146M [00:04<00:04, 17.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 73.4M/146M [00:04<00:02, 24.3MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 80.8M/146M [00:04<00:02, 32.1MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 84.8M/146M [00:05<00:03, 16.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94.4M/146M [00:05<00:02, 21.0MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 105M/146M [00:06<00:01, 25.4MiB/s] 
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 115M/146M [00:06<00:01, 28.9MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 120M/146M [00:06<00:01, 20.6MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 124M/146M [00:07<00:01, 20.2MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 126M/146M [00:07<00:01, 17.6MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 136M/146M [00:07<00:00, 23.1MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 145M/146M [00:07<00:00, 31.3MiB/s]INFO:     Started server process [119288]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:35118 - "POST /generate_audio HTTP/1.1" 200 OK

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146M/146M [00:20<00:00, 31.3MiB/s]INFO:     127.0.0.1:46240 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46240 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46246 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46246 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [119288]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146M/146M [01:38<00:00, 1.48MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [119834]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:51120 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51120 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34048 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [119834]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [120563]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:39384 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_to_file(text=text,
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 353, in tts
    speaker_id = self.tts_model.speaker_manager.name_to_id[speaker_name]
KeyError: 'trump'
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [120563]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [120828]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:52366 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 434, in tts
    outputs = synthesis(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 216, in synthesis
    outputs = run_model_torch(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/synthesis.py", line 52, in run_model_torch
    outputs = _func(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/models/vits.py", line 1000, in inference
    o = self.waveform_decoder((z * y_mask)[:, :, : self.max_inference_len], g=g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/vocoder/models/hifigan_generator.py", line 270, in forward
    o = o + self.cond_layer(g)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
TypeError: conv1d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)
 * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = "valid", tuple of ints dilation = 1, int groups = 1)
      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, !int!)

INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [120828]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [122812]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:40484 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     127.0.0.1:40676 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     127.0.0.1:40686 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     127.0.0.1:40690 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     127.0.0.1:40692 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [122812]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [123063]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:37806 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
TypeError: TTS.tts_with_vc_to_file() got an unexpected keyword argument 'speaker_idx'
INFO:     127.0.0.1:37808 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
TypeError: TTS.tts_with_vc_to_file() got an unexpected keyword argument 'speaker_idx'
INFO:     127.0.0.1:37824 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
TypeError: TTS.tts_with_vc_to_file() got an unexpected keyword argument 'speaker_idx'
INFO:     127.0.0.1:37838 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
TypeError: TTS.tts_with_vc_to_file() got an unexpected keyword argument 'speaker_idx'
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [123063]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [123447]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0.00/896M [00:00<?, ?iB/s]
  1%|          | 5.74M/896M [00:00<00:15, 57.4MiB/s]
  1%|â–         | 11.5M/896M [00:00<00:25, 35.4MiB/s]
  2%|â–         | 21.0M/896M [00:00<00:24, 35.5MiB/s]
  4%|â–Ž         | 31.5M/896M [00:00<00:23, 37.3MiB/s]
  4%|â–         | 39.4M/896M [00:00<00:18, 45.5MiB/s]
  5%|â–         | 44.8M/896M [00:01<00:23, 36.9MiB/s]
  6%|â–Œ         | 52.4M/896M [00:01<00:25, 33.5MiB/s]
  7%|â–‹         | 62.9M/896M [00:01<00:23, 35.7MiB/s]
  8%|â–Š         | 73.4M/896M [00:01<00:22, 36.9MiB/s]
  9%|â–‰         | 83.9M/896M [00:02<00:21, 38.3MiB/s]
 11%|â–ˆ         | 94.4M/896M [00:02<00:20, 38.9MiB/s]
 12%|â–ˆâ–        | 105M/896M [00:02<00:20, 38.6MiB/s] 
 13%|â–ˆâ–Ž        | 115M/896M [00:02<00:16, 47.1MiB/s]
 13%|â–ˆâ–Ž        | 120M/896M [00:03<00:19, 40.6MiB/s]
 14%|â–ˆâ–        | 126M/896M [00:03<00:21, 35.9MiB/s]
 15%|â–ˆâ–Œ        | 136M/896M [00:03<00:20, 37.6MiB/s]
 16%|â–ˆâ–‹        | 147M/896M [00:03<00:19, 38.4MiB/s]
 18%|â–ˆâ–Š        | 157M/896M [00:04<00:19, 38.6MiB/s]
 19%|â–ˆâ–Š        | 167M/896M [00:04<00:15, 46.9MiB/s]
 19%|â–ˆâ–‰        | 172M/896M [00:04<00:18, 39.6MiB/s]
 20%|â–ˆâ–‰        | 178M/896M [00:04<00:20, 35.3MiB/s]
 21%|â–ˆâ–ˆ        | 189M/896M [00:04<00:19, 37.1MiB/s]
 22%|â–ˆâ–ˆâ–       | 199M/896M [00:05<00:18, 37.1MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 210M/896M [00:05<00:18, 37.3MiB/s]
 24%|â–ˆâ–ˆâ–       | 218M/896M [00:05<00:15, 44.1MiB/s]
 25%|â–ˆâ–ˆâ–       | 223M/896M [00:05<00:16, 40.0MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 231M/896M [00:05<00:18, 36.8MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 241M/896M [00:06<00:17, 37.0MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 250M/896M [00:06<00:14, 45.1MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 256M/896M [00:06<00:15, 40.1MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 262M/896M [00:06<00:17, 36.8MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 271M/896M [00:06<00:13, 44.8MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 277M/896M [00:07<00:15, 40.5MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 283M/896M [00:07<00:16, 36.7MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 294M/896M [00:07<00:16, 36.9MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 298M/896M [00:07<00:21, 28.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 301M/896M [00:08<00:26, 22.5MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 304M/896M [00:08<00:29, 20.1MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 306M/896M [00:08<00:35, 16.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 315M/896M [00:08<00:25, 22.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 325M/896M [00:09<00:20, 28.4MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 335M/896M [00:09<00:14, 38.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 340M/896M [00:09<00:16, 34.2MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 346M/896M [00:09<00:17, 32.0MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 357M/896M [00:09<00:15, 34.7MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367M/896M [00:10<00:14, 36.6MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 377M/896M [00:10<00:13, 37.9MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 388M/896M [00:10<00:13, 38.5MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 398M/896M [00:10<00:12, 39.2MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 409M/896M [00:11<00:12, 39.4MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 419M/896M [00:11<00:12, 39.6MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 430M/896M [00:11<00:11, 39.9MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 440M/896M [00:11<00:11, 40.1MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 451M/896M [00:12<00:11, 40.2MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 461M/896M [00:12<00:10, 40.3MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472M/896M [00:12<00:10, 40.0MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 482M/896M [00:13<00:10, 38.4MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493M/896M [00:13<00:10, 39.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 497M/896M [00:13<00:12, 32.9MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 503M/896M [00:13<00:12, 31.5MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 514M/896M [00:14<00:11, 34.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 524M/896M [00:14<00:10, 36.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 535M/896M [00:14<00:09, 37.3MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 545M/896M [00:14<00:09, 37.9MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 556M/896M [00:15<00:08, 38.8MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 566M/896M [00:15<00:08, 38.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 570M/896M [00:17<00:27, 12.0MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 573M/896M [00:17<00:26, 12.3MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 575M/896M [00:17<00:24, 12.9MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 577M/896M [00:17<00:27, 11.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 587M/896M [00:17<00:17, 17.4MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 598M/896M [00:18<00:13, 22.1MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 607M/896M [00:18<00:09, 30.7MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 612M/896M [00:18<00:10, 28.0MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 619M/896M [00:18<00:10, 27.5MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 629M/896M [00:19<00:08, 31.3MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 640M/896M [00:19<00:07, 33.8MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 650M/896M [00:19<00:06, 35.8MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 661M/896M [00:19<00:06, 36.0MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 671M/896M [00:20<00:06, 37.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 682M/896M [00:20<00:05, 38.1MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 692M/896M [00:20<00:05, 38.3MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 703M/896M [00:20<00:04, 39.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 713M/896M [00:21<00:04, 38.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 724M/896M [00:21<00:04, 38.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 733M/896M [00:21<00:03, 45.5MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 738M/896M [00:21<00:04, 38.2MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 744M/896M [00:22<00:04, 35.0MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 755M/896M [00:22<00:03, 36.4MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 765M/896M [00:22<00:03, 37.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 776M/896M [00:22<00:03, 36.5MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 786M/896M [00:23<00:02, 37.6MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 796M/896M [00:23<00:02, 45.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 802M/896M [00:23<00:02, 40.6MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 807M/896M [00:23<00:02, 35.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 818M/896M [00:23<00:02, 37.0MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 828M/896M [00:24<00:01, 38.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 839M/896M [00:24<00:01, 38.9MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 849M/896M [00:24<00:01, 38.2MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 860M/896M [00:25<00:00, 38.8MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 870M/896M [00:25<00:00, 39.7MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 881M/896M [00:25<00:00, 39.9MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 891M/896M [00:25<00:00, 39.6MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 896M/896M [00:40<00:00, 39.6MiB/s]INFO:     127.0.0.1:47258 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37232 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37244 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37244 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37250 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37250 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50404 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55888 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55888 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [123447]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 896M/896M [03:14<00:00, 4.60MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [124885]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:51096 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 278, in _check_arguments
    raise ValueError("Model is not multi-speaker but `speaker` is provided.")
ValueError: Model is not multi-speaker but `speaker` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [124885]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [125094]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53126 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53126 - "POST /generate_audio HTTP/1.1" 200 OK
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [125640]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:54470 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [125640]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [125881]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:38898 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 347, in tts
    speaker_embedding = self.tts_model.speaker_manager.get_mean_embedding(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/managers.py", line 292, in get_mean_embedding
    embeddings = self.get_embeddings_by_name(idx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/tts/utils/managers.py", line 265, in get_embeddings_by_name
    return self.embeddings_by_names[idx]
KeyError: 'p225'
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [125881]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [126280]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:60152 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60152 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33550 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33550 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33550 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48772 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50720 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [126280]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [126906]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:45868 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 88, in generate_audio
    tts.tts_with_vc_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 508, in tts_with_vc_to_file
    wav = self.tts_with_vc(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 464, in tts_with_vc
    self.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 274, in _check_arguments
    raise ValueError("Model is multi-speaker but no `speaker` is provided.")
ValueError: Model is multi-speaker but no `speaker` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [126906]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [127366]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:35802 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35802 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59392 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [127366]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [127806]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:49242 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49242 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38872 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38872 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38872 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50308 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50308 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50308 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36380 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59572 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59572 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59572 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59572 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [127806]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [128539]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:34034 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 280, in _check_arguments
    raise ValueError("Model is not multi-lingual but `language` is provided.")
ValueError: Model is not multi-lingual but `language` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [128539]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [129013]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:00<01:31,  1.08it/s]
  3%|â–Ž         | 3/100 [00:01<00:27,  3.48it/s]
  5%|â–Œ         | 5/100 [00:01<00:16,  5.92it/s]
  7%|â–‹         | 7/100 [00:01<00:11,  8.20it/s]
  9%|â–‰         | 9/100 [00:01<00:09, 10.09it/s]
 11%|â–ˆ         | 11/100 [00:01<00:07, 11.87it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:01<00:06, 12.97it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 60.50it/s]

  0%|          | 0/5 [00:00<?, ?it/s]
 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  2.13it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.20it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:00,  2.24it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:01<00:00,  2.24it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.28it/s]
INFO:     127.0.0.1:41914 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41914 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 16.79it/s]
  4%|â–         | 4/100 [00:00<00:05, 17.18it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.76it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 17.00it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.12it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.69it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.97it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.71it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 238.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 94.60it/s] 

  0%|          | 0/7 [00:00<?, ?it/s]
 14%|â–ˆâ–        | 1/7 [00:00<00:02,  2.18it/s]
 29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:02,  2.20it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:01<00:01,  2.22it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:01<00:01,  2.22it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:02<00:00,  2.22it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:02<00:00,  2.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.28it/s]
INFO:     127.0.0.1:48376 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 16.99it/s]
  4%|â–         | 4/100 [00:00<00:05, 17.34it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.99it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 17.25it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.40it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.89it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 17.12it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:04, 16.95it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 17.06it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 234.47it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 86.24it/s] 

  0%|          | 0/8 [00:00<?, ?it/s]
 12%|â–ˆâ–Ž        | 1/8 [00:00<00:03,  2.19it/s]
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.21it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:02,  2.21it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.17it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:02<00:01,  2.20it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.21it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:03<00:00,  2.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.36it/s]
INFO:     127.0.0.1:37886 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [129013]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
INFO:     Started server process [129657]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0/100 [00:00<?, ?it/s]
  1%|          | 1/100 [00:01<01:40,  1.02s/it]
  3%|â–Ž         | 3/100 [00:01<00:30,  3.22it/s]
  5%|â–Œ         | 5/100 [00:01<00:17,  5.53it/s]
  7%|â–‹         | 7/100 [00:01<00:11,  7.78it/s]
  9%|â–‰         | 9/100 [00:01<00:09,  9.69it/s]
 11%|â–ˆ         | 11/100 [00:01<00:07, 11.48it/s]
 13%|â–ˆâ–Ž        | 13/100 [00:01<00:06, 12.61it/s]
 15%|â–ˆâ–Œ        | 15/100 [00:01<00:06, 13.85it/s]
 17%|â–ˆâ–‹        | 17/100 [00:01<00:05, 14.83it/s]
 19%|â–ˆâ–‰        | 19/100 [00:02<00:05, 15.27it/s]
 21%|â–ˆâ–ˆ        | 21/100 [00:02<00:04, 15.80it/s]
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:02<00:04, 16.27it/s]
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:02<00:04, 16.30it/s]
 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:02<00:04, 16.66it/s]
 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:02<00:04, 16.89it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:02<00:04, 16.74it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 34.32it/s]

  0%|          | 0/13 [00:00<?, ?it/s]
  8%|â–Š         | 1/13 [00:00<00:05,  2.08it/s]
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:05,  2.16it/s]
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:01<00:04,  2.19it/s]
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:01<00:04,  2.17it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:02<00:03,  2.17it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:02<00:03,  2.18it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:03<00:02,  2.19it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:03<00:02,  2.20it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:04<00:01,  2.21it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:04<00:01,  2.21it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:05<00:00,  2.22it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:05<00:00,  2.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.30it/s]
INFO:     127.0.0.1:33284 - "POST /generate_audio HTTP/1.1" 200 OK

  0%|          | 0/100 [00:00<?, ?it/s]
  2%|â–         | 2/100 [00:00<00:05, 16.72it/s]
  4%|â–         | 4/100 [00:00<00:05, 16.90it/s]
  6%|â–Œ         | 6/100 [00:00<00:05, 16.58it/s]
  8%|â–Š         | 8/100 [00:00<00:05, 16.89it/s]
 10%|â–ˆ         | 10/100 [00:00<00:05, 17.12it/s]
 12%|â–ˆâ–        | 12/100 [00:00<00:05, 16.63it/s]
 14%|â–ˆâ–        | 14/100 [00:00<00:05, 16.85it/s]
 16%|â–ˆâ–Œ        | 16/100 [00:00<00:05, 16.65it/s]
 18%|â–ˆâ–Š        | 18/100 [00:01<00:04, 16.91it/s]
 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:04, 17.03it/s]
 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:04, 16.82it/s]
 24%|â–ˆâ–ˆâ–       | 24/100 [00:01<00:04, 16.98it/s]
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:01<00:04, 17.12it/s]
 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:01<00:04, 15.98it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:01<00:04, 16.34it/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:01<00:04, 16.63it/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:02<00:04, 16.47it/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:03, 16.70it/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:02<00:03, 16.91it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 43.95it/s]

  0%|          | 0/15 [00:00<?, ?it/s]
  7%|â–‹         | 1/15 [00:00<00:06,  2.17it/s]
 13%|â–ˆâ–Ž        | 2/15 [00:00<00:05,  2.19it/s]
 20%|â–ˆâ–ˆ        | 3/15 [00:01<00:05,  2.21it/s]
 27%|â–ˆâ–ˆâ–‹       | 4/15 [00:01<00:04,  2.21it/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:02<00:04,  2.21it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:02<00:04,  2.21it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:03<00:03,  2.21it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:03<00:03,  2.22it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:04<00:02,  2.22it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:04<00:02,  2.22it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:04<00:01,  2.21it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:05<00:01,  2.21it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:05<00:00,  2.21it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:06<00:00,  2.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:06<00:00,  2.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:06<00:00,  2.29it/s]
INFO:     127.0.0.1:34790 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [129657]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [130402]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:57812 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57826 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57840 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57842 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57858 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57868 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57876 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57882 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:57894 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34520 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34528 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34536 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34546 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34554 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34562 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     127.0.0.1:34576 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 375, in tts_to_file
    self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 276, in _check_arguments
    raise ValueError("Model is multi-lingual but no `language` is provided.")
ValueError: Model is multi-lingual but no `language` is provided.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [130402]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [130661]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:55616 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40062 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40062 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46240 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50070 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50070 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36056 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [130661]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [131557]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:43998 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:43998 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44004 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53586 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53586 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53586 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58026 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58026 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58026 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [131557]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [132114]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [132114]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [132863]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [132863]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [133151]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:44546 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44546 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36322 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [133151]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [134460]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:40498 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36144 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56878 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [134460]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [135227]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:42074 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42074 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [135227]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [135737]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:36790 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36790 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36790 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37192 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57164 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57164 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [135737]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [137042]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:60006 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60006 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39454 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36108 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [137042]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [137665]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:40388 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40388 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40388 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44060 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60746 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44844 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45230 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36954 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 326, in tts
    raise ValueError(
ValueError: You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.
INFO:     127.0.0.1:45544 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45544 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42040 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44456 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60358 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38990 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [137665]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [139269]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:52358 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52358 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36432 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52482 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [139269]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [140259]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:38536 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38536 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37284 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58902 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58902 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44996 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58600 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [140259]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [141005]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53044 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60860 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60862 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55562 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54272 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [141005]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")

  0%|          | 0.00/425M [00:00<?, ?iB/s]
  1%|          | 3.58M/425M [00:00<00:11, 35.8MiB/s]
  2%|â–         | 10.5M/425M [00:00<00:12, 33.0MiB/s]
  5%|â–         | 21.0M/425M [00:00<00:11, 35.2MiB/s]
  7%|â–‹         | 31.5M/425M [00:00<00:10, 37.0MiB/s]
 10%|â–‰         | 41.9M/425M [00:01<00:10, 38.0MiB/s]
 12%|â–ˆâ–        | 52.4M/425M [00:01<00:09, 38.8MiB/s]
 15%|â–ˆâ–        | 62.9M/425M [00:01<00:09, 38.9MiB/s]
 17%|â–ˆâ–‹        | 73.4M/425M [00:01<00:09, 38.9MiB/s]
 20%|â–ˆâ–‰        | 83.9M/425M [00:02<00:08, 38.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 94.4M/425M [00:02<00:08, 39.3MiB/s]
 25%|â–ˆâ–ˆâ–       | 105M/425M [00:02<00:08, 39.7MiB/s] 
 27%|â–ˆâ–ˆâ–‹       | 115M/425M [00:02<00:07, 39.6MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 126M/425M [00:03<00:07, 39.4MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 136M/425M [00:03<00:07, 39.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 147M/425M [00:03<00:07, 39.1MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 157M/425M [00:04<00:06, 38.4MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 168M/425M [00:04<00:06, 38.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178M/425M [00:04<00:06, 38.7MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/425M [00:04<00:06, 38.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 199M/425M [00:05<00:05, 39.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 210M/425M [00:05<00:05, 38.9MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220M/425M [00:05<00:05, 39.1MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/425M [00:05<00:04, 39.6MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 241M/425M [00:06<00:04, 39.8MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 252M/425M [00:06<00:06, 26.6MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262M/425M [00:07<00:05, 29.4MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/425M [00:07<00:04, 31.6MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 283M/425M [00:07<00:04, 33.6MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 294M/425M [00:07<00:03, 35.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304M/425M [00:08<00:03, 36.8MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/425M [00:08<00:03, 36.0MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 325M/425M [00:08<00:02, 36.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 336M/425M [00:09<00:02, 37.1MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346M/425M [00:09<00:02, 36.9MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/425M [00:09<00:01, 37.6MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 367M/425M [00:09<00:01, 37.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 377M/425M [00:10<00:01, 36.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 388M/425M [00:10<00:01, 37.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 398M/425M [00:10<00:00, 37.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 409M/425M [00:11<00:00, 37.7MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 419M/425M [00:11<00:00, 38.4MiB/s]INFO:     Started server process [145608]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:44150 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40070 - "POST /generate_audio HTTP/1.1" 200 OK

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425M/425M [00:30<00:00, 38.4MiB/s]INFO:     127.0.0.1:37392 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34136 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34136 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [145608]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425M/425M [01:08<00:00, 6.18MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1161, in __call__
    return self.main(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1082, in main
    rv = self.invoke(ctx)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 1443, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/click/core.py", line 788, in invoke
    return __callback(*args, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 425, in main
    run(app, **kwargs)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/main.py", line 447, in run
    server.run()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 68, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/server.py", line 76, in serve
    config.load()
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/config.py", line 448, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 32, in <module>
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v1", gpu=True).to("cuda")
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 96, in __init__
    self.load_tts_model_by_name(model_name, vocoder_name, gpu=gpu)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 220, in load_tts_model_by_name
    model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 161, in download_model_by_name
    model_path, config_path, model_item = self.manager.download_model(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 406, in download_model
    model_item, model_full_name, model, md5sum = self._set_model_item(model_name)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/manage.py", line 319, in _set_model_item
    model_item = self.models_dict[model_type][lang][dataset][model]
KeyError: 'xtts_v1'
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > You must confirm the following:
 | > "I have purchased a commercial license from Coqui: licensing@coqui.ai"
 | > "Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml" - [y/n]
 | | > 
  0%|          | 0.00/1.87G [00:00<?, ?iB/s]
  0%|          | 9.27M/1.87G [00:00<00:20, 92.7MiB/s]
  1%|          | 20.8M/1.87G [00:00<00:17, 106MiB/s] 
  2%|â–         | 32.5M/1.87G [00:00<00:16, 111MiB/s]
  2%|â–         | 43.9M/1.87G [00:00<00:16, 112MiB/s]
  3%|â–Ž         | 55.4M/1.87G [00:00<00:16, 113MiB/s]
  4%|â–Ž         | 66.8M/1.87G [00:00<00:15, 114MiB/s]
  4%|â–         | 78.2M/1.87G [00:00<00:15, 114MiB/s]
  5%|â–         | 89.9M/1.87G [00:00<00:15, 115MiB/s]
  5%|â–Œ         | 101M/1.87G [00:00<00:15, 115MiB/s] 
  6%|â–Œ         | 113M/1.87G [00:01<00:15, 115MiB/s]
  7%|â–‹         | 125M/1.87G [00:01<00:15, 115MiB/s]
  7%|â–‹         | 136M/1.87G [00:01<00:15, 115MiB/s]
  8%|â–Š         | 148M/1.87G [00:01<00:14, 115MiB/s]
  9%|â–Š         | 159M/1.87G [00:01<00:14, 116MiB/s]
  9%|â–‰         | 171M/1.87G [00:01<00:14, 116MiB/s]
 10%|â–‰         | 182M/1.87G [00:01<00:14, 115MiB/s]
 10%|â–ˆ         | 194M/1.87G [00:01<00:14, 115MiB/s]
 11%|â–ˆ         | 205M/1.87G [00:01<00:14, 115MiB/s]
 12%|â–ˆâ–        | 217M/1.87G [00:01<00:14, 116MiB/s]
 12%|â–ˆâ–        | 229M/1.87G [00:02<00:14, 116MiB/s]
 13%|â–ˆâ–Ž        | 240M/1.87G [00:02<00:14, 116MiB/s]
 13%|â–ˆâ–Ž        | 252M/1.87G [00:02<00:13, 116MiB/s]
 14%|â–ˆâ–        | 264M/1.87G [00:02<00:13, 116MiB/s]
 15%|â–ˆâ–        | 275M/1.87G [00:02<00:13, 116MiB/s]
 15%|â–ˆâ–Œ        | 287M/1.87G [00:02<00:13, 116MiB/s]
 16%|â–ˆâ–Œ        | 298M/1.87G [00:02<00:13, 116MiB/s]
 17%|â–ˆâ–‹        | 310M/1.87G [00:02<00:13, 116MiB/s]
 17%|â–ˆâ–‹        | 322M/1.87G [00:02<00:13, 116MiB/s]
 18%|â–ˆâ–Š        | 333M/1.87G [00:02<00:13, 116MiB/s]
 18%|â–ˆâ–Š        | 345M/1.87G [00:03<00:13, 116MiB/s]
 19%|â–ˆâ–‰        | 356M/1.87G [00:03<00:13, 116MiB/s]
 20%|â–ˆâ–‰        | 368M/1.87G [00:03<00:12, 116MiB/s]
 20%|â–ˆâ–ˆ        | 380M/1.87G [00:03<00:12, 116MiB/s]
 21%|â–ˆâ–ˆ        | 391M/1.87G [00:03<00:12, 116MiB/s]
 22%|â–ˆâ–ˆâ–       | 403M/1.87G [00:03<00:12, 116MiB/s]
 22%|â–ˆâ–ˆâ–       | 415M/1.87G [00:03<00:12, 116MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 426M/1.87G [00:03<00:12, 116MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 438M/1.87G [00:03<00:12, 116MiB/s]
 24%|â–ˆâ–ˆâ–       | 449M/1.87G [00:03<00:12, 116MiB/s]
 25%|â–ˆâ–ˆâ–       | 461M/1.87G [00:04<00:12, 116MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 473M/1.87G [00:04<00:12, 116MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 484M/1.87G [00:04<00:11, 115MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 496M/1.87G [00:04<00:11, 115MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 507M/1.87G [00:04<00:11, 115MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 519M/1.87G [00:04<00:11, 116MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 530M/1.87G [00:04<00:11, 116MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 542M/1.87G [00:04<00:11, 116MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 554M/1.87G [00:04<00:11, 116MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 565M/1.87G [00:04<00:11, 116MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 577M/1.87G [00:05<00:11, 116MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 588M/1.87G [00:05<00:11, 116MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 600M/1.87G [00:05<00:10, 116MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 612M/1.87G [00:05<00:10, 116MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 623M/1.87G [00:05<00:10, 115MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 635M/1.87G [00:05<00:10, 116MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 646M/1.87G [00:05<00:10, 116MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 658M/1.87G [00:05<00:10, 116MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 670M/1.87G [00:05<00:10, 116MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 681M/1.87G [00:05<00:10, 116MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 693M/1.87G [00:06<00:10, 116MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 704M/1.87G [00:06<00:10, 116MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 716M/1.87G [00:06<00:09, 116MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 728M/1.87G [00:06<00:09, 116MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 739M/1.87G [00:06<00:09, 116MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 751M/1.87G [00:06<00:09, 115MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 763M/1.87G [00:06<00:09, 116MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 774M/1.87G [00:06<00:09, 116MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 786M/1.87G [00:06<00:09, 115MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 797M/1.87G [00:06<00:09, 115MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 809M/1.87G [00:07<00:09, 115MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 820M/1.87G [00:07<00:09, 116MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 832M/1.87G [00:07<00:08, 116MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 844M/1.87G [00:07<00:08, 116MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 855M/1.87G [00:07<00:08, 116MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 867M/1.87G [00:07<00:08, 116MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 878M/1.87G [00:07<00:08, 116MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 890M/1.87G [00:07<00:08, 116MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 902M/1.87G [00:07<00:08, 116MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 913M/1.87G [00:07<00:08, 116MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 925M/1.87G [00:08<00:08, 115MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 936M/1.87G [00:08<00:08, 116MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 948M/1.87G [00:08<00:07, 116MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 960M/1.87G [00:08<00:07, 116MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 971M/1.87G [00:08<00:07, 116MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 983M/1.87G [00:08<00:07, 116MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 994M/1.87G [00:08<00:07, 116MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.01G/1.87G [00:08<00:07, 116MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:08<00:07, 116MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.03G/1.87G [00:08<00:07, 116MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.04G/1.87G [00:09<00:07, 116MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.05G/1.87G [00:09<00:07, 115MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.06G/1.87G [00:09<00:06, 116MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.08G/1.87G [00:09<00:06, 116MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.09G/1.87G [00:09<00:06, 115MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.10G/1.87G [00:09<00:06, 115MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:09<00:06, 115MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.12G/1.87G [00:09<00:06, 115MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.13G/1.87G [00:09<00:06, 116MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:09<00:06, 116MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.16G/1.87G [00:10<00:06, 116MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.17G/1.87G [00:10<00:09, 71.1MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:10<00:08, 80.2MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.19G/1.87G [00:10<00:07, 88.3MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.20G/1.87G [00:10<00:06, 94.9MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.21G/1.87G [00:10<00:06, 100MiB/s] 
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.23G/1.87G [00:10<00:06, 105MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.24G/1.87G [00:10<00:05, 108MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:11<00:05, 110MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.26G/1.87G [00:11<00:05, 111MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.27G/1.87G [00:11<00:05, 112MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.28G/1.87G [00:11<00:05, 114MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.30G/1.87G [00:11<00:05, 114MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.31G/1.87G [00:11<00:04, 115MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:11<00:04, 115MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.33G/1.87G [00:11<00:04, 115MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.34G/1.87G [00:11<00:04, 116MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.35G/1.87G [00:11<00:04, 116MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:12<00:04, 115MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.38G/1.87G [00:12<00:04, 115MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:12<00:04, 115MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.40G/1.87G [00:12<00:04, 116MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.41G/1.87G [00:12<00:03, 116MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.42G/1.87G [00:12<00:03, 115MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:12<00:03, 115MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.45G/1.87G [00:12<00:03, 115MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:12<00:03, 115MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.47G/1.87G [00:12<00:03, 115MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.48G/1.87G [00:13<00:03, 110MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.49G/1.87G [00:13<00:03, 112MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:13<00:03, 113MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.52G/1.87G [00:13<00:03, 114MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:13<00:02, 114MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.54G/1.87G [00:13<00:02, 115MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.55G/1.87G [00:13<00:02, 115MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.56G/1.87G [00:13<00:02, 115MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:13<00:02, 115MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:13<00:02, 115MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:14<00:02, 115MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.61G/1.87G [00:14<00:02, 116MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.62G/1.87G [00:14<00:02, 106MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.63G/1.87G [00:14<00:02, 109MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:14<00:02, 111MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.65G/1.87G [00:14<00:01, 112MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.67G/1.87G [00:14<00:01, 113MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.87G [00:14<00:01, 112MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.69G/1.87G [00:14<00:01, 110MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.70G/1.87G [00:14<00:01, 112MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:15<00:01, 113MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:15<00:01, 113MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.73G/1.87G [00:15<00:01, 114MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.75G/1.87G [00:15<00:01, 114MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.76G/1.87G [00:15<00:00, 115MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.77G/1.87G [00:15<00:00, 115MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.78G/1.87G [00:15<00:00, 115MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:15<00:00, 115MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.80G/1.87G [00:15<00:00, 115MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.81G/1.87G [00:16<00:00, 103MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:16<00:00, 109MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.84G/1.87G [00:16<00:00, 111MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.85G/1.87G [00:16<00:00, 112MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:16<00:00, 113MiB/s]

  0%|          | 0.00/4.70k [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.87G/1.87G [00:16<00:00, 111MiB/s]

  0%|          | 0.00/294k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.70k/4.70k [00:00<00:00, 6.62kiB/s]

 23%|â–ˆâ–ˆâ–Ž       | 66.6k/294k [00:00<00:00, 328kiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 206k/294k [00:00<00:00, 535kiB/s] 

  0%|          | 0.00/64.0 [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 294k/294k [00:01<00:00, 265kiB/s]
INFO:     Started server process [146584]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:51472 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51472 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46432 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [146584]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64.0/64.0 [01:42<00:00, 1.60s/iB]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
 > You must confirm the following:
 | > "I have purchased a commercial license from Coqui: licensing@coqui.ai"
 | > "Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml" - [y/n]
 | | > 
  0%|          | 0.00/1.87G [00:00<?, ?iB/s]
  0%|          | 4.45M/1.87G [00:00<00:42, 44.0MiB/s]
  0%|          | 8.86M/1.87G [00:00<00:42, 44.0MiB/s]
  1%|          | 13.3M/1.87G [00:00<00:42, 43.5MiB/s]
  1%|          | 17.6M/1.87G [00:00<00:42, 43.1MiB/s]
  1%|          | 22.0M/1.87G [00:00<00:42, 43.0MiB/s]
  1%|â–         | 26.3M/1.87G [00:00<00:42, 42.8MiB/s]
  2%|â–         | 30.7M/1.87G [00:00<00:42, 42.9MiB/s]
  2%|â–         | 35.1M/1.87G [00:00<00:42, 43.2MiB/s]
  2%|â–         | 39.6M/1.87G [00:00<00:42, 43.2MiB/s]
  2%|â–         | 44.0M/1.87G [00:01<00:42, 43.3MiB/s]
  3%|â–Ž         | 48.5M/1.87G [00:01<00:41, 43.4MiB/s]
  3%|â–Ž         | 53.0M/1.87G [00:01<00:41, 43.5MiB/s]
  3%|â–Ž         | 57.3M/1.87G [00:01<00:41, 43.5MiB/s]
  3%|â–Ž         | 61.6M/1.87G [00:01<00:41, 43.1MiB/s]
  4%|â–Ž         | 66.1M/1.87G [00:01<00:41, 43.0MiB/s]
  4%|â–         | 70.5M/1.87G [00:01<00:41, 43.2MiB/s]
  4%|â–         | 75.0M/1.87G [00:01<00:41, 43.2MiB/s]
  4%|â–         | 79.4M/1.87G [00:01<00:41, 43.2MiB/s]
  4%|â–         | 83.9M/1.87G [00:01<00:41, 43.4MiB/s]
  5%|â–         | 88.2M/1.87G [00:02<00:43, 41.0MiB/s]
  5%|â–         | 92.5M/1.87G [00:02<00:42, 41.5MiB/s]
  5%|â–Œ         | 96.8M/1.87G [00:02<00:42, 41.9MiB/s]
  5%|â–Œ         | 101M/1.87G [00:02<00:41, 42.2MiB/s] 
  6%|â–Œ         | 105M/1.87G [00:02<00:41, 42.2MiB/s]
  6%|â–Œ         | 110M/1.87G [00:02<00:41, 42.6MiB/s]
  6%|â–Œ         | 114M/1.87G [00:02<00:40, 42.9MiB/s]
  6%|â–‹         | 119M/1.87G [00:02<00:40, 43.0MiB/s]
  7%|â–‹         | 123M/1.87G [00:02<00:40, 43.4MiB/s]
  7%|â–‹         | 128M/1.87G [00:02<00:43, 39.8MiB/s]
  7%|â–‹         | 132M/1.87G [00:03<00:43, 40.3MiB/s]
  7%|â–‹         | 136M/1.87G [00:03<00:42, 41.2MiB/s]
  8%|â–Š         | 141M/1.87G [00:03<00:41, 42.1MiB/s]
  8%|â–Š         | 145M/1.87G [00:03<00:41, 42.0MiB/s]
  8%|â–Š         | 149M/1.87G [00:03<00:40, 42.2MiB/s]
  8%|â–Š         | 154M/1.87G [00:03<00:40, 42.4MiB/s]
  8%|â–Š         | 158M/1.87G [00:03<00:40, 42.7MiB/s]
  9%|â–Š         | 162M/1.87G [00:03<00:39, 43.0MiB/s]
  9%|â–‰         | 167M/1.87G [00:03<00:39, 42.7MiB/s]
  9%|â–‰         | 171M/1.87G [00:04<00:42, 40.1MiB/s]
  9%|â–‰         | 175M/1.87G [00:04<00:41, 40.9MiB/s]
 10%|â–‰         | 180M/1.87G [00:04<00:40, 41.2MiB/s]
 10%|â–‰         | 184M/1.87G [00:04<00:40, 41.7MiB/s]
 10%|â–ˆ         | 188M/1.87G [00:04<00:39, 42.3MiB/s]
 10%|â–ˆ         | 193M/1.87G [00:04<00:39, 42.4MiB/s]
 11%|â–ˆ         | 197M/1.87G [00:04<00:39, 42.6MiB/s]
 11%|â–ˆ         | 202M/1.87G [00:04<00:38, 42.8MiB/s]
 11%|â–ˆ         | 206M/1.87G [00:04<00:38, 42.8MiB/s]
 11%|â–ˆâ–        | 210M/1.87G [00:04<00:41, 40.3MiB/s]
 11%|â–ˆâ–        | 215M/1.87G [00:05<00:40, 41.2MiB/s]
 12%|â–ˆâ–        | 219M/1.87G [00:05<00:39, 41.6MiB/s]
 12%|â–ˆâ–        | 223M/1.87G [00:05<00:39, 42.0MiB/s]
 12%|â–ˆâ–        | 228M/1.87G [00:05<00:39, 42.0MiB/s]
 12%|â–ˆâ–        | 232M/1.87G [00:05<00:38, 42.7MiB/s]
 13%|â–ˆâ–Ž        | 236M/1.87G [00:05<00:38, 42.3MiB/s]
 13%|â–ˆâ–Ž        | 241M/1.87G [00:05<00:38, 42.6MiB/s]
 13%|â–ˆâ–Ž        | 245M/1.87G [00:05<00:38, 42.7MiB/s]
 13%|â–ˆâ–Ž        | 249M/1.87G [00:05<00:38, 42.6MiB/s]
 14%|â–ˆâ–Ž        | 254M/1.87G [00:06<00:40, 40.2MiB/s]
 14%|â–ˆâ–        | 258M/1.87G [00:06<00:39, 41.1MiB/s]
 14%|â–ˆâ–        | 262M/1.87G [00:06<00:38, 41.9MiB/s]
 14%|â–ˆâ–        | 267M/1.87G [00:06<00:37, 42.4MiB/s]
 15%|â–ˆâ–        | 271M/1.87G [00:06<00:37, 42.2MiB/s]
 15%|â–ˆâ–        | 275M/1.87G [00:06<00:37, 42.0MiB/s]
 15%|â–ˆâ–        | 280M/1.87G [00:06<00:37, 42.6MiB/s]
 15%|â–ˆâ–Œ        | 284M/1.87G [00:06<00:37, 42.2MiB/s]
 15%|â–ˆâ–Œ        | 288M/1.87G [00:06<00:37, 42.4MiB/s]
 16%|â–ˆâ–Œ        | 293M/1.87G [00:06<00:36, 42.7MiB/s]
 16%|â–ˆâ–Œ        | 297M/1.87G [00:07<00:39, 40.2MiB/s]
 16%|â–ˆâ–Œ        | 301M/1.87G [00:07<00:38, 41.0MiB/s]
 16%|â–ˆâ–‹        | 306M/1.87G [00:07<00:37, 41.3MiB/s]
 17%|â–ˆâ–‹        | 310M/1.87G [00:07<00:36, 42.2MiB/s]
 17%|â–ˆâ–‹        | 314M/1.87G [00:07<00:37, 42.0MiB/s]
 17%|â–ˆâ–‹        | 319M/1.87G [00:07<00:36, 42.3MiB/s]
 17%|â–ˆâ–‹        | 323M/1.87G [00:07<00:36, 42.7MiB/s]
 18%|â–ˆâ–Š        | 327M/1.87G [00:07<00:36, 42.7MiB/s]
 18%|â–ˆâ–Š        | 332M/1.87G [00:07<00:36, 42.7MiB/s]
 18%|â–ˆâ–Š        | 336M/1.87G [00:07<00:38, 40.2MiB/s]
 18%|â–ˆâ–Š        | 341M/1.87G [00:08<00:37, 40.9MiB/s]
 18%|â–ˆâ–Š        | 345M/1.87G [00:08<00:36, 41.8MiB/s]
 19%|â–ˆâ–Š        | 349M/1.87G [00:08<00:36, 41.8MiB/s]
 19%|â–ˆâ–‰        | 353M/1.87G [00:08<00:36, 42.0MiB/s]
 19%|â–ˆâ–‰        | 358M/1.87G [00:08<00:35, 42.5MiB/s]
 19%|â–ˆâ–‰        | 362M/1.87G [00:08<00:35, 42.7MiB/s]
 20%|â–ˆâ–‰        | 367M/1.87G [00:08<00:35, 42.8MiB/s]
 20%|â–ˆâ–‰        | 371M/1.87G [00:08<00:34, 42.8MiB/s]
 20%|â–ˆâ–ˆ        | 376M/1.87G [00:08<00:34, 43.0MiB/s]
 20%|â–ˆâ–ˆ        | 380M/1.87G [00:09<00:37, 40.1MiB/s]
 21%|â–ˆâ–ˆ        | 384M/1.87G [00:09<00:36, 40.7MiB/s]
 21%|â–ˆâ–ˆ        | 389M/1.87G [00:09<00:35, 41.3MiB/s]
 21%|â–ˆâ–ˆ        | 393M/1.87G [00:09<00:35, 41.8MiB/s]
 21%|â–ˆâ–ˆâ–       | 397M/1.87G [00:09<00:34, 42.0MiB/s]
 22%|â–ˆâ–ˆâ–       | 402M/1.87G [00:09<00:34, 42.3MiB/s]
 22%|â–ˆâ–ˆâ–       | 406M/1.87G [00:09<00:34, 42.7MiB/s]
 22%|â–ˆâ–ˆâ–       | 411M/1.87G [00:09<00:33, 42.9MiB/s]
 22%|â–ˆâ–ˆâ–       | 415M/1.87G [00:09<00:33, 42.9MiB/s]
 22%|â–ˆâ–ˆâ–       | 419M/1.87G [00:09<00:33, 42.7MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 424M/1.87G [00:10<00:35, 40.2MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 428M/1.87G [00:10<00:35, 40.9MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 432M/1.87G [00:10<00:34, 41.6MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 437M/1.87G [00:10<00:34, 41.8MiB/s]
 24%|â–ˆâ–ˆâ–Ž       | 441M/1.87G [00:10<00:33, 42.2MiB/s]
 24%|â–ˆâ–ˆâ–       | 446M/1.87G [00:10<00:33, 42.6MiB/s]
 24%|â–ˆâ–ˆâ–       | 450M/1.87G [00:10<00:33, 42.3MiB/s]
 24%|â–ˆâ–ˆâ–       | 454M/1.87G [00:10<00:33, 42.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 459M/1.87G [00:10<00:32, 43.1MiB/s]
 25%|â–ˆâ–ˆâ–       | 463M/1.87G [00:10<00:34, 40.2MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 467M/1.87G [00:11<00:34, 41.0MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 472M/1.87G [00:11<00:33, 41.8MiB/s]
 25%|â–ˆâ–ˆâ–Œ       | 476M/1.87G [00:11<00:32, 42.3MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 481M/1.87G [00:11<00:32, 42.8MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 485M/1.87G [00:11<00:32, 42.6MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 489M/1.87G [00:11<00:32, 42.8MiB/s]
 26%|â–ˆâ–ˆâ–‹       | 494M/1.87G [00:11<00:31, 43.0MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 498M/1.87G [00:11<00:31, 43.1MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 503M/1.87G [00:11<00:31, 43.3MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 507M/1.87G [00:12<00:34, 39.2MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 511M/1.87G [00:12<00:33, 40.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 516M/1.87G [00:12<00:51, 26.2MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 525M/1.87G [00:12<00:34, 39.5MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 530M/1.87G [00:12<00:33, 40.3MiB/s]
 29%|â–ˆâ–ˆâ–Š       | 534M/1.87G [00:12<00:32, 40.5MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 539M/1.87G [00:12<00:32, 41.1MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 543M/1.87G [00:12<00:31, 41.8MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 548M/1.87G [00:13<00:31, 42.1MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 552M/1.87G [00:13<00:31, 42.0MiB/s]
 30%|â–ˆâ–ˆâ–‰       | 557M/1.87G [00:13<00:31, 42.2MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 561M/1.87G [00:13<00:30, 42.6MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 565M/1.87G [00:13<00:30, 42.7MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 570M/1.87G [00:13<00:30, 42.7MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 574M/1.87G [00:13<00:30, 42.9MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 579M/1.87G [00:13<00:29, 43.0MiB/s]
 31%|â–ˆâ–ˆâ–ˆ       | 583M/1.87G [00:13<00:29, 43.2MiB/s]
 31%|â–ˆâ–ˆâ–ˆâ–      | 587M/1.87G [00:14<00:30, 41.6MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 592M/1.87G [00:14<00:29, 43.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 597M/1.87G [00:14<00:29, 43.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 601M/1.87G [00:14<00:29, 43.3MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 605M/1.87G [00:14<00:29, 42.8MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 610M/1.87G [00:14<00:29, 43.0MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 614M/1.87G [00:14<00:29, 43.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 618M/1.87G [00:14<00:28, 43.1MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 623M/1.87G [00:14<00:28, 43.3MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 627M/1.87G [00:14<00:28, 43.2MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 632M/1.87G [00:15<00:28, 43.3MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 636M/1.87G [00:15<00:28, 43.3MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 641M/1.87G [00:15<00:28, 43.5MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 645M/1.87G [00:15<00:28, 43.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 649M/1.87G [00:15<00:28, 43.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–      | 654M/1.87G [00:15<00:28, 42.9MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 658M/1.87G [00:15<00:28, 42.7MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 662M/1.87G [00:15<00:28, 42.8MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 667M/1.87G [00:15<00:27, 43.1MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 671M/1.87G [00:15<00:28, 42.3MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 675M/1.87G [00:16<00:27, 42.6MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 680M/1.87G [00:16<00:27, 42.7MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 684M/1.87G [00:16<00:27, 43.0MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 688M/1.87G [00:16<00:27, 42.8MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 693M/1.87G [00:16<00:27, 43.1MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 697M/1.87G [00:16<00:27, 42.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 701M/1.87G [00:16<00:27, 42.9MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 706M/1.87G [00:16<00:27, 43.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 710M/1.87G [00:16<00:27, 42.8MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 714M/1.87G [00:16<00:28, 40.0MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 719M/1.87G [00:17<00:28, 40.8MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 723M/1.87G [00:17<00:27, 41.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 727M/1.87G [00:17<00:27, 41.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 732M/1.87G [00:17<00:27, 41.9MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 736M/1.87G [00:17<00:26, 42.2MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 741M/1.87G [00:17<00:26, 42.4MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 745M/1.87G [00:17<00:26, 42.7MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 749M/1.87G [00:17<00:26, 42.9MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 754M/1.87G [00:17<00:25, 43.0MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 758M/1.87G [00:18<00:27, 40.2MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 763M/1.87G [00:18<00:26, 41.0MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 767M/1.87G [00:18<00:26, 41.4MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 771M/1.87G [00:18<00:26, 41.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 776M/1.87G [00:18<00:25, 42.2MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 780M/1.87G [00:18<00:25, 42.8MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 784M/1.87G [00:18<00:25, 42.5MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 789M/1.87G [00:18<00:25, 42.7MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 793M/1.87G [00:18<00:25, 43.0MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 798M/1.87G [00:18<00:26, 40.1MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 802M/1.87G [00:19<00:53, 20.0MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 805M/1.87G [00:19<01:14, 14.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 816M/1.87G [00:19<00:37, 28.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 827M/1.87G [00:20<00:26, 39.9MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 833M/1.87G [00:20<00:25, 40.6MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 839M/1.87G [00:20<00:24, 41.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 844M/1.87G [00:20<00:24, 41.8MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 850M/1.87G [00:20<00:24, 42.0MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 854M/1.87G [00:20<00:23, 42.3MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 859M/1.87G [00:20<00:23, 42.8MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 864M/1.87G [00:20<00:23, 42.8MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 868M/1.87G [00:21<00:23, 43.1MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 873M/1.87G [00:21<00:23, 42.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 877M/1.87G [00:21<00:23, 43.0MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 881M/1.87G [00:21<00:23, 42.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 886M/1.87G [00:21<00:22, 42.7MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 890M/1.87G [00:21<00:22, 43.0MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 895M/1.87G [00:21<00:22, 43.2MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 899M/1.87G [00:21<00:22, 43.3MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 904M/1.87G [00:21<00:22, 43.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 908M/1.87G [00:21<00:21, 43.6MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 912M/1.87G [00:22<00:21, 43.4MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 917M/1.87G [00:22<00:22, 43.0MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 921M/1.87G [00:22<00:21, 43.1MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 926M/1.87G [00:22<00:21, 43.2MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 930M/1.87G [00:22<00:21, 43.1MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 934M/1.87G [00:22<00:21, 42.8MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 939M/1.87G [00:22<00:21, 42.7MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 943M/1.87G [00:22<00:21, 42.7MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 947M/1.87G [00:22<00:21, 42.8MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 952M/1.87G [00:22<00:21, 43.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 956M/1.87G [00:23<00:21, 43.1MiB/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 961M/1.87G [00:23<00:21, 43.1MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 965M/1.87G [00:23<00:20, 43.2MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 970M/1.87G [00:23<00:20, 43.4MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 974M/1.87G [00:23<00:20, 43.4MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 978M/1.87G [00:23<00:32, 27.5MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 990M/1.87G [00:23<00:19, 45.9MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 996M/1.87G [00:23<00:18, 47.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.00G/1.87G [00:24<00:18, 46.5MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.01G/1.87G [00:24<00:18, 45.5MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.01G/1.87G [00:24<00:19, 44.9MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:24<00:19, 44.1MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.02G/1.87G [00:24<00:19, 44.0MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.03G/1.87G [00:24<00:19, 43.2MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.03G/1.87G [00:24<00:19, 42.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.03G/1.87G [00:24<00:19, 43.0MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.04G/1.87G [00:24<00:19, 43.2MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.04G/1.87G [00:25<00:19, 42.9MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.05G/1.87G [00:25<00:19, 43.1MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.05G/1.87G [00:25<00:18, 43.3MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.06G/1.87G [00:25<00:18, 43.1MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.06G/1.87G [00:25<00:18, 42.7MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.07G/1.87G [00:25<00:18, 42.9MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.07G/1.87G [00:25<00:18, 43.0MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.07G/1.87G [00:25<00:18, 43.1MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.08G/1.87G [00:25<00:18, 43.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.08G/1.87G [00:26<00:18, 43.3MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.09G/1.87G [00:26<00:17, 43.4MiB/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.09G/1.87G [00:26<00:17, 43.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.10G/1.87G [00:26<00:17, 43.1MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.10G/1.87G [00:26<00:17, 43.3MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:26<00:17, 43.2MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:26<00:17, 42.7MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.11G/1.87G [00:26<00:17, 43.2MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.12G/1.87G [00:26<00:17, 43.1MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.12G/1.87G [00:26<00:17, 42.8MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.13G/1.87G [00:27<00:17, 42.9MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.13G/1.87G [00:27<00:17, 43.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.14G/1.87G [00:27<00:16, 43.1MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.14G/1.87G [00:27<00:16, 43.0MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.14G/1.87G [00:27<00:16, 43.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:27<00:16, 43.2MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.15G/1.87G [00:27<00:16, 43.0MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.16G/1.87G [00:27<00:16, 42.9MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.16G/1.87G [00:27<00:16, 42.9MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.17G/1.87G [00:27<00:16, 43.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.17G/1.87G [00:28<00:16, 43.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:28<00:16, 42.9MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:28<00:15, 43.4MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.18G/1.87G [00:28<00:15, 43.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.19G/1.87G [00:28<00:15, 43.1MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.19G/1.87G [00:28<00:15, 42.7MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.20G/1.87G [00:28<00:15, 42.8MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.20G/1.87G [00:28<00:15, 43.1MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.21G/1.87G [00:28<00:15, 43.0MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.21G/1.87G [00:28<00:15, 43.4MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.21G/1.87G [00:29<00:15, 43.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.22G/1.87G [00:29<00:15, 43.2MiB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.22G/1.87G [00:29<00:14, 43.6MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.23G/1.87G [00:29<00:14, 43.4MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.23G/1.87G [00:29<00:14, 43.3MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.24G/1.87G [00:29<00:14, 43.2MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.24G/1.87G [00:29<00:14, 42.9MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:29<00:14, 43.0MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:29<00:14, 43.2MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.25G/1.87G [00:29<00:14, 43.0MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.26G/1.87G [00:30<00:14, 43.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.26G/1.87G [00:30<00:13, 43.4MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.27G/1.87G [00:30<00:14, 42.8MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.27G/1.87G [00:30<00:13, 43.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.28G/1.87G [00:30<00:13, 43.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.28G/1.87G [00:30<00:13, 43.2MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.28G/1.87G [00:30<00:13, 43.0MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.29G/1.87G [00:30<00:13, 43.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.29G/1.87G [00:30<00:13, 43.2MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.30G/1.87G [00:30<00:13, 43.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.30G/1.87G [00:31<00:13, 43.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.31G/1.87G [00:31<00:12, 43.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.31G/1.87G [00:31<00:12, 43.0MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:31<00:12, 42.8MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:31<00:12, 43.2MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.32G/1.87G [00:31<00:12, 43.1MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.33G/1.87G [00:31<00:12, 42.9MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.33G/1.87G [00:31<00:12, 42.9MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.34G/1.87G [00:31<00:12, 42.9MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.34G/1.87G [00:32<00:12, 43.1MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.35G/1.87G [00:32<00:12, 43.4MiB/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.35G/1.87G [00:32<00:11, 43.4MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.35G/1.87G [00:32<00:11, 43.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:32<00:11, 43.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.36G/1.87G [00:32<00:11, 43.3MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.37G/1.87G [00:32<00:11, 43.2MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.37G/1.87G [00:32<00:11, 43.3MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.38G/1.87G [00:32<00:11, 43.3MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.38G/1.87G [00:32<00:11, 43.2MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:33<00:11, 43.2MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:33<00:11, 43.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.39G/1.87G [00:33<00:10, 43.3MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.40G/1.87G [00:33<00:10, 43.3MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.40G/1.87G [00:33<00:10, 43.2MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.41G/1.87G [00:33<00:10, 43.1MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.41G/1.87G [00:33<00:10, 43.4MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.42G/1.87G [00:33<00:10, 43.3MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.42G/1.87G [00:33<00:10, 43.2MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:33<00:10, 43.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:34<00:10, 42.8MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.43G/1.87G [00:34<00:10, 42.6MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.44G/1.87G [00:34<00:09, 43.0MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.44G/1.87G [00:34<00:09, 43.4MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.45G/1.87G [00:34<00:09, 43.0MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.45G/1.87G [00:34<00:09, 42.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:34<00:09, 42.7MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:34<00:09, 43.2MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.46G/1.87G [00:34<00:09, 42.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.47G/1.87G [00:34<00:09, 40.3MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.47G/1.87G [00:35<00:09, 40.9MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.48G/1.87G [00:35<00:09, 41.6MiB/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.48G/1.87G [00:35<00:09, 42.2MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.49G/1.87G [00:35<00:08, 42.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.49G/1.87G [00:35<00:08, 42.7MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:35<00:08, 42.5MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:35<00:08, 42.8MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.50G/1.87G [00:35<00:08, 43.1MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.51G/1.87G [00:35<00:08, 42.7MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.51G/1.87G [00:36<00:08, 39.7MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.52G/1.87G [00:36<00:09, 38.0MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.52G/1.87G [00:36<00:08, 41.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:36<00:08, 42.2MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:36<00:07, 42.3MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.53G/1.87G [00:36<00:07, 42.8MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.54G/1.87G [00:36<00:07, 42.7MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.54G/1.87G [00:36<00:07, 42.6MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.55G/1.87G [00:36<00:07, 42.9MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.55G/1.87G [00:36<00:07, 40.3MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.56G/1.87G [00:37<00:07, 41.1MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.56G/1.87G [00:37<00:07, 41.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:37<00:07, 42.3MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:37<00:07, 42.6MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.57G/1.87G [00:37<00:06, 42.5MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:37<00:06, 42.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.58G/1.87G [00:37<00:06, 42.7MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.59G/1.87G [00:37<00:06, 42.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.59G/1.87G [00:37<00:06, 42.9MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:38<00:06, 39.7MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:38<00:06, 40.4MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.60G/1.87G [00:38<00:06, 41.3MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.61G/1.87G [00:38<00:06, 42.2MiB/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.61G/1.87G [00:38<00:06, 42.0MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.62G/1.87G [00:38<00:05, 42.4MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.62G/1.87G [00:38<00:05, 42.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.63G/1.87G [00:38<00:05, 42.7MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.63G/1.87G [00:38<00:05, 42.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:38<00:05, 42.7MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:39<00:05, 40.2MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.64G/1.87G [00:39<00:05, 40.9MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.65G/1.87G [00:39<00:05, 41.4MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.65G/1.87G [00:39<00:05, 42.2MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.66G/1.87G [00:39<00:04, 42.5MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.66G/1.87G [00:39<00:04, 42.8MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.67G/1.87G [00:39<00:04, 42.7MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.67G/1.87G [00:39<00:04, 42.9MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.87G [00:39<00:04, 43.3MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.87G [00:40<00:04, 39.6MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.68G/1.87G [00:40<00:04, 40.4MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.69G/1.87G [00:40<00:04, 40.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.69G/1.87G [00:40<00:04, 41.8MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.70G/1.87G [00:40<00:04, 41.7MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.70G/1.87G [00:40<00:03, 42.3MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:40<00:03, 42.8MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:40<00:03, 42.8MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.71G/1.87G [00:40<00:03, 42.9MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:40<00:03, 42.6MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.72G/1.87G [00:41<00:03, 40.2MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.73G/1.87G [00:41<00:03, 38.2MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.73G/1.87G [00:41<00:03, 42.3MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.74G/1.87G [00:41<00:03, 42.7MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.74G/1.87G [00:41<00:02, 42.8MiB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.75G/1.87G [00:41<00:02, 42.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.75G/1.87G [00:41<00:02, 42.8MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.75G/1.87G [00:41<00:02, 43.0MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.76G/1.87G [00:41<00:02, 43.4MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.76G/1.87G [00:41<00:02, 40.2MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.77G/1.87G [00:42<00:02, 40.7MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.77G/1.87G [00:42<00:02, 41.5MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.78G/1.87G [00:42<00:02, 42.3MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.78G/1.87G [00:42<00:02, 42.1MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:42<00:01, 42.3MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:42<00:01, 42.6MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.79G/1.87G [00:42<00:01, 42.4MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.80G/1.87G [00:42<00:01, 42.8MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.80G/1.87G [00:42<00:01, 43.0MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.81G/1.87G [00:43<00:01, 39.6MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.81G/1.87G [00:43<00:01, 40.7MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.82G/1.87G [00:43<00:01, 41.4MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.82G/1.87G [00:43<00:01, 42.0MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.82G/1.87G [00:43<00:01, 42.0MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:43<00:00, 42.5MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.83G/1.87G [00:43<00:00, 42.8MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.84G/1.87G [00:43<00:00, 43.0MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.84G/1.87G [00:43<00:00, 43.4MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.85G/1.87G [00:43<00:00, 40.2MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.85G/1.87G [00:44<00:00, 40.8MiB/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:44<00:00, 41.5MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:44<00:00, 41.7MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.86G/1.87G [00:44<00:00, 41.9MiB/s]

  0%|          | 0.00/4.37k [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.87G/1.87G [00:45<00:00, 41.2MiB/s]

  0%|          | 0.00/361k [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.37k/4.37k [00:00<00:00, 6.35kiB/s]

 18%|â–ˆâ–Š        | 66.6k/361k [00:00<00:00, 324kiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 198k/361k [00:00<00:00, 504kiB/s] 

  0%|          | 0.00/32.0 [00:00<?, ?iB/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 361k/361k [00:01<00:00, 333kiB/s]

  0%|          | 0.00/7.75M [00:00<?, ?iB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.0/32.0 [00:00<00:00, 32.6iB/s]

 19%|â–ˆâ–‰        | 1.49M/7.75M [00:00<00:00, 14.9MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 6.78M/7.75M [00:00<00:00, 37.2MiB/s]INFO:     Started server process [147237]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.75M/7.75M [00:11<00:00, 37.2MiB/s]INFO:     127.0.0.1:41402 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41402 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42100 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59012 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59012 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [147237]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.75M/7.75M [00:52<00:00, 148kiB/s] 
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [147799]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:50770 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50770 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53938 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53938 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48742 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53892 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56608 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56608 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [147799]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [149332]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)

  0%|          | 0.00/896M [00:00<?, ?iB/s]
  1%|          | 4.98M/896M [00:00<00:17, 49.8MiB/s]
  1%|          | 10.5M/896M [00:00<00:26, 33.3MiB/s]
  2%|â–         | 21.0M/896M [00:00<00:24, 36.4MiB/s]
  4%|â–Ž         | 31.5M/896M [00:00<00:22, 38.1MiB/s]
  5%|â–         | 41.9M/896M [00:01<00:22, 38.1MiB/s]
  6%|â–Œ         | 52.4M/896M [00:01<00:21, 39.1MiB/s]
  7%|â–‹         | 62.9M/896M [00:01<00:21, 39.5MiB/s]
  8%|â–Š         | 73.4M/896M [00:01<00:21, 38.9MiB/s]
  9%|â–‰         | 83.9M/896M [00:02<00:20, 39.9MiB/s]
 11%|â–ˆ         | 94.4M/896M [00:02<00:19, 40.2MiB/s]
 12%|â–ˆâ–        | 105M/896M [00:02<00:19, 40.2MiB/s] 
 13%|â–ˆâ–Ž        | 115M/896M [00:02<00:19, 40.8MiB/s]
 14%|â–ˆâ–        | 126M/896M [00:03<00:19, 40.2MiB/s]
 15%|â–ˆâ–Œ        | 136M/896M [00:03<00:19, 39.9MiB/s]
 16%|â–ˆâ–‹        | 147M/896M [00:03<00:18, 40.1MiB/s]
 18%|â–ˆâ–Š        | 157M/896M [00:03<00:18, 40.4MiB/s]
 19%|â–ˆâ–Š        | 168M/896M [00:04<00:18, 40.2MiB/s]
 20%|â–ˆâ–‰        | 178M/896M [00:04<00:17, 41.1MiB/s]
 21%|â–ˆâ–ˆ        | 189M/896M [00:04<00:17, 39.6MiB/s]
 22%|â–ˆâ–ˆâ–       | 193M/896M [00:04<00:17, 40.1MiB/s]
 22%|â–ˆâ–ˆâ–       | 197M/896M [00:04<00:17, 39.8MiB/s]
 22%|â–ˆâ–ˆâ–       | 201M/896M [00:05<00:23, 29.0MiB/s]
 23%|â–ˆâ–ˆâ–Ž       | 210M/896M [00:05<00:22, 30.6MiB/s]
 25%|â–ˆâ–ˆâ–       | 220M/896M [00:05<00:19, 34.2MiB/s]
 26%|â–ˆâ–ˆâ–Œ       | 231M/896M [00:06<00:18, 36.5MiB/s]
 27%|â–ˆâ–ˆâ–‹       | 241M/896M [00:06<00:17, 36.6MiB/s]
 28%|â–ˆâ–ˆâ–Š       | 252M/896M [00:06<00:17, 37.0MiB/s]
 29%|â–ˆâ–ˆâ–‰       | 262M/896M [00:06<00:16, 38.4MiB/s]
 30%|â–ˆâ–ˆâ–ˆ       | 273M/896M [00:07<00:15, 39.2MiB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 283M/896M [00:07<00:15, 39.2MiB/s]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 294M/896M [00:07<00:15, 39.5MiB/s]
 34%|â–ˆâ–ˆâ–ˆâ–      | 304M/896M [00:07<00:14, 40.1MiB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 315M/896M [00:08<00:14, 40.7MiB/s]
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 325M/896M [00:08<00:14, 40.1MiB/s]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 336M/896M [00:08<00:13, 40.4MiB/s]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 342M/896M [00:08<00:12, 43.3MiB/s]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 346M/896M [00:08<00:14, 36.7MiB/s]
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 357M/896M [00:09<00:14, 37.8MiB/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367M/896M [00:09<00:13, 39.1MiB/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 377M/896M [00:09<00:12, 40.6MiB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 386M/896M [00:09<00:10, 47.1MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 391M/896M [00:10<00:12, 39.3MiB/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 398M/896M [00:10<00:13, 36.5MiB/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 407M/896M [00:10<00:10, 44.9MiB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 413M/896M [00:10<00:12, 38.8MiB/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 419M/896M [00:10<00:13, 34.5MiB/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 430M/896M [00:11<00:12, 36.3MiB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 440M/896M [00:11<00:12, 37.1MiB/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 451M/896M [00:11<00:11, 38.4MiB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 461M/896M [00:11<00:11, 39.4MiB/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472M/896M [00:12<00:10, 39.6MiB/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 482M/896M [00:12<00:10, 39.9MiB/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493M/896M [00:12<00:09, 40.5MiB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 503M/896M [00:12<00:09, 40.8MiB/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 514M/896M [00:13<00:09, 40.5MiB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 524M/896M [00:13<00:09, 40.7MiB/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 535M/896M [00:13<00:08, 40.6MiB/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 545M/896M [00:13<00:08, 40.6MiB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 556M/896M [00:14<00:08, 40.2MiB/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 566M/896M [00:14<00:08, 39.5MiB/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 577M/896M [00:14<00:08, 39.5MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 587M/896M [00:14<00:07, 40.0MiB/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 596M/896M [00:15<00:06, 46.1MiB/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 601M/896M [00:15<00:07, 38.0MiB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 608M/896M [00:15<00:08, 35.1MiB/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 619M/896M [00:15<00:07, 37.2MiB/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 629M/896M [00:16<00:06, 38.2MiB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 640M/896M [00:16<00:06, 38.7MiB/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 650M/896M [00:16<00:06, 39.4MiB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 661M/896M [00:16<00:05, 40.0MiB/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 671M/896M [00:17<00:05, 40.5MiB/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 682M/896M [00:17<00:05, 40.3MiB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 692M/896M [00:17<00:04, 40.8MiB/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 703M/896M [00:17<00:04, 39.7MiB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 713M/896M [00:18<00:04, 38.7MiB/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 724M/896M [00:18<00:04, 38.0MiB/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 734M/896M [00:18<00:04, 37.6MiB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 744M/896M [00:19<00:03, 38.8MiB/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 755M/896M [00:19<00:03, 38.3MiB/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 765M/896M [00:19<00:03, 39.5MiB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 776M/896M [00:19<00:03, 39.5MiB/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 786M/896M [00:20<00:02, 40.3MiB/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 796M/896M [00:20<00:02, 48.4MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 802M/896M [00:20<00:02, 41.8MiB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 807M/896M [00:20<00:02, 36.4MiB/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 818M/896M [00:20<00:02, 38.0MiB/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 828M/896M [00:21<00:01, 38.3MiB/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 839M/896M [00:21<00:01, 39.3MiB/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 849M/896M [00:21<00:01, 39.6MiB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 860M/896M [00:21<00:00, 39.9MiB/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 870M/896M [00:22<00:00, 40.6MiB/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 881M/896M [00:22<00:00, 39.1MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 891M/896M [00:22<00:00, 39.8MiB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 896M/896M [00:40<00:00, 39.8MiB/s]INFO:     127.0.0.1:36436 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56576 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [149332]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 896M/896M [03:09<00:00, 4.73MiB/s]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [150561]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:38150 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45964 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [150561]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [160000]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:48110 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48110 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34714 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34724 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47082 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33920 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59958 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51894 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51894 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51894 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36820 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36836 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36836 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56390 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47508 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50962 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50970 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [160000]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [164487]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:39056 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39056 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46558 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46558 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46558 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [164487]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [165162]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:41082 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41082 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37802 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35694 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53698 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46620 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [165162]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [171699]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:40666 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40666 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42204 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35496 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35496 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42014 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45610 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46514 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45804 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56570 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38888 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41204 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41204 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36382 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:43786 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35950 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46882 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45120 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42950 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42950 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53386 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60690 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39452 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39460 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41228 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41244 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41244 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [171699]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [173251]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:50966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50966 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49948 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55122 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55132 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55132 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [173251]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [174034]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:56096 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56096 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56096 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56516 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:40670 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60848 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33166 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46864 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58670 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52904 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52910 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52910 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52910 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52910 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38752 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38752 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38752 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42020 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33616 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36140 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54032 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39066 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39066 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44616 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44616 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [174034]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [227558]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [227558]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [227684]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53514 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45642 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34840 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54510 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48652 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35574 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54470 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58666 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37726 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [227684]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [228511]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:55608 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55608 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38466 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38466 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [228511]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [228673]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:32846 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54984 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [228673]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [228811]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [228811]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229031]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53828 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:52168 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229031]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229170]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:52038 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38242 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38242 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45152 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45152 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36994 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33294 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54796 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54796 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36154 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229170]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229291]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:36950 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36516 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229291]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229413]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:42056 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34824 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34824 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60418 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50846 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38932 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229413]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229536]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:58486 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58940 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229536]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229660]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:53158 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53162 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53162 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:46628 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229660]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [229802]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [229802]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [230592]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:47246 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47246 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33466 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53118 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41182 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [230592]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [230723]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:33628 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33628 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33644 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33644 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:43896 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42158 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42158 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37858 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37862 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [230723]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [230848]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:33432 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33432 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33432 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33444 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33444 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44134 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [230848]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231072]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:42540 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42540 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36184 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231072]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231194]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:36988 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36988 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55750 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35228 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60122 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50408 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231194]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231320]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:50008 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50008 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36980 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 85, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 326, in tts
    raise ValueError(
ValueError: You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231320]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231499]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:49800 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49800 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52748 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 85, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 326, in tts
    raise ValueError(
ValueError: You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231499]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231618]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:54298 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39600 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 85, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n0x/vocal-fun-ai-node/./tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 377, in tts_to_file
    wav = self.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py", line 323, in tts
    wav = self.synthesizer.tts(
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/utils/synthesizer.py", line 326, in tts
    raise ValueError(
ValueError: You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.
INFO:     127.0.0.1:48458 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231618]
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/n0x/vocal-fun-ai-node/venv/lib/python3.10/site-packages/TTS/api.py:92: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [231740]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:44120 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58190 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58190 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58720 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:53612 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45998 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36386 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48578 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33734 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55124 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42260 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39172 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [231740]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [435]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:39406 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38006 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38006 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45828 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [435]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [753]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:50700 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50700 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44526 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [753]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [857]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:37874 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37874 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:52976 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py", line 376, in tts_to_file
    wav = self.tts(
          ^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py", line 322, in tts
    wav = self.synthesizer.tts(
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/utils/synthesizer.py", line 422, in tts
    outputs = self.tts_model.synthesize(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/tts/models/xtts.py", line 405, in synthesize
    return self.full_inference(text, speaker_wav, language, **settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/tts/models/xtts.py", line 474, in full_inference
    return self.inference(
           ^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/tts/models/xtts.py", line 522, in inference
    assert text_tokens.shape[-1] < self.args.gpt_max_text_tokens, (
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError:  â— XTTS can only generate text with a maximum of 400 tokens.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [857]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [963]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:54832 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59218 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:36106 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:55902 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:51442 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45592 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:33374 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:35546 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:45396 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:53954 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55840 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [963]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [1072]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:41170 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1072]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [2445]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:40480 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38510 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:56992 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [2445]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [2554]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:43106 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49658 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49658 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51178 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58044 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58044 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [2554]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [2662]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:58488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:34994 - "POST /generate_audio HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/applications.py", line 208, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 181, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 78, in __call__
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/exceptions.py", line 82, in __call__
    raise exc from None
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 580, in __call__
    await route.handle(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 241, in handle
    await self.app(scope, receive, send)
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/starlette/routing.py", line 52, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/routing.py", line 226, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/venv/lib/python3.12/site-packages/fastapi/routing.py", line 159, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/tts.py", line 81, in generate_audio
    tts.tts_to_file(
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py", line 376, in tts_to_file
    wav = self.tts(
          ^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py", line 322, in tts
    wav = self.synthesizer.tts(
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/utils/synthesizer.py", line 326, in tts
    raise ValueError(
ValueError: You need to define either `text` (for sythesis) or a `reference_wav` (for voice conversion) to use the Coqui TTS API.
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [2662]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [3269]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:48370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48370 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48376 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:48376 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [3269]
/home/n0x/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [3375]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:38922 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38922 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:35728 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47692 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:59142 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:60826 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55448 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37902 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:39046 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:35654 - "POST /generate_audio HTTP/1.1" 200 OK
The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.
INFO:     127.0.0.1:53660 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [3375]
/home/naman/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [24054]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:51484 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55744 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36614 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:49142 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44092 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:41916 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50156 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [24054]
/home/naman/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
/home/naman/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [29146]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:46638 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47582 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47582 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:47582 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57212 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57212 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:57228 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:54840 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:43240 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52758 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:33110 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:44392 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51882 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:43232 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:55568 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:42536 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [29146]
/home/naman/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [33137]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:41990 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51810 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:51810 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:52488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [33137]
/home/naman/vocal-fun-ai-node/coqui-ai-TTS/TTS/api.py:91: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.
  warnings.warn("`gpu` will be deprecated. Please use `tts.to(device)` instead.")
INFO:     Started server process [33902]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)
INFO:     127.0.0.1:46292 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:36828 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:37546 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:32964 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:38488 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:58606 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     127.0.0.1:50744 - "POST /generate_audio HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [33902]
